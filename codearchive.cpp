Contents
./content/combinatorial/IntPerm.h
./content/combinatorial/binomialModPrime.h
./content/combinatorial/multinomial.h
./content/data-structures/DavidSegmentTree.h
./content/data-structures/DynamicHull.h
./content/data-structures/FenwickTree.h
./content/data-structures/FenwickTree2d.h
./content/data-structures/HashMap.h
./content/data-structures/InternalStructures.h
./content/data-structures/IntervalSet.h
./content/data-structures/IntervalSetHenry.h
./content/data-structures/LazySegmentTree.h
./content/data-structures/LineContainer.h
./content/data-structures/LinkCutTree.h
./content/data-structures/Matrix.h
./content/data-structures/OrderStatisticTree.h
./content/data-structures/PSegTreeHenry.h
./content/data-structures/Pareto.h
./content/data-structures/PersistentLiChao.h
./content/data-structures/RMQ.h
./content/data-structures/SegmentTree.h
./content/data-structures/SplayCutTree.h
./content/data-structures/SplayTree.h
./content/data-structures/SubMatrix.h
./content/data-structures/Treap.h
./content/data-structures/UnionFind.h
./content/geometry/3dHull.h
./content/geometry/Angle.h
./content/geometry/CircleConvexHull.h
./content/geometry/CircleIntersection.h
./content/geometry/CircleIntersectionArea.h
./content/geometry/CircleTangent.h
./content/geometry/ClosestPair.h
./content/geometry/ConvexHull.h
./content/geometry/CustomComplex.h
./content/geometry/DelaunayFast.h
./content/geometry/DelaunayHenry.h
./content/geometry/DelaunayTriangulation.h
./content/geometry/GeometryPrimitives.h
./content/geometry/InsidePolygon.h
./content/geometry/LineHullIntersection.h
./content/geometry/Lines.h
./content/geometry/Miniball.h
./content/geometry/Point3D.h
./content/geometry/PointInsideHull.h
./content/geometry/PolygonArea.h
./content/geometry/PolygonCenter.h
./content/geometry/PolygonCut.h
./content/geometry/SegmentIntersection.h
./content/geometry/kdTree.h
./content/geometry/linearTransformation.h
./content/geometry/sphericalDistance.h
./content/graph/2sat.h
./content/graph/BellmanFord.h
./content/graph/BiconnectedComponents.h
./content/graph/CactusDecomposition.h
./content/graph/CentroidHenry.h
./content/graph/CompressTree.h
./content/graph/DFSMatching.h
./content/graph/Dinic.h
./content/graph/EdmondsKarp.h
./content/graph/EulerTour.h
./content/graph/EulerWalk.h
./content/graph/Flow.h
./content/graph/FlowApplications.h
./content/graph/FloydWarshall.h
./content/graph/GeneralMatching.h
./content/graph/GlobalMinCut.h
./content/graph/GomoryHu.h
./content/graph/HLD.h
./content/graph/HopcroftKarp.h
./content/graph/Hungarian.h
./content/graph/ISAP.h
./content/graph/LCA.h
./content/graph/MatrixTree.h
./content/graph/MaximalCliques.h
./content/graph/MaximumClique.h
./content/graph/MaximumIndependentSet.h
./content/graph/MinCostArb.h
./content/graph/MinCostMaxFlow.h
./content/graph/MinCut.h
./content/graph/MinimumVertexCover.h
./content/graph/PushRelabel.h
./content/graph/SCC.h
./content/graph/ScaryGeneralMatching.h
./content/graph/TopoSort.h
./content/graph/TreePower.h
./content/graph/WeightedMatching.h
./content/number-theory/CRT.h
./content/number-theory/ContinuedFractions.h
./content/number-theory/Diophantine.h
./content/number-theory/Euclid.h
./content/number-theory/Factor.h
./content/number-theory/Farey.h
./content/number-theory/FracBinarySearch.h
./content/number-theory/MillerRabin.h
./content/number-theory/ModInverse.h
./content/number-theory/ModLog.h
./content/number-theory/ModMulLL.h
./content/number-theory/ModPow.h
./content/number-theory/ModSqrt.h
./content/number-theory/ModSum.h
./content/number-theory/ModularArithmetic.h
./content/number-theory/PythagTriples.h
./content/number-theory/Sieve.h
./content/numerical/BerlekampMassey.h
./content/numerical/Determinant.h
./content/numerical/F2MatrixMultiplication.h
./content/numerical/FastFourierTransform.h
./content/numerical/FastFourierTransformMod.h
./content/numerical/FastSubsetTransform.h
./content/numerical/GoldenSectionSearch.h
./content/numerical/HillClimbing.h
./content/numerical/IntDeterminant.h
./content/numerical/Integrate.h
./content/numerical/IntegrateAdaptive.h
./content/numerical/LinearRecurrence.h
./content/numerical/MatrixInverse-mod.h
./content/numerical/MatrixInverse.h
./content/numerical/NumberTheoreticTransform.h
./content/numerical/OldSimplex.h
./content/numerical/PolyInterpolate.h
./content/numerical/PolyRoots.h
./content/numerical/Polynomial.h
./content/numerical/Simplex.h
./content/numerical/SolveLinear.h
./content/numerical/SolveLinear2.h
./content/numerical/SolveLinearBinary.h
./content/numerical/Tridiagonal.h
./content/strings/AhoCorasick.h
./content/strings/DavidAhoCorasick.h
./content/strings/FastSuffixArray.h
./content/strings/Hashing-codeforces.h
./content/strings/Hashing.h
./content/strings/KMP.h
./content/strings/Manacher.h
./content/strings/MinRotation.h
./content/strings/OldAhoCorasick.h
./content/strings/OldSuffixTree.h
./content/strings/SuffixArray.h
./content/strings/SuffixTree.h
./content/strings/WaveletTree.h
./content/strings/Zfunc.h
./content/various/BumpAllocator.h
./content/various/BumpAllocatorSTL.h
./content/various/ConstantIntervals.h
./content/various/DivideAndConquerDP.h
./content/various/FastMod.h
./content/various/IntervalContainer.h
./content/various/IntervalCover.h
./content/various/Josephus.h
./content/various/KnuthDP.h
./content/various/LIS.h
./content/various/Poker.h
./content/various/SIMD.h
./content/various/SmallPtr.h
./content/various/TernarySearch.h
./content/various/Unrolling.h
./content/various/WeightedLIS.h
------------------------------------------------------------------------


./content/combinatorial/IntPerm.h
/**
 * Author: Simon Lindholm
 * Date: 2018-07-06
 * License: CC0
 * Description: Permutation -> integer conversion. (Not order preserving.)
 * Time: O(n)
 */
#pragma once

int permToInt(vi& v) {
	int use = 0, i = 0, r = 0;
	trav(x, v) r = r * ++i + __builtin_popcount(use & -(1 << x)),
		use |= 1 << x;                     // (note: minus, not ~!)
	return r;
}


./content/combinatorial/binomialModPrime.h
/**
 * Author: Håkan Terelius
 * Date: 2009-09-25
 * License: CC0
 * Source: http://en.wikipedia.org/wiki/Lucas'_theorem
 * Description: Lucas' thm: Let $n,m$ be non-negative integers and $p$ a prime.
 * Write $n=n_kp^k+...+n_1p+n_0$ and $m=m_kp^k+...+m_1p+m_0$.
 * Then $\binom{n}{m} \equiv \prod_{i=0}^k\binom{n_i}{m_i} \pmod{p}$.
 * fact and invfact must hold pre-computed factorials / inverse factorials, e.g. from ModInverse.h.
 * Status: Untested
 * Time: O(\log_p n)
 */
#pragma once

ll chooseModP(ll n, ll m, int p, vi& fact, vi& invfact) {
	ll c = 1;
	while (n || m) {
		ll a = n % p, b = m % p;
		if (a < b) return 0;
		c = c * fact[a] % p * invfact[b] % p * invfact[a - b] % p;
		n /= p; m /= p;
	}
	return c;
}


./content/combinatorial/multinomial.h
/**
 * Author: Mattias de Zalenski, Fredrik Niemelä, Per Austrin, Simon Lindholm
 * Date: 2002-09-26
 * Source: Max Bennedich
 * Description: Computes $\displaystyle \binom{k_1 + \dots + k_n}{k_1, k_2, \dots, k_n} = \frac{(\sum k_i)!}{k_1!k_2!...k_n!}$.
 * Status: Tested on kattis:lexicography
 */
#pragma once

ll multinomial(vi& v) {
	ll c = 1, m = v.empty() ? 1 : v[0];
	rep(i,1,sz(v)) rep(j,0,v[i])
		c = c * ++m / (j+1);
	return c;
}


./content/data-structures/DavidSegmentTree.h
/**
 * Description: Segment Tree.
 */
#pragma once

struct segtree {
  vector<ll> t, d;
  int h, n;
  segtree() {}
  segtree(int sz) {
    h = 32 - __builtin_clz(sz);
    n = 1<<h;
    t = vector<ll>(n<<1, 0);
    d = vector<ll>(n<<1, 0);
  }
  void apply(int x, ll v) {
    int p = h-(31-__builtin_clz(x));
    t[x] += v*(1LL<<p);
    d[x] += v;
  }
  void pulll(int x) {
    int p = h-(31-__builtin_clz(x));
    t[x] = t[x<<1]+t[x<<1|1];
    t[x] += d[x]*(1LL<<p);
  }
  void pushh(int x) {
    if(d[x]) {
      apply(x<<1, d[x]);
      apply(x<<1|1, d[x]);
      d[x] = 0;
    }
  }
  void push(int i) {
    i += n;
    for(int l=h;l>0;--l) {
      pushh(i>>l);
    }
  }
  void add(int l, int r, ll v) {
    push(l); push(r-1);
    bool cl=0, cr=0;
    for(l+=n, r+=n;l<r;l/=2, r/=2) {
      if(cl) pulll(l-1);
      if(cr) pulll(r);
      if(l%2) {
        apply(l++, v);
        cl = 1;
      }
      if(r%2) {
        apply(--r, v);
        cr = 1;
      }
    }
    for(l--;r>0;l/=2, r/=2) {
      if(cl) pulll(l);
      if(cr && (!cl || l != r)) pulll(r);
    }
  }
  ll query(int l, int r) {
    ll ans = 0;
    push(l); push(r-1);
    for(l+=n, r+=n;l<r;l/=2, r/=2) {
      if(l%2) ans += t[l++];
      if(r%2) ans += t[--r];
    }
    return ans;
  }
};


./content/data-structures/DynamicHull.h
/**
 * Description: Dynamic hull from old codearchive
 * Time: O(\log N)
 */
#pragma once

// WARNING: could overflow for values ~1e9, use __int128 instead
// WARNING: tested only with integer and rational types
const ll is_query = -(1LL<<62);
struct Line {
  ll m, b;
  mutable function<const Line*()> succ;
  bool operator<(const Line& rhs) const {
    if (rhs.b != is_query) return m < rhs.m;
    const Line* s = succ();
    if (!s) return 0;
    ll x = rhs.m;
    return b - s->b < (s->m - m) * x;
  }
};
// will maintain upper hull for maximum
struct HullDynamic : public multiset<Line> {
  bool bad(iterator y) {
    auto z = next(y);
    if (y == begin()) {
      if (z == end()) return 0;
      return y->m == z->m && y->b <= z->b;
    }
    auto x = prev(y);
    if (z == end()) return y->m == x->m && y->b <= x->b;
    // could overflow
    return (x->b - y->b)*(z->m - y->m) >= (y->b - z->b)*(y->m - x->m);
  }
  void insert_line(ll m, ll b) { // m = -m; b = -b; // for lower hull
    auto y = insert({ m, b });
    y->succ = [=] { return next(y) == end() ? 0 : &*next(y); };
    if (bad(y)) { erase(y); return; }
    while (next(y) != end() && bad(next(y))) erase(next(y));
    while (y != begin() && bad(prev(y))) erase(prev(y));
  }
  ll eval(ll x) {
    auto l = *lower_bound((Line) { x, is_query });
    return l.m * x + l.b; // return -(l.m * x + l.b); // for lower hull
  }
};


./content/data-structures/FenwickTree.h
/**
 * Description: Computes range sums and performs point updates for associative and invertible group operations,
 *  or performs range updates and point queries. Valid positions are 1..N.
 *  Commented lines are hints for a 2D BIT.
 * Time: $O(\log N)$.
 */
#pragma once

struct BITree { ll freq[N+1]; BITree() { memset(freq, 0, sizeof freq); }
  void insert(int x, ll cnt=1) {
    for ( ; x <= MAXN; x += x & -x) freq[x] += cnt;
      //for (int y = argy; y <= MAXN; y += y & -y) freq[x][y] += cnt;
  }
  ll query(int x) { ll sum = 0;
    for ( ; x; x -= x & -x) sum += freq[x];
      //for (int y = argy; y; y -= y & -y) sum += freq[x][y];
    return sum; }
  void insert_range(int xl,int xr,ll cnt=1) {
    insert(xl,cnt); insert(xr+1,-cnt);}
  ll query_range(int xl, int xr) { return query(xr) - query(xl-1); }
  int get_nth(ll n) { int x = 1<<30; // assumes non-negative frequencies
    for (int step = x>>1; step; step >>= 1) {
      if (x-step > MAXN || freq[x-step] >= n) x -= step;
      else n -= freq[x-step];
    }
    return x; } };


./content/data-structures/FenwickTree2d.h
/**
 * Author: Simon Lindholm
 * Date: 2017-05-11
 * License: CC0
 * Source: folklore
 * Description: Computes sums a[i,j] for all i<I, j<J, and increases single elements a[i,j].
 *  Requires that the elements to be updated are known in advance (call fakeUpdate() before init()).
 * Time: $O(\log^2 N)$. (Use persistent segment trees for $O(\log N)$.)
 */
#pragma once

#include "FenwickTree.h"

struct FT2 {
	vector<vi> ys; vector<FT> ft;
	FT2(int limx) : ys(limx) {}
	void fakeUpdate(int x, int y) {
		for (; x < sz(ys); x |= x + 1) ys[x].push_back(y);
	}
	void init() {
		trav(v, ys) sort(all(v)), ft.emplace_back(sz(v));
	}
	int ind(int x, int y) {
		return (int)(lower_bound(all(ys[x]), y) - ys[x].begin()); }
	void update(int x, int y, ll dif) {
		for (; x < sz(ys); x |= x + 1)
			ft[x].update(ind(x, y), dif);
	}
	ll query(int x, int y) {
		ll sum = 0;
		for (; x; x &= x - 1)
			sum += ft[x-1].query(ind(x-1, y));
		return sum;
	}
};


./content/data-structures/HashMap.h
/**
 * Author: Simon Lindholm, chilli
 * Date: 2018-07-23
 * License: CC0
 * Source: http://codeforces.com/blog/entry/60737
 * Description: Hash map with the same API as unordered\_map, but \tilde 3x faster.
 * Initial capacity must be a power of 2 (if provided).
 */
#pragma once

#include <bits/extc++.h> /** keep-include */
// To use most bits rather than just the lowest ones:
struct chash {
	const uint64_t C = ll(2e18 * M_PI) + 71; // large odd number
	ll operator()(ll x) const { return __builtin_bswap64(x*C); }
};
__gnu_pbds::gp_hash_table<ll,int,chash> h({},{},{},{},{1<<16});

/** For CodeForces, or other places where hacking might be a problem:

const int RANDOM = chrono::high_resolution_clock::now().time_since_epoch().count();
struct chash { // To use most bits rather than just the lowest ones:
	const uint64_t C = ll(2e18 * M_PI) + 71; // large odd number
	ll operator()(ll x) const { return __builtin_bswap64((x^RANDOM)*C); }
};
__gnu_pbds::gp_hash_table<ll, int, chash> h({},{},{},{}, {1 << 16});
*/


./content/data-structures/InternalStructures.h
/**
 * Description: Some data structures internal to GCC.
 */

#pragma once

#include <ext/pb_ds/assoc_container.hpp> // BST stuff /// keep-include
#include <ext/pb_ds/tree_policy.hpp>   // BST stuff   /// keep-include
using namespace __gnu_pbds;        // BST namespace
template <typename T> using ordered_set = tree<T, null_type, less<T>,
				 rb_tree_tag, tree_order_statistics_node_update>;

#include <ext/rope> //header with rope                /// keep-include
using namespace __gnu_cxx; //namespace with rope and additional stuff
void example() {
  // rope stuff!
  rope <int> v;                            // initialization
  int i = 10; v.push_back(i);              // adding values
  int l = 0, r = 0;
  rope <int> cur = v.substr(l, r - l + 1); // getting substrings
  v.erase(l, r - l + 1);           // erasing substrings
  v.insert(v.mutable_begin(), cur);    // inserting
  int x = v[i];              // random access

  typedef tree<double, int, less<double>, rb_tree_tag,
      tree_order_statistics_node_update> map_t;
  map_t s;
  s.insert(make_pair(12, 1012));
  s.insert(make_pair(505, 1505));
  s.insert(make_pair(30, 1030));
  cout << s.find_by_order(1)->second << '\n'; // returns kth item
  cout << s.order_of_key(12) << '\n'; // returns count of how many < 12

  gp_hash_table<int, int> h; // faster hash table
  h[x] = 5;
}


./content/data-structures/IntervalSet.h
/**
 * Author: Jason
 * Description: Stores a set of disjoint intervals $[a, b)$.
 * Time: O(\log n) amortized per operation
 */

#pragma once

struct interval_set { set<pair<ll, ll>> s;
  void insert(ll a, ll b) { if (s.empty()) { s.insert({a, b}); return; }
    /// extend right (intervals starting > a)
    auto it1 = s.upper_bound({a, INF}); while (it1 != s.end()) {
      if ((*it1).first <= b) { auto it1nxt = it1; ++it1nxt;
        b = max(b, (*it1).second); s.erase(it1); it1 = it1nxt;
      } else break; }
    /// extend left (intervals starting <= a)
    it1 = s.upper_bound({a, INF}); if (it1 != s.begin()) { --it1;
      while (1) { if (a <= (*it1).second) { auto it1nxt = it1; --it1nxt;
        bool isBegin = (it1 == s.begin());
        a = min(a, (*it1).first); b = max(b, (*it1).second);
        s.erase(it1); it1 = it1nxt; if (isBegin) break;
      } else break; } } s.insert({a, b}); }
  pair<ll, ll> find(ll x) { if (s.empty()) return {INF, INF};
    auto it1 = s.upper_bound({x, INF});
    if (it1 == s.begin()) return {INF, INF}; --it1;
    if ((*it1).second <= x) return {INF, INF}; return *it1; } };


./content/data-structures/IntervalSetHenry.h
/**
 * Author: Henry Xia
 * Description: Stores a set of disjoint intervals $[a, b)$ (default). Returns {inf,inf} when not found.
 * Usage: 1. Define a type with operators < and ==, Also an inf for that type
 * 2. IntervalSet<Type,left_inclusive,right_inclusive> iset(T.inf);
 * 3. iset.insert(a,b); to insert the interval (a,b)
 * 4. iset.find(x); to find to which interval point x belongs
 * Time: O(\log n) amortized per operation
 * Status: tested unconvincingly on USP tryouts 2018
 */
#pragma once

template <class T, bool lin=true, bool rin=false>
struct IntervalSet {
  T inf; set<pair<T,T>> s;
  IntervalSet(T F): inf(F) {}
  bool cmp(const T& a, const T& b, bool l, bool r=false) {
    if (l||r) return a < b || a == b; else return a < b;
  }
  void insert(T a, T b) {
    auto it = s.upper_bound({a,inf});
    while (it != s.end() && cmp(it->first, b, lin, rin)) {
      b = max(b, it->second); it = s.erase(it);
    }
    if (it != s.begin() && cmp(a, (--it)->second, lin, rin)) {
      a = min(a, it->first); b = max(b, it->second); s.erase(it);
    }
    s.insert({a,b});
  }
  pair<T,T> find(T x) {
    if (s.empty()) { return {inf,inf}; }
    auto it = s.upper_bound({x,inf});
    if (it == s.begin()) return {inf,inf};
    if (cmp((--it)->second,x,!rin)) return {inf,inf};
    if (cmp(x,it->first,!lin)) return {inf,inf};
    return *it;
  }
};


./content/data-structures/LazySegmentTree.h
/**
 * Author: Simon Lindholm
 * Date: 2016-10-08
 * License: CC0
 * Source: me
 * Description: Segment tree with ability to add or set values of large intervals, and compute max of intervals.
 * Can be changed to other things.
 * Use with a bump allocator for better performance, and SmallPtr or implicit indices to save memory.
 * Time: O(\log N).
 * Usage: Node* tr = new Node(v, 0, sz(v));
 * Status: fuzz-tested a bit
 */
#pragma once

#include "../various/BumpAllocator.h"

const int inf = 1e9;
struct Node {
	Node *l = 0, *r = 0;
	int lo, hi, mset = inf, madd = 0, val = -inf;
	Node(int lo,int hi):lo(lo),hi(hi){} // Large interval of -inf
	Node(vi& v, int lo, int hi) : lo(lo), hi(hi) {
		if (lo + 1 < hi) {
			int mid = lo + (hi - lo)/2;
			l = new Node(v, lo, mid); r = new Node(v, mid, hi);
			val = max(l->val, r->val);
		}
		else val = v[lo];
	}
	int query(int L, int R) {
		if (R <= lo || hi <= L) return -inf;
		if (L <= lo && hi <= R) return val;
		push();
		return max(l->query(L, R), r->query(L, R));
	}
	void set(int L, int R, int x) {
		if (R <= lo || hi <= L) return;
		if (L <= lo && hi <= R) mset = val = x, madd = 0;
		else {
			push(), l->set(L, R, x), r->set(L, R, x);
			val = max(l->val, r->val);
		}
	}
	void add(int L, int R, int x) {
		if (R <= lo || hi <= L) return;
		if (L <= lo && hi <= R) {
			if (mset != inf) mset += x;
			else madd += x;
			val += x;
		}
		else {
			push(), l->add(L, R, x), r->add(L, R, x);
			val = max(l->val, r->val);
		}
	}
	void push() {
		if (!l) {
			int mid = lo + (hi - lo)/2;
			l = new Node(lo, mid); r = new Node(mid, hi);
		}
		if (mset != inf)
			l->set(lo,hi,mset), r->set(lo,hi,mset), mset = inf;
		else if (madd)
			l->add(lo,hi,madd), r->add(lo,hi,madd), madd = 0;
	}
};


./content/data-structures/LineContainer.h
/**
 * Author: Simon Lindholm
 * Date: 2017-04-20
 * License: CC0
 * Source: own work
 * Description: Container where you can add lines of the form mx+b, and query maximum values at points x.
 *  Useful for dynamic programming.
 * Time: O(\log N)
 * Status: tested
 */
#pragma once

struct Line {
	mutable ll m, b, p;
	bool operator<(const Line& o) const { return m < o.m; }
	bool operator<(ll x) const { return p < x; }
};

struct LineContainer : multiset<Line, less<>> {
	// (for doubles, use inf = 1/.0, div(a,b) = a/b)
	const ll inf = LLONG_MAX;
	ll div(ll a, ll b) { // floored division
		return a / b - ((a ^ b) < 0 && a % b); }
	bool isect(iterator x, iterator y) {
		if (y == end()) { x->p = inf; return false; }
		if (x->m == y->m) x->p = x->b > y->b ? inf : -inf;
		else x->p = div(y->b - x->b, x->m - y->m);
		return x->p >= y->p;
	}
	void add(ll m, ll b) {
		auto z = insert({m, b, 0}), y = z++, x = y;
		while (isect(y, z)) z = erase(z);
		if (x != begin() && isect(--x, y)) isect(x, y = erase(y));
		while ((y = x) != begin() && (--x)->p >= y->p)
			isect(x, erase(y));
	}
	ll query(ll x) {
		assert(!empty());
		auto l = *lower_bound(x);
		return l.m * x + l.b;
	}
};


./content/data-structures/LinkCutTree.h
/**
 * Author: Antony at UCF
 * Description: Represents a forest of unrooted trees. You can add and remove
 * edges (as long as the result is still a forest), and check whether
 * two nodes are in the same tree.
 * Usage:
 *  - link(p, q) - makes the *root* p a child of the node q.
 *                 if p is not a root, makeroot will be called and lca(p, q) will be changed.
 *  - cut(p)     - deletes the edge connecting p to its parent
 *  - cut(p, q)  - delete the edge connecting p to q (or on path p to q)
 *  - pathAggregate(p, q) - returns the sum of weights on path p to q.
 *                          this operation can be min, adding a constant, etc.
 *  - pathUpdate(x, y, c) - increase value of all nodes x-y inc. by c.
 *  - findroot(p)         - returns the root of node p's tree
 *  - makeroot(p)         - makes p the root of its tree
 * Time: All operations take amortized O(\log N).
 * Status: tested SPOJ DYNALCA, DYNACON1, and more
 */
#pragma once

struct LinkCutTree {
  vector<int> l,r,p,pp,val,sum,carry,size,flip; int null;
  void init(int n) { // begin-hash
    vector<int>* v[] = {&l,&r,&p,&pp,&size,&val,&sum,&carry,&flip};
    int ival[] = {null=n, null, null, null, 1, 0, 0, 0, 0};
    for (int i=0; i<9; i++) {v[i]->clear(); v[i]->resize(n+1, ival[i]);}
    size[null] = 0; }
  inline int access(int x) {
    if(r[splay(x)] != null) r[pp[r[x]] = x] = p[r[x]] = null;
    for(int w=x;update(w)>=0 && splay(w=pp[x])!=null;splay(r[p[x]=w]=x))
      if(r[w] != null) p[r[pp[r[w]]=w]] = null;
    return x; }
  void makeroot(int x) { access(x); flip[x] ^= 1; push(x); }
  int findroot(int x) {
    for(access(x); l[x] != null; x = l[x]) {}
    return access(x); } // end-hash: b7f4d2
  int pathAggregate(int x) { return sum[access(x)]; } // begin-hash
  int pathAggregate(int x, int y){makeroot(x); return pathAggregate(y);}
  void cut(int x) { l[x] = p[l[access(x)]] = null; }
  void cut(int x, int y) { makeroot(y); cut(x); }
  void link(int x, int y) { makeroot(x);l[p[access(y)]=access(x)] = y; }
  void pathUpdate(int x, int y, int c) { int z = lca(x,y);
    if(x != z) carry[x] += c; if(y != z) carry[y] += c;
    val[z] += c; }
  inline int splay(int x) {
    for(push(x); p[x] != null; lift(x))
      if(l[l[p[p[x]]]] == x || r[r[p[p[x]]]] == x) lift(p[x]);
      else lift(x);
    return x; } // end-hash: 4d311f
  void push(int x) { // begin-hash
    if(flip[x]==1) {
      swap(l[x], r[x]);
      flip[x]^=1; flip[l[x]]^=1; flip[r[x]]^=1; }
    val[x] += carry[x];
    carry[l[x]] += carry[x]; carry[r[x]] += carry[x];
    carry[x] = 0; }
  int update(int x) {
    if(x == null) return x;
    size[x] = size[l[x]] + size[r[x]] + 1;
    sum[x] = val[x]+sum[l[x]]+sum[r[x]] + carry[x]*size[x];
    return x; }
  int lca(int x, int y) {
    access(x); access(y); splay(x);
    return access(pp[x]==null?x:pp[x]); }
  void lift(int x) {
    if(p[x] == null) return;
    push(p[x]); push(x); push(l[x]); push(r[x]);
    pp[x] = pp[p[x]]; pp[p[x]] = null;
    int* a=&l[0], *b=&r[0];
    if(r[p[x]]==x) {a=&r[0]; b=&l[0];}
    a[p[x]] = b[x]; b[x] = p[x]; p[x] = p[p[x]];
    if(p[x] != null) {
      if(a[p[x]] == b[x]) a[p[x]] = x;
      else b[p[x]] = x; }
    if(a[b[x]] != null) p[a[b[x]]] = b[x];
    update(l[b[x]]); update(r[b[x]]);
    update(p[update(b[x])] = x); } }; // end-hash: fb0cfa


./content/data-structures/Matrix.h
/**
 * Author: Ulf Lundstrom
 * Date: 2009-08-03
 * License: CC0
 * Source: My head
 * Description: Basic operations on square matrices.
 * Usage: Matrix<int, 3> A;
 *  A.d = {{{{1,2,3}}, {{4,5,6}}, {{7,8,9}}}};
 *  vector<int> vec = {1,2,3};
 *  vec = (A^N) * vec;
 * Status: tested
 */
#pragma once

template<class T, int N> struct Matrix {
	typedef Matrix M;
	array<array<T, N>, N> d{};
	M operator*(const M& m) const {
		M a;
		rep(i,0,N) rep(j,0,N)
			rep(k,0,N) a.d[i][j] += d[i][k]*m.d[k][j];
		return a;
	}
	vector<T> operator*(const vector<T>& vec) const {
		vector<T> ret(N);
		rep(i,0,N) rep(j,0,N) ret[i] += d[i][j] * vec[j];
		return ret;
	}
	M operator^(ll p) const {
		assert(p >= 0);
		M a, b(*this);
		rep(i,0,N) a.d[i][i] = 1;
		while (p) {
			if (p&1) a = a*b;
			b = b*b;
			p >>= 1;
		}
		return a;
	}
};


./content/data-structures/OrderStatisticTree.h
/**
 * Author: Simon Lindholm
 * Date: 2016-03-22
 * License: CC0
 * Source: hacKIT, NWERC 2015
 * Description: A set (not multiset!) with support for finding the n'th
 * element, and finding the index of an element.
 * To get a map, change \texttt{null\_type}.
 * Time: O(\log N)
 */
#pragma once

#include <bits/extc++.h> /** keep-include */
using namespace __gnu_pbds;

template<class T>
using Tree = tree<T, null_type, less<T>, rb_tree_tag,
    tree_order_statistics_node_update>;

void example() {
	Tree<int> t, t2; t.insert(8);
	auto it = t.insert(10).first;
	assert(it == t.lower_bound(9));
	assert(t.order_of_key(10) == 1);
	assert(t.order_of_key(11) == 2);
	assert(*t.find_by_order(0) == 8);
	t.join(t2); // assuming T < T2 or T > T2, merge t2 into t
}


./content/data-structures/PSegTreeHenry.h
/**
 * Author: Henry
 * Description: Persistent Lazy Segment Tree EXAMPLE
 * Time: O(\log n) memory and time per update
 */
#pragma once

// const int N = 1<<20; // range of psegtree leaves (power of 2)
// const int M = 1e5+1; // versions of the psegtree
const int D = 8e6;

struct Node {
	ll sum, z;
	Node(): sum(0), z(0) {}
	void update(ll v, int s, int e) {
		z += v * (e-s+1);
		sum += v * (e-s+1);
	}
};

int root[M];
Node st[D];
int ls[D], rs[D];
int sid;

void push(int ver, int s, int m, int e) {
	if(ls[ver] == 0) ls[ver] = ++sid;
	if(rs[ver] == 0) rs[ver] = ++sid;
	if(st[ver].z) {
		st[ls[ver]].sum += st[ver].z/2;  st[rs[ver]].sum += st[ver].z/2;
		st[ls[ver]].z += st[ver].z/2;    st[rs[ver]].z += st[ver].z/2;
		st[ver].z = 0;
	}
}
void pull(int ver) { st[ver].sum = st[ls[ver]].sum + st[rs[ver]].sum; }

void insert(int& ver, int old, ll v, int l, int r, int s, int e) {
	if(r<s || e<l) return;
	ver = ++sid;
	ls[ver] = ls[old];
	rs[ver] = rs[old];
	st[ver] = st[old];

	if(l<=s && e<=r) { st[ver].update(v, s, e); return; }

	int m = (s+e)/2; push(ver, s, m, e);
	insert(ls[ver], ls[old], v, l, r, s, m);
	insert(rs[ver], rs[old], v, l, r, m+1, e);
	pull(ver);
}

ll query(int ver, int l, int r, int s, int e) {
	if(r<s || e<l) return 0;
	if(l<=s && e<=r) { return st[ver].sum; }
	int m = (s+e)/2; push(ver, s, m, e);
	return query(ls[ver], l, r, s, m) + query(rs[ver], l, r, m+1, e);
}


./content/data-structures/Pareto.h
/**
 * Author: Jason
 * Description: Stores the Pareto front of a set of 2D points.
 * Time: O(\log N) amortized per operation
 */

#pragma once

struct pareto { set<pair<ll, ll>> s;
  void insert(ll x, ll y) { if (s.empty()) { s.insert({x, y}); return; }
    /// find last pt.x <= x, check if one dominates another
    auto it1 = s.upper_bound({x, INF}); auto it0 = it1;
    if (it0 != s.begin()) { --it0; if ((*it0).second <= y) return;
      else if ((*it0).first == x) s.erase(it0); }
    /// greedily scan to the right and remove dominated points
    while (it1 != s.end()) { auto it2 = it1; ++it2;
      if ((*it1).second >= y) s.erase(it1); else break; it1 = it2; }
    s.insert({x, y}); }
  ll getMinY(ll x) { if (s.empty() || x < s.begin()->first) return INF;
    return (*(--s.upper_bound({x, INF}))).second; } };


./content/data-structures/PersistentLiChao.h
/**
 * Author: Xingyu, Henry
 * Description: Persistent Segment Tree EXAMPLE (Li Chao Tree)
 * Time: O(\log n) memory and time per update
 */
#pragma once

//const int N = 1<<30; // range of psegtree leaves (power of 2)
//const int M = 8e4+1; // versions of the psegtree
const int D = 1e7; // nodes for memory
const ll INFLL = 0x3f3f3f3f3f3f3f3f;
struct Line {
	int m, b;
	ll eval(int x) const { return (b == -1 ? INFLL : (ll)m*x + b); }
};

int root[M];
Line st[D];
int ls[D], rs[D];

int sid;
void init() {
	sid = 0;
	st[0] = {0, -1};
}

void fix(int& ver, int old, Line v, int l, int r) {
	ver = ++sid;
	ls[ver] = ls[old];
	rs[ver] = rs[old];
	st[ver] = st[old];

	int m = (l+r)/2;
	bool left = (v.eval(l) < st[old].eval(l));
	bool right = (v.eval(r) < st[old].eval(r));
	bool mid = (v.eval(m) < st[old].eval(m));
	if(left == right) {
		if(left) st[ver] = v;
		return;
	}

	if(mid) swap(v, st[ver]);
	fix(ls[ver], ls[old], v, l, m);
	fix(rs[ver], rs[old], v, m+1, r);
}

void insert(int& ver, int old, Line v, int l, int r, int s, int e) {
	if(r<s || e<l) return;
	if(l<=s && e<=r) {
		fix(ver, old, v, s, e);
		return;
	}

	ver = ++sid;
	ls[ver] = ls[old];
	rs[ver] = rs[old];
	st[ver] = st[old];

	int m = (s+e)/2;
	insert(ls[ver], ls[old], v, l, r, s, m);
	insert(rs[ver], rs[old], v, l, r, m+1, e);
}

ll query(int ver, int x, int s, int e) {
	ll res = st[ver].eval(x);
	if(s == e) return res;
	int m = (s+e)/2;
	if(x <= m) return min(res, query(ls[ver], x, s, m));
	else return min(res, query(rs[ver], x, m+1, e));
}

int A[M], B[M], C[M];
vector<int> adj[M];
void build(int u, int p) {
	insert(root[u], root[p], {B[u], A[u]}, 0, C[u], 0, N-1);
	for(int v : adj[u]) {
		if(v == p) continue;
		build(v, u);
	}
}


./content/data-structures/RMQ.h
/**
 * Author: Johan Sannemo
 * Date: 2015-02-06
 * License: CC0
 * Source: Folklore
 * Status: Tested at Petrozavodsk
 * Description: Range Minimum Queries on an array. Returns
 * min(V[a], V[a + 1], ... V[b - 1]) in constant time. 
 * Usage:
 *  RMQ rmq(values);
 *  rmq.query(inclusive, exclusive);
 * Time: $O(|V| \log |V| + Q)$
 */
#pragma once

template<class T>
struct RMQ {
	vector<vector<T>> jmp;

	RMQ(const vector<T>& V) {
		int N = sz(V), on = 1, depth = 1;
		while (on < N) on *= 2, depth++;
		jmp.assign(depth, V);
		rep(i,0,depth-1) rep(j,0,N)
			jmp[i+1][j] = min(jmp[i][j],
			jmp[i][min(N - 1, j + (1 << i))]);
	}

	T query(int a, int b) {
		assert(a < b); // or return inf if a == b
		int dep = 31 - __builtin_clz(b - a);
		return min(jmp[dep][a], jmp[dep][b - (1 << dep)]);
	}
};


./content/data-structures/SegmentTree.h
/**
 * Author: Lucian Bicsi
 * Date: 2017-10-31
 * License: CC0
 * Source: folklore
 * Description: Zero-indexed max-tree. Bounds are inclusive to the left and exclusive to the right. Can be changed by modifying T, f and unit.
 * Time: O(\log N)
 * Status: fuzz-tested
 */
#pragma once

struct Tree {
	typedef int T;
	static constexpr T unit = INT_MIN;
	T f(T a, T b) { return max(a, b); } // (any associative fn)
	vector<T> s; int n;
	Tree(int n = 0, T def = unit) : s(2*n, def), n(n) {}
	void update(int pos, T val) {
		for (s[pos += n] = val; pos /= 2;)
			s[pos] = f(s[pos * 2], s[pos * 2 + 1]);
	}
	T query(int b, int e) { // query [b, e)
		T ra = unit, rb = unit;
		for (b += n, e += n; b < e; b /= 2, e /= 2) {
			if (b % 2) ra = f(ra, s[b++]);
			if (e % 2) rb = f(s[--e], rb);
		}
		return f(ra, rb);
	}
};


./content/data-structures/SplayCutTree.h
/**
 * Description: (Splay tree + LCT plugin) A powerful self-balancing binary search tree.
 *  Must \texttt{splay()} every constant number of accesses to maintain the amortized bound.
 *  Note some operations do not splay.
 * Time: O(\log n) amortized all operations
 * Usage:
 *  construct nodes with new_node(constructor params)
 *  node ids are assigned starting at 1; node 0 is nil
 *  Before accessing children, push() lazy; after updating children, pull() changes
 * Status: tested SPOJS CERC07S, TWIST, ORDERSET, GSS6, SEQ2; cf102001B
 */
#pragma once

struct node; using pn = node*;
struct node { pn l, r, p, pp; ll key, val, cnt, lazy, acc; bool rev;
  node(ll k=0, ll v=0);  // pp is for LCT
  inline int dir() { return this == p->r; }
  inline void setc(pn c, bool right) { (right?r:l) = c; c->p = this; }
} dat[N]; // nil = dat[0]
pn nil=[](){pn x=dat; x->l=x->r=x->p=x; /*x->acc=INF;*/ // RMQ
  x->cnt=0; return x;}();
node::node(ll k, ll v): l(nil), r(nil), p(nil), pp(nil),
  key(k), val(v), cnt(1), lazy(0), acc(v), rev(0) {}
int nodeid = 0; template <class... T> pn new_node(T&& ...args) {
  return &(dat[++nodeid] = node(forward<T>(args)...)); }

namespace SplayTree {
//%%== Code for upwards propagating property (eg. count, min)
inline void pull(pn x) { if (x != nil) {
  x->cnt = 1 + x->l->cnt + x->r->cnt;
  /*x->acc = min(x->l->acc, min(x->val, x->r->acc));*/ } }         //RMQ
//%%== Code for lazy propagating property (eg. reverse subtree, add)
void rev(pn x) { if (x != nil) { x->rev ^= 1; swap(x->l, x->r); } }
inline void modifyNode(pn x, ll v) { if (x != nil) {
  /*x->val += v; x->acc += v; x->lazy += v;*/ } }                  //RMQ
inline void setpp(pn x, pn pp) { if(x!=nil) x->pp = pp; }  // LCT
inline void push(pn x) {
  if (x->rev) { rev(x->l); rev(x->r); x->rev=0; }                  //REV
  setpp(x->l, x->pp); setpp(x->r, x->pp);  // LCT
  //modifyNode(x->l, x->lazy); modifyNode(x->r, x->lazy); x->lazy=0; RMQ
}
//%%== call pushTo before using node if ancestor may have unpushed lazy
void pushTo(pn c) { if (c->p != nil) pushTo(c->p); push(c); }
//%%== Core splay tree code (rotate, splay, delete)
inline void rot(pn x) { pn p = x->p; push(p); push(x); bool d=x->dir();
  p->setc(d ? x->l : x->r, d); p->p->setc(x, p->dir()); x->setc(p, !d);
  pull(p); pull(x); }
// splays node x until it is a child of node to
pn splay(pn x, pn to=nil) { if (x!=nil) { while (x->p!=to) {
  if (x->p->p!=to) rot(x->dir() == x->p->dir() ? x->p : x); rot(x); } }
  return x; }
pn del(pn y) { pn x=splay(y)->r; if (x==nil) x=y->l; else {
  while (push(x), x->l != nil) x = x->l; splay(x,y)->setc(y->l,0); }
  x->p=nil; pull(x); return x; }
//%%== BST methods (lb, find, insert) (conflicts with other features)
pn lb(pn c, ll k) { if (c == nil) return c; // c MUST BE THE ROOT
  push(c); if (c->key>=k) { pn l=lb(c->l,k); return l==nil?c:l; }
  return lb(c->r,k); }
pn lowerBound(pn ref, ll k) { return lb(splay(ref), k); }
pn find(pn c, ll k) { c=lb(splay(c),k); return c->key!=k?nil:splay(c); }
pn insert(pn c, pn x) { if (splay(c)==nil) return x; ll k=x->key; pn p;
  while (c!=nil) { push(c); p=c; c=(p->key>k?p->l:p->r); }
  p->setc(x,p->key<=k); return splay(x); }
//%%== Utility code (rank, nth order statistic; requires cnt maintained)
int idx(pn x) { return splay(x)->l->cnt; } // rank; for sz, remove '->l'
pn nth(pn c, int n) {splay(c); while(c!=nil) { push(c); int l=c->l->cnt;
  if (n==l) break; if (n < l) c = c->l; else n = n-l-1, c = c->r; }
  return c; }
//%%== Iterator-based access, returns nil when iterator exhausted
pn first(pn c) { if (splay(c) != nil)
  while (push(c), c->l != nil) c=c->l; return splay(c); }
pn last(pn c) { if (splay(c) != nil)
  while (push(c), c->r != nil) c=c->r; return splay(c); }
pn prv(pn x) { if (splay(x)->l == nil) return nil; x = x->l;
  while (push(x), x->r != nil) x = x->r; return x; }
pn nxt(pn x) { if (splay(x)->r == nil) return nil; x = x->r;
  while (push(x), x->l != nil) x = x->l; return x; }
//%%== Iterator-based insert, does NOT work with BST unless key sorted
pn insertBefore(pn c, pn at, pn x) { // to insert "last", use at=nil
  if (at==nil) { if (splay(c)!=nil) last(c)->setc(x,1); }
  else { pn p=prv(at); if (p==nil) at->setc(x,0); else p->setc(x,1); }
  return splay(x); }
//%%== Range query/update operations by iterator, range is EXCLUSIVE!
pn range(pn c, pn l, pn r) { if (l == nil) {
  if (r == nil) return splay(c); return splay(r)->l; }
  if (l == r) return nil; splay(l);
  if (r == nil) return l->r; return splay(r,l)->l;}
ll pQuery(pn x) { return splay(x)->val; }
ll rQuery(pn c, pn l, pn r) { return range(c, l, r)->acc; }
void pUpdate(pn x, ll v) { splay(x)->val += v; pull(x); }          //RMQ
void rUpdate(pn c, pn l, pn r, ll v) {
  pn u = range(c, l, r); modifyNode(u, v); splay(u); }
//%%== Rope operations: split and merge, nil = right end
pn splitBefore(pn x) { if (splay(x)==nil) return nil;
  push(x); if (x->l!=nil) push(x->l);
  pn ret=x->l; x->l=x->l->p=nil; pull(ret); pull(x); return ret; }
pn append(pn l, pn r) { if (splay(l) == nil) return r;
  if (splay(r) == nil) return l; pn x = splay(last(l)); push(x);
  push(r); x->setc(r,1); pull(x->r); pull(x); return x; }

struct LinkCutTree { vector<pn> nds;
	LinkCutTree(int n=0) { init(n); }
  void init(int n) { nds.resize(n, nil);
    for(int i=0;i<n;i++) nds[i] = new_node(i); }
  pn splitAfter(pn x) { push(x); push(x->r); pn bot = x->r;
    x->r = x->r->p = nil; pull(bot); pull(x); return bot; }
	void join(pn l, pn r) { pn x = splay(first(r)); x->pp = l->pp;
		push(x); push(splay(l)); x->setc(l,0); pull(x->l); pull(x); }
  pn access(pn x) { if(splay(x)->r != nil) { splitAfter(x)->pp = x; }
    for(pn w=x; pull(w), splay(w=x->pp)!=nil; splay(x)) {
      if(w->r!=nil) { splitAfter(w)->pp=w; } join(w,x); } return x; }
  void link(int x, int y) { join(access(nds[y]), reroot(nds[x])); }
  void cut(int x, int y) { reroot(nds[x]); access(nds[y]);
		splitAfter(splay(nds[x]))->pp = nil; }
  int lca(int x, int y) { return lca(nds[x], nds[y])->key; }
  pn lca(pn x, pn y) { access(x); access(y); splay(x);
    return (x->pp == nil ? x : x->pp); }
  void reroot(int x) { reroot(nds[x]); }
  pn reroot(pn x) { rev(access(x)); push(x); return x; }
  int findroot(int x) { return findroot(nds[x])->key; }
  pn findroot(pn x) { return first(access(x)); }

  void insert_path(int x, int y, ll v) {
    reroot(nds[x]); access(nds[y]); rUpdate(nds[x], nil, nil, v); }
  ll query_path(int x, int y) { reroot(nds[x]); access(nds[y]);
    return rQuery(nds[x], nil, nil); }
  void insert_node(int x, ll v) { pUpdate(nds[x], v); }
  ll query_node(int x) { return pQuery(nds[x]); }
}; }


./content/data-structures/SplayTree.h
/**
 * Description: A powerful self-balancing binary search tree.
 *  Must \texttt{splay()} every constant number of accesses to maintain the amortized bound.
 *  Note some operations do not splay.
 * Time: O(\log n) amortized all operations
 * Usage:
 *  construct nodes with new_node(constructor params)
 *  node ids are assigned starting at 1; node 0 is nil
 *  Before accessing children, push() lazy; after updating children, pull() changes
 * Status: tested SPOJS CERC07S, TWIST, ORDERSET, GSS6, SEQ2; cf102001B
 */

#pragma once

/// Extended Documentation (benchmarks untested after change by henryx)
///
/// There is a special nil node pointer - this is NOT the NULL pointer
/// Make sure you initialize and compare to nil and not NULL or 0
///
/// Create new tree:   the nodes should keep track of themselves
/// Create new node:   pn x = new_node(constructor params);
/// NOTE: for func(pn c, ...), c is the reference node for the splay tree, 
///       ie. c is any node in the splay tree. 
///
/// BST Methods
///
///   lb     = find first node with key >= k, returns nil if all keys < k
///   find   = find first node with key == k, returns nil if all keys != k
///   insert = BST insertion, ordered by key
///
///   lb() does NOT splay, find() and insert() DO splay
///   Duplicate keys are inserted from left to right (i.e. copy 1, copy 2, ...)
///
/// Order statistics / random access iterator
///
///   rank   = return rank of the node = # nodes before it
///   nth    = find node with rank n   = find node with n nodes before it
///
///   rank() and nth() are 0-indexed
///   nth() returns nil if out of range
///
///   rank() splays but nth() does NOT splay
///
/// Ordered traversal with iterator (= pointer to node)
///
///   In order traversal (ref is a node in the splay tree):
///     for (pn cur = first(ref); cur != nil; cur = nxt(cur)) {...}
///
///   Reverse order traversal (ref is a node in the splay tree):
///     for (pn cur = last(ref); cur != nil; cur = prv(cur)) {...}
///
///   Calling del() on iterator invalidates it: prev(), nxt() stop working
///   Calling prv(x)/nxt(x) will splay(x) but not splay the returned node
///   first() and last() do NOT splay
///
/// Insertion at iterator (i.e. random insertion)
///
///   insertBefore(ref, nth(ref, 15), x);         // x is now rank 15
///
/// Range query: implemented here is range min query and range sum update
///              but query interval is *open* / *exclusive* on BOTH ends
///
///   TODO: update to use ref
///   tree.rUpdate(nth(a-1), nth(b+1), 100); // +100 to all nodes in [a, b]
///   tree.rQuery(nth(a-1), nth(b+1));       // query min val of nodes in [a, b]
///   tree.rQuery(prv(lb(x)), lb(y+1));      // get min val of keys in [x, y]
///   tree.range(prv(lb(x)), lb(y+1))->cnt;  // count number of keys in [x, y]
///
///   Point update and point query are faster with pUpdate() / pQuery()
///
///   push() is for pushing lazy propagating property down
///   pull() is to update node based on its value + child
///
///   Each node represents both a single node and a range of nodes,
///   so merging in e.g. pull() is a 3-way merge of: left, mid, right
///
///   IMPORTANT: you need to edit rev() if you use it and
///              your val/acc/lazy changes when order is reversed
///              (e.g. if you store prefix/suffix sum, etc)
///
/// Reversing nodes in a sub-range
///
///   rev(range(ref, nth(ref, a-1), nth(ref, b+1))); // reverse nodes in [a, b]
///
/// Rope operations (cut and merge)
///
///   pn leftHalf = splitBefore(ref, x);  // cuts out all nodes >= x
///   append(leftHalf, rightHalf);        // merge rightHalf into leftHalf
///
/// Field dependence of features
///
/// Feature \ Field    key  val  cnt  lazy  acc  rev   Description
/// rot/splay/del                                      Basic splay tree ops
/// lb/find/insert      x                              BST operations
/// rank/nth                      x                    Order statistics
/// iterators                                          In-order access & insert
/// range query/update       x          x    x         Range tree ops with lazy
/// reverse subtree                               x    Reverse node ordering
/// rope operations                                    Split and merge trees
///
/// Update method                pull  push pull push
///
/// Splay tree internals
///
///   Each node keeps pointer to parent, left child, right child
///   dir() is 1 if this node is right child of parent
///   setc() sets a node to be child of this, 0 for left child, 1 for right
///
///   Before accessng children, MUST call push() to push down lazy updates
///   After modifying node OR children, MUST splay() or pull() up changes
///
/// Benchmarks for random range min query + range sum update
///
/// 10^5 range query + 10^5 range update on 2*10^5 nodes, CS490-2016W2-A4B
///   Full feature tree + nth() for indexing:        0.750 seconds  ~3.75x time
///   Full feature tree + direct indexing in data[]: 0.600 seconds  ~3.00x time
///   Keep only val/lazy/acc fields + direct index:  0.520 seconds  ~2.60x time
///   ARQBIT:                                        0.200 seconds
/// TODO: these times may not be accurate anymore
///
/// THANKS JASON!
///

struct node; using pn = node*;
struct node { pn l, r, p; ll key, val, cnt, lazy, acc; bool rev;
  node() = default; node(ll k, ll v);
  inline int dir() { return this == p->r; }
  inline void setc(pn c, bool right) { (right?r:l) = c; c->p = this; }
} dat[N];
pn nil=[](){pn x=dat; x->l=x->r=x->p=x;/*x->acc=INF;*/return x;}();//RMQ
node::node(ll k, ll v): l(nil), r(nil), p(nil),
  key(k), val(v), cnt(1), lazy(0), acc(v), rev(0) {}
int nodeid = 0; template <class... T> pn new_node(T&& ...args) {
  return &(dat[++nodeid] = node(forward<T>(args)...)); }

namespace SplayTree {
//%%== Code for upwards propagating property (eg. count, min)
inline void pull(pn x) { if (x != nil) {
  x->cnt = 1 + x->l->cnt + x->r->cnt;
  /*x->acc = min(x->l->acc, min(x->val, x->r->acc));*/ } }         //RMQ
//%%== Code for lazy propagating property (eg. reverse subtree, add)
void rev(pn x) { if (x != nil) { x->rev ^= 1; swap(x->l, x->r); } }
inline void modifyNode(pn x, ll v) { if (x != nil) {
  /*x->val += v; x->acc += v; x->lazy += v;*/ } }                  //RMQ
inline void push(pn x) {
  //if (x->rev) { rev(x->l); rev(x->r); x->rev=0; }                  REV
  //modifyNode(x->l, x->lazy); modifyNode(x->r, x->lazy); x->lazy=0; RMQ
}
//%%== call pushTo before using node if ancestor may have unpushed lazy
void pushTo(pn c) { if (c->p != nil) pushTo(c->p); push(c); }
//%%== Core splay tree code (rotate, splay, delete)
inline void rot(pn x) { pn p = x->p; push(p); push(x); bool d=x->dir();
  p->setc(d ? x->l : x->r, d); p->p->setc(x, p->dir()); x->setc(p, !d);
  pull(p); pull(x); }
// splays node x until it is a child of node to
pn splay(pn x, pn to=nil) { if (x!=nil) { while (x->p!=to) {
  if (x->p->p!=to) rot(x->dir() == x->p->dir() ? x->p : x); rot(x); } }
  return x; }
pn del(pn y) { pn x=splay(y)->r; if (x==nil) x=y->l; else {
  while (push(x), x->l != nil) x = x->l; splay(x,y)->setc(y->l,0); }
  x->p=nil; pull(x); return x; }
//%%== BST methods (lb, find, insert) (conflicts with other features)
pn lb(pn c, ll k) { if (c == nil) return c; // c MUST BE THE ROOT
  push(c); if (c->key>=k) { pn l=lb(c->l,k); return l==nil?c:l; }
  return lb(c->r,k); }
pn lowerBound(pn ref, ll k) { return lb(splay(ref), k); }
pn find(pn c, ll k) { c=lb(splay(c),k); return c->key!=k?nil:splay(c); }
pn insert(pn c, pn x) { if (splay(c)==nil) return x; ll k=x->key; pn p;
  while (c!=nil) { push(c); p=c; c=(p->key>k?p->l:p->r); }
  p->setc(x,p->key<=k); return splay(x); }
//%%== Utility code (rank, nth order statistic; requires cnt maintained)
int idx(pn x) { return splay(x)->l->cnt; } // rank; for sz, remove '->l'
pn nth(pn c, int n) {splay(c); while(c!=nil) { push(c); int l=c->l->cnt;
  if (n==l) break; if (n < l) c = c->l; else n = n-l-1, c = c->r; }
  return c; }
//%%== Iterator-based access, returns nil when iterator exhausted
pn first(pn c) { if (splay(c) != nil)
  while (push(c), c->l != nil) c=c->l; return splay(c); }
pn last(pn c) { if (splay(c) != nil)
  while (push(c), c->r != nil) c=c->r; return splay(c); }
pn prv(pn x) { if (splay(x)->l == nil) return nil; x = x->l;
  while (push(x), x->r != nil) x = x->r; return x; }
pn nxt(pn x) { if (splay(x)->r == nil) return nil; x = x->r;
  while (push(x), x->l != nil) x = x->l; return x; }
//%%== Iterator-based insert, does NOT work with BST unless key sorted
pn insertBefore(pn c, pn at, pn x) { // to insert "last", use at=nil
  if (at==nil) { if (splay(c)!=nil) last(c)->setc(x,1); }
  else { pn p=prv(at); if (p==nil) at->setc(x,0); else p->setc(x,1); }
  return splay(x); }
//%%== Range query/update operations by iterator, range is EXCLUSIVE!
pn range(pn c, pn l, pn r) { if (l == nil) {
  if (r == nil) return splay(c); return splay(r)->l; }
  if (l == r) return nil; splay(l);
  if (r == nil) return l->r; return splay(r,l)->l;}
ll pQuery(pn x) { return splay(x)->val; }
ll rQuery(pn c, pn l, pn r) { return range(c, l, r)->acc; }
void pUpdate(pn x, ll v) { splay(x)->val += v; pull(x); }          //RMQ
void rUpdate(pn c, pn l, pn r, ll v) {
  pn u = range(c, l, r); modifyNode(u, v); splay(u); }
//%%== Rope operations: split and merge, nil = right end
pn splitBefore(pn x) { if (splay(x)==nil) return nil;
  push(x); if (x->l!=nil) push(x->l);
  pn ret=x->l; x->l=x->l->p=nil; pull(ret); pull(x); return ret; }
pn append(pn l, pn r) { if (splay(l) == nil) return r;
  if (splay(r) == nil) return l; pn x = splay(last(l)); push(x);
  push(r); x->setc(r,1); pull(x->r); pull(x); return x; } }


./content/data-structures/SubMatrix.h
/**
 * Date: 2014-11-28
 * Author: Johan Sannemo
 * License: CC0
 * Source: Folklore
 * Status: Tested on Kattis
 * Description: Calculate submatrix sums quickly, given upper-left and lower-right corners (half-open).
 * Usage:
 * SubMatrix<int> m(matrix);
 * m.sum(0, 0, 2, 2); // top left 4 elements
 * Time: O(N^2 + Q)
 */
#pragma once

template<class T>
struct SubMatrix {
	vector<vector<T>> p;
	SubMatrix(vector<vector<T>>& v) {
		int R = sz(v), C = sz(v[0]);
		p.assign(R+1, vector<T>(C+1));
		rep(r,0,R) rep(c,0,C)
			p[r+1][c+1] = v[r][c] + p[r][c+1] + p[r+1][c] - p[r][c];
	}
	T sum(int u, int l, int d, int r) {
		return p[d][r] - p[d][l] - p[u][r] + p[u][l];
	}
};


./content/data-structures/Treap.h
/**
 * Author: luccasiau
 * Description: A short self-balancing tree. It acts as a
 *  sequential container with log-time splits/joins, and
 *  is easy to augment with additional data.
 * Usage:
 *  - Put all the info that you need to save on the node
 *  - Update the update (might be helpful to create helper functions like count)
 *  - rand() is being used, so remember to initialize the seed
 *  - Create a node with new node(value, rand())
 *  - Empty treap is NULL node pointer
 *  - To delete, pass a node with the same value (random priority)
 * Time: $O(\log N)$
 * Status: tested SPOJ TREAP, ORDERSET; CF62D, Kattis GCPC, OBI15P2F2, SPOJ GSS6, TWIST, CERC07S
 */
#pragma once

// COMMON FUNCTIONS FOR REGULAR AND IMPLICIT TREAP ---------------------
struct node{ node *l, *r; int v, p, lazy, count; // regular & implicit
  node(int v_=0, int p_=0){ l=r=NULL; v=v_; p=p_; lazy=0; count=1; } };
int count(node *x){ return (x == NULL)?0:x->count; } // regular&implicit
//change Lazy and Update for lazy-propagation (only use it in implicit)
void lazy(node *&x){ if(x == NULL) return; }
void update(node *&curr){ if (!curr) return; // regular & implicit
  curr->count = count(curr->l) + count(curr->r) + 1; lazy(curr); }
void merge(node *&curr, node *l, node *r){ // regular & implicit
  lazy(l); lazy(r); if(l == NULL || r == NULL) curr = (l == NULL)?r:l;
  else if( l->p < r->p ){ merge(r->l, l, r->l); curr = r;
  }else{ merge(l->r, l->r, r); curr = l; } update(curr); }
node* kth_element(node *&treap, int k){ // 1-indexed. Kth element from L to R
  lazy(treap); if(k - count(treap->l) == 1) return treap;
  if(k <= count(treap->l)) return kth_element(treap->l, k);
  return kth_element(treap->r, k - count(treap->l) - 1); }
// FUNCTIONS ONLY FOR REGULAR TREAP ------------------------------------
void split(node *curr, node *&l, node *&r, int key){ // regular
  if(curr == NULL){ l = r = NULL; return; }
  if(curr->v <= key){ split(curr->r, curr->r, r, key); l=curr;
  }else{ split(curr->l, l, curr->l, key); r=curr; } update(curr); }
void insert(node *&treap, node *x){ node *l=0,*r=0,*aux=0; // regular
  split(treap, l, r, x->v); merge(aux, l, x); merge(treap, aux, r); aux = NULL;}
void erase(node *&treap, int v){ node *l=0,*r=0,*l2=0,*r2=0;// regular
  split(treap, l, r, v); split(l, l2, r2, v-1); if(count(r2) > 1){
    merge(r2, r2->l, r2->r); merge(l2, l2, r2); } merge(treap, l2, r); }
bool isInTreap(node *treap, int x){ // regular | checks if x is in treap
  if(treap == NULL) return false; if(treap->v == x) return true;
  if(treap->v < x) return isInTreap(treap->r,x);
  return isInTreap(treap->l,x); }
// FUNCTIONS ONLY FOR IMPLICIT TREAP -----------------------------------
void splitImplicit(node *curr, node *&l, node *&r, int key){ // implicit
  lazy(curr); if(curr == NULL){ l = r = NULL; return; }
  if(count(curr->l) + 1 <= key){
    splitImplicit(curr->r,curr->r,r,key-count(curr->l)-1); l=curr;
  }else{splitImplicit(curr->l,l,curr->l,key); r=curr;}update(curr);}
// implicit | inserts node at pos (1-indexed)
void insertImplicit(node *&treap, node *x, int pos){
  lazy(treap); node *l=0,*r=0,*aux=0; splitImplicit(treap, l, r, pos-1);
  merge(aux, l, x); merge(treap, aux, r); aux = 0; }
void eraseImplicit(node *&treap, int pos){ // deletes node at pos
  lazy(treap); node *l=0,*r=0,*l2=0,*r2=0;
  splitImplicit(treap, l, r, pos); splitImplicit(l, l2, r2, pos-1);
  merge(treap, l2, r); l2 = r2 = l = r = NULL; }


./content/data-structures/UnionFind.h
/**
 * Author: Lukas Polacek
 * Date: 2009-10-26
 * License: CC0
 * Source: folklore
 * Description: Disjoint-set data structure.
 * Time: $O(\alpha(N))$
 */
#pragma once

struct UF {
	vi e;
	UF(int n) : e(n, -1) {}
	bool same_set(int a, int b) { return find(a) == find(b); }
	int size(int x) { return -e[find(x)]; }
	int find(int x) { return e[x] < 0 ? x : e[x] = find(e[x]); }
	bool join(int a, int b) {
		a = find(a), b = find(b);
		if (a == b) return false;
		if (e[a] > e[b]) swap(a, b);
		e[a] += e[b]; e[b] = a;
		return true;
	}
};


./content/geometry/3dHull.h
/**
 * Description: Computes all faces, surface area, volume of the 3-dimension hull of a point set.
 *  All faces will point outwards. Code shifts points to near the origin, add base to unshift.
 * Time: O(n^2)
 * Status: tested SPOJ/CH3D, kattis/categorymanipulation,worminapple,threedprinter
 */
#pragma once

#include "Point3D.h"

namespace Hull3 { // change shift and mask values for >1024 verts
  const int S = 10; const int M = (1<<S) - 1;
  struct face{int a, b, c;};
  struct vert{p3d v; int i; operator p3d() const { return v; } };
  vector<face> faces; vector<vert> v; p3d base;
  ld dist(const face& f, const p3d& p) {
    return dot(cross(v[f.b]-v[f.a], v[f.c]-v[f.b]), p-v[f.a]); }
  ld area(const face& f) {
    return abs(cross(v[f.b]-v[f.a], v[f.c]-v[f.a])); }
  ld volume(const face& f) { p3d n=cross(v[f.b]-v[f.a], v[f.c]-v[f.b]);
    return area(f)*dot(n/abs(n), v[f.a])/6; }
  void convex_hull_clean_input(const vector<p3d>& _v) { int n=_v.size();
    v.resize(n); for(int i=0; i<n; i++) v[i] = {_v[i], i};
    shuffle(v.begin(), v.end(), rng);
    base = v[0]; for(int i=0; i<n; i++) v[i].v = v[i] - base;
    for(int i=1;i<n;i++) if(abs(v[i])>EPS) { swap(v[i],v[1]); break; }
    for(int i=2;i<n;i++) if(abs(cross(v[1], v[i])) > EPS) {
      swap(v[i], v[2]); break; }
    for(int i=3; i<n; i++) if(abs(dot(cross(v[1], v[2]), v[i])) > EPS) {
      swap(v[i], v[3]); break; } }
  void build(const vector<p3d>& _v) {
    convex_hull_clean_input(_v); int n = v.size();
    vector<face> f { {0, 1, 2}, {2, 1, 0} };
    for(int i=3; i<n; i++) { vector<face> nxt; set<int> edge;
      for(auto ff : f) { // remove the faces
        if(dist(ff, v[i]) > EPS) { // above
          edge.insert((ff.a << S) | ff.b);
          edge.insert((ff.b << S) | ff.c);
          edge.insert((ff.c << S) | ff.a);
        } else nxt.push_back(ff); }
      for(auto e : edge) { if(!edge.count(((e & M) << S) | (e >> S)))
        nxt.push_back(face{e >> S, e & M, i}); }
      f = nxt; } faces = f;
    //ld ar=0, vo=0; for (auto ff : f) ar += area(ff), vo += volume(ff);
  }
}


./content/geometry/Angle.h
/**
 * Description: Sorts points CCW starting from positive x-axis, does not handle (0, 0)
 * Usage: sort(pts.begin(), pts.end(), cmp_ang);
 */
#pragma once

#include "GeometryPrimitives.h"

const pt orig(0, 0);
bool cmp_ang(const pt& a, const pt& b) {
  bool aorig = cmp_lex_i(orig, a), borig = cmp_lex_i(orig, b);
  if (aorig ^ borig) return aorig; else return cp(a-orig, b-orig) > 0; }


./content/geometry/CircleConvexHull.h
/**
 * Description: Convex hull of circles.
 * Status: tested on UVa
 */
#pragma once

#include "GeometryPrimitives.h"
#include "CircleTangent.h"

const ld far = 1e10; // can't be too big or precision error
pt center[MAXN]; ld radius[MAXN]; int V; // # of circles
// true if circle1 is in circle2
bool c_in_c(pt c1, ld r1, pt c2, ld r2) {
  ld d = abs(c1 - c2); return r1 - EPS <= r2 && d + r1 - EPS <= r2; }
// convex hull of circles
ld solve() { // find lowest point; and biggest circle
  pt lowest(far, far);
  // need 2nd point because we may touch the first circle TWICE
  int first = -1, second = -1;
  for (int i = 0; i < V; ++i) { pt low = center[i] - pt(0, radius[i]);
    if (cmp_lex_i(low, lowest)) { lowest = low; first = i; }
    else if (abs(low - lowest) < EPS &&
      c_in_c(center[first],radius[first],center[i],radius[i])) first=i;}
  ld perim = 0; pt left(-far, lowest.imag()), right(far, lowest.imag());
  pt A = left, B = lowest; int i = first;
  while (true) { // tangents are A-B C-D, B and C lie on the same circle
    pt C = A, D = B; int nxt = i; ld nxt_angle = 1e9;
    for (int j = 0; j < V; ++j) { if (i == j) continue;
      // check if inside current circle
      if(c_in_c(center[j], radius[j], center[i], radius[i])) continue;
      // bot-bot since we are doing counter clockwise
      // tangent.first lies on first circle etc.
      auto t=circle_tangent(center[i],radius[i],center[j],radius[j],1);
      ld angle=atan2(cp(B-A,t.second-t.first),dp(B-A,t.second-t.first));
      if (angle < -EPS) angle += PI * 2;
      if (angle + EPS < nxt_angle) { nxt_angle = angle; nxt = j;
        C = t.first; D = t.second; } }
    if (nxt == i) { perim += radius[i] * PI * 2; break; }
    if (i == first && second == -1) second = nxt;
    else if (i == first && second == nxt) { // done,calculate last angle
      perim += radius[i] * nxt_angle; break; }
    else perim += radius[i] * nxt_angle;
    perim += abs(C - D); A = C; B = D; i = nxt; } return perim; }


./content/geometry/CircleIntersection.h
/**
 * Description: Computes the pair of points at which two circles intersect. Returns number of intersections.
 * Status: tested UVa 453
 */
#pragma once

int cc_inter(pt p1, ld r1, pt p2, ld r2, pt &i1, pt &i2) {
  ld dq=norm(p1-p2), rq=r1*r1-r2*r2;
  pt c=(p1+p2)*0.5L + (p2-p1)*rq*0.5L/dq;
  ld dt=2.0*dq*(r1*r1+r2*r2)-dq*dq-rq*rq;
  if(dt < -EPS) return 0; else if(dt < EPS) { i1=i2=c; return 1; }
  dt=sqrt(dt)*0.5/dq; i1=c+(p2-p1)*pt(0,1)*dt; i2=c-(p2-p1)*pt(0,1)*dt;
  return 2; }


./content/geometry/CircleIntersectionArea.h
/**
 * Description: returns area of intersection of 2 circles.
 * Status: untested
 */

#pragma once

ld cc_area(pt p1, ld r1, pt p2, ld r2) {
  if(r2 < r1) swap(p1, p2), swap(r1, r2);
  ld d = abs(p2 - p1); if (d + r1 < r2 + EPS) return r1*r1*PI;
  if (d >= r1 + r2) return 0;
  ld dA = (d*d + r1*r1 - r2*r2)/d/2, dB = d-dA;
  return r1*r1*acos(dA/r1) - dA*sqrt(r1*r1-dA*dA)
       + r2*r2*acos(dB/r2) - dB*sqrt(r2*r2-dB*dB); }


./content/geometry/CircleTangent.h
/**
 * Description: Returns tangent line between two circles. Also works for points. CAUTION: INTERSECTION IS BAD
 * Status: tested Chicago2012-H
 * Usage: k=0 top-top, k=1 bot-bot, k=2 top-bot, k=3 bot-top. 
 */

#pragma once

pair<pt, pt> circle_tangent(ld r1, ld r2, ld d, int k) { // use below fn
  ld dr = (k & 2) ? (-r1-r2) : (r2-r1); ld t = asin(dr / d);
  pt p1=polar(r1, PI/2+t), p2=polar(r2, PI/2+t); if(k&2) p2*=-1;
  p2+=pt(d,0);
  if(k&1){ p1=pt(p1.real(),-p1.imag()); p2=pt(p2.real(),-p2.imag()); }
  return make_pair(p1, p2); }
pair<pt, pt> circle_tangent(pt p1, ld r1, pt p2, ld r2, int k) {
  // translate/rotate so c1 at (0,0), c2 at x-axis
  pt d = p2-p1; auto p = circle_tangent(r1,r2,abs(d),k); d /= abs(d);
  p.first *= d; p.second *= d; p.first += p1; p.second += p1; return p;}


./content/geometry/ClosestPair.h
/**
 * Description: Finds the closest pair of points. Assumes v.size() >= 2.
 * Time: O(n \log n)
 * Status: Tested UVa 10245, 11378
 */
#pragma once

#include "GeometryPrimitives.h"
pair<pt, pt> closest_pair(vector<pt> v) {
  sort(v.begin(), v.end(), cmp_lex);
  ld best = 1e99; auto low = 0u; pair<pt, pt> bestpair;
  set<pt, bool(*)(const pt&,const pt&)> help(cmp_lex_i);
  for(auto i = 0u; i < v.size(); i++) {
    while(low < i && (v[i] - v[low]).real() > best)help.erase(v[low++]);
    for(auto it = help.lower_bound(v[i] - pt(1e99, best));
          it != help.end() && (*it - v[i]).imag() < best; it++)
      if (abs(*it - v[i]) < best)
        best = abs(*it - v[i]), bestpair = make_pair(*it, v[i]);
    help.insert(v[i]); }
  return bestpair; }


./content/geometry/ConvexHull.h
/**
 * Description: Returns the convex hull of p in ccw order. Assumes CH is not a line.
 * Status: tested SPOJ BSHEEP, UVA 11096
 * Time: O(n \log n)
*/
#pragma once

#include "GeometryPrimitives.h"
pol chull(pol p) {
  sort(p.begin(), p.end(), cmp_lex_i); int top=0, bot=1, n=p.size();
  pol ch(2*n); for (int i = 0, d = 1; i < n && i >= 0; i += d) {
    // If no duplicates, can change <= 0 to < 0 to keep redundant points
    while (top>bot && cp(ch[top-1]-ch[top-2], p[i]-ch[top-2])<=0) top--;
    ch[top++] = p[i]; if (i == n-1) d = -1, bot = top;
  } ch.resize(max(1, top-1)); return ch; }


./content/geometry/CustomComplex.h
/**
 * Description: Fast handwritten complex number class; about
 * $4 \times$ faster than std::complex.
 * Status: tested PacNW2013J Phuket2016G CHICAGO 2012H
 */
#pragma once

namespace CustomComplex {
template<class T> struct cplx {
  T x, y; cplx(T nx=0, T ny=0): x(nx), y(ny) {}
  cplx operator+(const cplx &c) const { return {x+c.x, y+c.y}; }
	cplx operator-(const cplx &c) const { return {x-c.x, y-c.y}; }
  cplx operator*(const cplx &c) const {
    return {x*c.x-y*c.y, x*c.y+y*c.x}; }
  cplx& operator*=(const cplx &c) {
    return *this={x*c.x-y*c.y, x*c.y+y*c.x}; }
  // Only supports right scalar multiplication like p*c
  template<class U> cplx operator*(const U &c) const {return {x*c,y*c};}
  template<class U> cplx operator/(const U &c) const {return {x/c,y/c};}
  bool operator<(const cplx& o) const {return tie(x,y)<tie(o.x,o.y);} };
#define polar(r,a)  (pt){r*cos(a),r*sin(a)}
using pt = cplx<ld>;
using pol = vector<pt>;
/// for left mult. c*p
pt operator*(ld c, const pt p) { return {p.x*c,p.y*c};}
/// useful for debugging
ostream& operator<<(ostream &o,const pt &p) {
  return o<<"("<<p.x<<","<<p.y<<")"; }
ld cp(const pt& a, const pt& b) { return a.x*b.y - b.x*a.y; }
ld dp(const pt& a, const pt& b) { return a.x*b.x + a.y*b.y; }
inline ld norm(const pt& a) { return a.x*a.x + a.y*a.y; }
inline ld abs(const pt &a) {return sqrt(a.x*a.x + a.y*a.y);}
inline ld arg(const pt &a) {return atan2(a.y,a.x);}
ld ang(const pt &a, const pt &b, const pt &c) {
	return atan2(cp(a-b,b-c),dp(a-b,b-c)); }
inline bool cmp_lex(const pt& a, const pt& b) {
  return a.x<b.x-EPS||(a.x<b.x+EPS&&a.y<b.y-EPS);}
inline bool cmp_lex_i(const pt& a, const pt& b) {
  return a.y<b.y-EPS||(a.y<b.y+EPS&&a.x<b.x-EPS);}
}


./content/geometry/DelaunayFast.h
/**
 * Author: Philippe Legault
 * Date: 2016
 * License: MIT
 * Source: https://github.com/Bathlamos/delaunay-triangulation/
 * Description: Fast Delaunay triangulation.
 * Each circumcircle contains none of the input points.
 * There must be no duplicate points.
 * If all points are on a line, no triangles will be returned.
 * Should work for doubles as well, though there may be precision issues in 'circ'.
 * Returns triangles in order \{t[0][0], t[0][1], t[0][2], t[1][0], \dots\}, all counter-clockwise.
 * Time: O(n \log n)
 * Status: fuzz-tested
 */
#pragma once

#include "Point.h"

typedef Point<ll> P;
typedef struct Quad* Q;
typedef __int128_t lll; // (can be ll if coords are < 2e4)
P arb(LLONG_MAX,LLONG_MAX); // not equal to any other point

struct Quad {
	bool mark; Q o, rot; P p;
	P F() { return r()->p; }
	Q r() { return rot->rot; }
	Q prev() { return rot->o->rot; }
	Q next() { return r()->prev(); }
};

bool circ(P p, P a, P b, P c) { // is p in the circumcircle?
	lll p2 = p.dist2(), A = a.dist2()-p2,
	    B = b.dist2()-p2, C = c.dist2()-p2;
	return p.cross(a,b)*C + p.cross(b,c)*A + p.cross(c,a)*B > 0;
}
Q makeEdge(P orig, P dest) {
	Q q[] = {new Quad{0,0,0,orig}, new Quad{0,0,0,arb},
	         new Quad{0,0,0,dest}, new Quad{0,0,0,arb}};
	rep(i,0,4)
		q[i]->o = q[-i & 3], q[i]->rot = q[(i+1) & 3];
	return *q;
}
void splice(Q a, Q b) {
	swap(a->o->rot->o, b->o->rot->o); swap(a->o, b->o);
}
Q connect(Q a, Q b) {
	Q q = makeEdge(a->F(), b->p);
	splice(q, a->next());
	splice(q->r(), b);
	return q;
}

pair<Q,Q> rec(const vector<P>& s) {
	if (sz(s) <= 3) {
		Q a = makeEdge(s[0], s[1]), b = makeEdge(s[1], s.back());
		if (sz(s) == 2) return { a, a->r() };
		splice(a->r(), b);
		auto side = s[0].cross(s[1], s[2]);
		Q c = side ? connect(b, a) : 0;
		return {side < 0 ? c->r() : a, side < 0 ? c : b->r() };
	}

#define H(e) e->F(), e->p
#define valid(e) (e->F().cross(H(base)) > 0)
	Q A, B, ra, rb;
	int half = sz(s) / 2;
	tie(ra, A) = rec({all(s) - half});
	tie(B, rb) = rec({sz(s) - half + all(s)});
	while ((B->p.cross(H(A)) < 0 && (A = A->next())) ||
	       (A->p.cross(H(B)) > 0 && (B = B->r()->o)));
	Q base = connect(B->r(), A);
	if (A->p == ra->p) ra = base->r();
	if (B->p == rb->p) rb = base;

#define DEL(e, init, dir) Q e = init->dir; if (valid(e)) \
		while (circ(e->dir->F(), H(base), e->F())) { \
			Q t = e->dir; \
			splice(e, e->prev()); \
			splice(e->r(), e->r()->prev()); \
			e = t; \
		}
	for (;;) {
		DEL(LC, base->r(), o);  DEL(RC, base, prev());
		if (!valid(LC) && !valid(RC)) break;
		if (!valid(LC) || (valid(RC) && circ(H(RC), H(LC))))
			base = connect(RC, base->r());
		else
			base = connect(base->r(), LC->r());
	}
	return { ra, rb };
}

vector<P> triangulate(vector<P> pts) {
	sort(all(pts));  assert(unique(all(pts)) == pts.end());
	if (sz(pts) < 2) return {};
	Q e = rec(pts).first;
	vector<Q> q = {e};
	int qi = 0;
	while (e->o->F().cross(e->F(), e->p) < 0) e = e->o;
#define ADD { Q c = e; do { c->mark = 1; pts.push_back(c->p); \
	q.push_back(c->r()); c = c->next(); } while (c != e); }
	ADD; pts.clear();
	while (qi < sz(q)) if (!(e = q[qi++])->mark) ADD;
	return pts;
}


./content/geometry/DelaunayHenry.h
/**
 * Author: Henry Xia
 * Date: 2018
 * Description: Sketch Delaunay triangulation. No idea when this works.
 * returns the Delaunay Triangulation as triples of indices
 * Time: O(\text{very}~n^2)
 * Status: Tested WF2018G
 */
#pragma once

pt circumcenter(const pt& A, const pt& B, const pt& C) {
  ld a = norm(B-C), b = norm(C-A), c = norm(A-B);
  ld fa = a*(b+c-a), fb = b*(c+a-b), fc = c*(a+b-c);
  return (fa*A + fb*B + fc*C) / (fa+fb+fc);
}

struct Tuple { vector<int> v;
  Tuple() {}
  Tuple(int a, int b) { v={a,b}; sort(v.begin(), v.end()); }
  Tuple(int a, int b, int c) { v={a,b,c}; sort(v.begin(),v.end()); }
  bool operator == (const Tuple& t) const { return v == t.v; }
  int operator [] (int i) const { return v[i]; }
};

namespace std {
  template<> struct hash<Tuple> {
    size_t operator () (const Tuple& t) const {
      size_t h = 0;
      for (int i = 0; i < t.v.size(); i++)
        h ^= hash<int>()(t[i]<<(10*i)); //?????
      return h; } };
}

vector<Tuple> delaunay(vector<pt> p) {
  int n = p.size();
  p.push_back(pt(INF,INF));
  p.push_back(pt(INF,-INF));
  p.push_back(pt(-INF,0));

  unordered_map<Tuple,int> cnt;
  unordered_set<Tuple> cur;
  cur.insert(Tuple(n, n+1, n+2));
  for (int i = 0; i < n; i++) {
    vector<Tuple> border; // edge
    vector<Tuple> bad; // triangle
    cnt.clear();
    for (const Tuple& tri : cur) {
      pt cc = circumcenter(p[tri[0]], p[tri[1]], p[tri[2]]);
      if (abs(p[i]-cc) < abs(p[tri[0]]-cc)) {
        bad.push_back(tri);
        for (int j = 0; j < 3; j++) {
          cnt[Tuple(tri[j], tri[(j+1)%3])]++; } } }
    for (const Tuple& tri : bad) {
      for (int j = 0; j < 3; j++) {
        cur.erase(tri);
        if (cnt[Tuple(tri[j], tri[(j+1)%3])] == 1) {
          border.push_back(Tuple(tri[j], tri[(j+1)%3])); } } }
    for (const Tuple& e : border) { cur.insert(Tuple(i, e[0], e[1])); }
  }

  vector<Tuple> res;
  for (const Tuple& tri : cur) {
    if (tri[0] < n && tri[1] < n && tri[2] < n) res.push_back(tri);
  } return res;
}

// returns the voronoi vertices (UNTESTED) (for reference)
vector<pt> voronoi(const vector<pt>& p) {
  vector<Tuple> triangles = delaunay(p);
  vector<pt> res;
  for (const Tuple& t : triangles) {
    res.push_back(circumcenter(p[t[0]], p[t[1]], p[t[2]]));
  } return res;
}


./content/geometry/DelaunayTriangulation.h
/**
 * Author: Mattias de Zalenski
 * Date: Unknown
 * Source: Geometry in C
 * Description: Computes the Delaunay triangulation of a set of points.
 *  Each circumcircle contains none of the input points.
 *  If any three points are colinear or any four are on the same circle, behavior is undefined.
 * Status: fuzz-tested
 * Time: O(n^2)
 */
#pragma once

#include "Point.h"
#include "3dHull.h"

template<class P, class F>
void delaunay(vector<P>& ps, F trifun) {
	if (sz(ps) == 3) { int d = (ps[0].cross(ps[1], ps[2]) < 0);
		trifun(0,1+d,2-d); }
	vector<P3> p3;
	trav(p, ps) p3.emplace_back(p.x, p.y, p.dist2());
	if (sz(ps) > 3) trav(t, hull3d(p3)) if ((p3[t.b]-p3[t.a]).
			cross(p3[t.c]-p3[t.a]).dot(P3(0,0,1)) < 0)
		trifun(t.a, t.c, t.b);
}


./content/geometry/GeometryPrimitives.h
/**
 * Description: Geometry primitives.
 */
#pragma once

ld cp(const pt& a, const pt& b) { return imag(conj(a)*b); }
ld dp(const pt& a, const pt& b) { return real(conj(a)*b); }
// dist(const pt& a, const pt& b) ==> abs(a-b)
bool eq(const pt &a, const pt &b) { return abs(a-b) < EPS; }
int sgn(const ld& x) { return abs(x) < EPS ? 0 : x < 0 ? -1 : 1; }
bool cmp_lex(const pt& a, const pt& b) {
  return a.real()<b.real()-EPS
    ||  (a.real()<=b.real()+EPS && a.imag()<b.imag()-EPS); }
inline bool cmp_lex_i(const pt& a, const pt& b) {
  return a.imag()<b.imag()-EPS
    ||  (a.imag()<=b.imag()+EPS && a.real()<b.real()-EPS); }


./content/geometry/InsidePolygon.h
/**
 * Description: Returns true if p is inside polygon v. Setting \texttt{strict} to true excludes boundary.
 */
#pragma once

#include "GeometryPrimitives.h"
// Does NOT include points on the ends of the segment.
inline bool on_segment(const pt &a, const pt &b, const pt &p) {
  return abs(cp(b-a, p-a)) / abs(a-b) < EPS &&
    dp(b-a, p-a)>0 && dp(a-b, p-b)>0; }

// Checks if p lies on the boundary of a polygon v.
inline bool on_boundary(const pol &v, const pt &p) {
  bool res = 0; for(int i=v.size()-1, j=0; j<v.size(); i=j++) {
    res |= on_segment(v[i], v[j], p) || abs(p-v[i]) < EPS; }
  return res; }

// orientation does not matter !!!
bool pt_in_polygon(const pt &p, const pol &v, bool strict=false) {
  if (on_boundary(v,p)) return !strict;
  ld res = 0; for(int i = v.size() - 1, j = 0; j < v.size(); i = j++) {
    res += atan2(cp(v[i] - p, v[j] - p), dp(v[i] - p, v[j] - p)); }
  return abs(res) > 1; } // will be either 2*PI or 0


./content/geometry/LineHullIntersection.h
/**
 * Author: Oleksandr Bacherikov, chilli
 * Date: 2019-05-07
 * License: Boost Software License
 * Source: https://github.com/AlCash07/ACTL/blob/master/include/actl/geometry/algorithm/intersect/line_convex_polygon.hpp
 * Description: Line-convex polygon intersection. The polygon must be ccw and have no colinear points.
 * lineHull(line, poly) returns a pair describing the intersection of a line with the polygon:
 *  \begin{itemize*}
 *    \item $(-1, -1)$ if no collision,
 *    \item $(i, -1)$ if touching the corner $i$,
 *    \item $(i, i)$ if along side $(i, i+1)$,
 *    \item $(i, j)$ if crossing sides $(i, i+1)$ and $(j, j+1)$.
 *  \end{itemize*}
 *  In the last case, if a corner $i$ is crossed, this is treated as happening on side $(i, i+1)$.
 *  The points are returned in the same order as the line hits the polygon.
 * \texttt{extrVertex} returns the point of a hull with the max projection onto a line.
 * Status: fuzz-tested
 * Time: O(N + Q \log n)
 */
#pragma once

#include "Point.h"

typedef array<P, 2> Line;
#define cmp(i,j) sgn(dir.perp().cross(poly[(i)%n]-poly[(j)%n]))
#define extr(i) cmp(i + 1, i) >= 0 && cmp(i, i - 1 + n) < 0
int extrVertex(vector<P>& poly, P dir) {
	int n = sz(poly), lo = 0, hi = n;
	if (extr(0)) return 0;
	while (lo + 1 < hi) {
		int m = (lo + hi) / 2;
		if (extr(m)) return m;
		int ls = cmp(lo + 1, lo), ms = cmp(m + 1, m);
		(ls < ms || (ls == ms && ls == cmp(lo, m)) ? hi : lo) = m;
	}
	return lo;
}

#define cmpL(i) sgn(line[0].cross(poly[i], line[1]))
array<int, 2> lineHull(Line line, vector<P> poly) {
	int endA = extrVertex(poly, (line[0] - line[1]).perp());
	int endB = extrVertex(poly, (line[1] - line[0]).perp());
	if (cmpL(endA) < 0 || cmpL(endB) > 0)
		return {-1, -1};
	array<int, 2> res;
	rep(i,0,2) {
		int lo = endB, hi = endA, n = sz(poly);
		while ((lo + 1) % n != hi) {
			int m = ((lo + hi + (lo < hi ? 0 : n)) / 2) % n;
			(cmpL(m) == cmpL(endB) ? lo : hi) = m;
		}
		res[i] = (lo + !cmpL(hi)) % n;
		swap(endA, endB);
	}
	if (res[0] == res[1]) return {res[0], -1};
	if (!cmpL(res[0]) && !cmpL(res[1]))
		switch ((res[0] - res[1] + sz(poly) + 1) % sz(poly)) {
			case 0: return {res[0], res[0]};
			case 2: return {res[1], res[1]};
		}
	return res;
}


./content/geometry/Lines.h
/**
 * Description: Line operations and distances.
 */

#include "GeometryPrimitives.h"

// Intersection of non-parallel lines a -> b, c -> d.
pt line_inter(const pt &a, const pt &b, const pt &c, const pt &d) {
  return a + cp(c - a, d - c) / cp(b - a, d - c) * (b - a); }

// Projection of (a -> p) to vector (a -> b), SIGNED - positive in front
ld proj_dist(const pt &a, const pt &b, const pt &p) {
  return dp(b - a, p - a) / abs(b - a); }

// SIGNED distance. Pt on the right of vector (a -> b) will be NEGATIVE.
ld lp_dist(const pt &a, const pt &b, const pt &p) {
  return cp(b - a, p - a) / abs(b - a); }

// Line segment (a, b) to pt p distance.
ld lsp_dist(const pt &a, const pt &b, const pt &p) {
  return dp(b - a, p - a) > 0 && dp(a - b, p - b) > 0 ?
    abs(cp(b - a, p - a) / abs(b - a)) : min(abs(a - p), abs(b - p)); }

// Closest pt on line segment (a, b) to pt p.
pt lsp_closest(const pt &a, const pt &b, const pt &p) {
  if (dp(b - a, p - a) > 0 && dp(a - b, p - b) > 0)
    return abs(cp(b-a,p-a))<EPS ? p : line_inter(a,b,p,p+(a-b)*pt(0,1));
  return abs(a - p) < abs(b - p) ? a : b; }


./content/geometry/Miniball.h
/**
 * Description: Computes the minimum enclosing ball of a point set in arbitrary dimensions.
 * Source: adapted from http://www.inf.ethz.ch/personal/gaertner/miniball.html
 * Status: tested UVa 10005(2D), 10095(3D)
 * Usage:
 *   0. pray your soul remains intact after using black magic
 *   1. create pt p(D) and set values in p[i] - DON'T FORGET THE D IN pt p(D)
 *   2. add pt to Miniball mb with mb.add(p)
 *   3. after adding all pts call mb.build() - WARNING: CALL THIS ONLY ONCE
 *   4. coordinates of centre are in mb.c_c[d]
 *   5. *SQUARED* radius of circle/ball/thing is in mb.c_r2
 * Time: O(n), with large constant factor depending on \texttt{D}
 */
#pragma once

const int D = 3;
typedef vector<ld> ndpt;
typedef list<ndpt>::iterator It;
struct Miniball { list<ndpt> L; int m; vector<vector<ld>> v, a;
  vector<ndpt> c; ndpt q0; vector<ld> r2,z,f; It end; ndpt c_c; ld c_r2;
  Miniball() : m(0), v(D+1,vector<ld>(D)), a(D+1,vector<ld>(D)),
    c(D+1,ndpt(D,0)), q0(D), r2(D+1), z(D+1), f(D+1), end(L.begin()),
    c_c(c[0]), c_r2(-1.L) {}
  void add(ndpt &p) { L.push_back(p); }
  void move_to_front(It i) {
    m--; if (end==i) end++; L.splice(L.begin(),L,i); }
  void mtf_mb(It i) { end=L.begin(); if (m==D+1) return;
    for (It k=L.begin(),j;(j=k++)!=i;) { ld e = get_e(j);
      if (e > 0 && push(*j)) mtf_mb(j), move_to_front(j); } }
  void pivot_mb(It i) {
    It t=++L.begin(), pivot; mtf_mb(t); ld max_e, old_r2=-1;
    do { if((max_e=max_excess(t,i,pivot)) > 0) {
      if ((t=end)==pivot) ++t;
      old_r2=c_r2; push(*pivot); mtf_mb(end); move_to_front(pivot); }
    } while (max_e > 0 && c_r2 > old_r2); }
  ld max_excess(It j,It i,It& pivot) { ld max_e=0,e;
    for (; j!=i;++j) if ((e=get_e(j)) > max_e) max_e=e,pivot=j;
    return max_e; }
  ld get_e(It j) { ld e = -c_r2;
    for (int i=0;i<D;++i) { e+=pow((*j)[i]-c_c[i], 2); } return e; }
  bool push(const ndpt& p) { int i, j; if (!m) c[0]=q0=p, r2[0]=0;
    else { for (i=0;i<D;++i) v[m][i]=p[i]-q0[i];
      for (i=1;i<m;++i) { a[m][i]=0;
        for (j=0;j<D;++j) a[m][i]+=v[i][j]*v[m][j];
        a[m][i]*=(2/z[i]); }
      for (i=1;i<m;++i) for (j=0;j<D;++j) v[m][j]-=a[m][i]*v[i][j];
      z[m]=0; for (j=0;j<D;++j) z[m]+=2*pow(v[m][j], 2);
      if (z[m] < c_r2*EPS) return false;
      ld e=-r2[m-1]; for (i=0;i<D;++i) e+=pow(p[i]-c[m-1][i], 2);
      f[m]=e/z[m];
      for (i=0;i<D;++i) c[m][i]=c[m-1][i]+f[m]*v[m][i];
      r2[m]=r2[m-1]+e*f[m]/2;
    } c_c=c[m]; c_r2=r2[m]; m++; return true; }
  void build(){ pivot_mb(L.end()); } };


./content/geometry/Point3D.h
/**
 * Description: General 3d geometry.
 */
#pragma once

struct p3d{ ld x,y,z;
  friend ostream& operator<< (ostream& os, const p3d& p) {
  return os << "(" << p.x << "," << p.y << "," << p.z << ")"; } };
ld abs(const p3d &v){ return sqrt(v.x*v.x + v.y*v.y + v.z*v.z); }
p3d operator+(const p3d& a, const p3d& b) {
  return {a.x+b.x,a.y+b.y,a.z+b.z}; }
p3d operator-(const p3d& a, const p3d& b) {
  return {a.x-b.x,a.y-b.y,a.z-b.z}; }
p3d operator*(const ld &s, const p3d &v){ return {s*v.x,s*v.y,s*v.z}; }
p3d operator/(const p3d&v, const ld &s){ return {v.x/s, v.y/s, v.z/s}; }
inline ld dot(const p3d &a, const p3d &b){
  return a.x*b.x + a.y*b.y + a.z*b.z; }
inline p3d cross(const p3d &a, const p3d &b){
  return {a.y*b.z - a.z*b.y, a.z*b.x - a.x*b.z, a.x*b.y - a.y*b.x}; }
// Azimuthal angle (longitude) to x-axis in interval [-pi, pi]
ld phi(const p3d& a) { return atan2(a.y, a.x); }
// Zenith angle (latitude) to the z-axis in interval [0, pi]
ld theta(const p3d& a) { return atan2(sqrt(a.x*a.x+a.y*a.y), a.z); }
inline ld dist(const p3d &s, const p3d &p) {
  return (p.x-s.x)*(p.x-s.x)+(p.y-s.y)*(p.y-s.y)+(p.z-s.z)*(p.z-s.z); }
// plane/line intersection. p - pt on plane, n - normal, a1 -> a2 : line
p3d pl_inter(const p3d &p, const p3d &n, const p3d &a1, const p3d &a2) {
  return a1 + dot(p - a1, n)/dot(n, a2 - a1)*(a2 - a1); }
// CCW rotation about arbitrary axis; tested pacnw2009D but pray anyway
p3d rotate(const p3d& p/*pt*/, const p3d& u/*axis*/, const ld& angle) {
  ld c = cos(angle), s = sin(angle), t = 1 - cos(angle);  return {
    p.x*(t*u.x*u.x + c)+p.y*(t*u.x*u.y - s*u.z)+p.z*(t*u.x*u.z + s*u.y),
    p.x*(t*u.x*u.y + s*u.z)+p.y*(t*u.y*u.y + c)+p.z*(t*u.y*u.z - s*u.x),
    p.x*(t*u.x*u.z - s*u.y)+p.y*(t*u.y*u.z + s*u.x)+p.z*(t*u.z*u.z + c)
  }; } // hash: 3f78e3


./content/geometry/PointInsideHull.h
/**
 * Author: chilli
 * Date: 2019-05-17
 * License: CC0
 * Source: https://github.com/ngthanhtrung23/ACM_Notebook_new
 * Description: Determine whether a point t lies inside a convex hull (CCW
 * order, with no colinear points). Returns true if point lies within
 * the hull. If strict is true, points on the boundary aren't included.
 * Usage:
 * Status: fuzz-tested
 * Time: O(\log N)
 */
#pragma once

#include "GeometryPrimitives.h"
#include "InsidePolygon.h"

bool in_hull(const pt& p, const vector<pt>& l, bool strict = true) {
	int a = 1, b = (int)l.size() - 1, r = !strict;
	if (l.size() < 3)
    return r &&
      (eq(p,l[0]) || eq(p,l.back()) || on_segment(l[0],l.back(),p));
	if (sgn(cp(l[a]-l[0], l[b]-l[0])) > 0) swap(a, b);
	if (sgn(cp(l[a]-l[0],p-l[0])) >= r || sgn(cp(l[b]-l[0],p-l[0])) <= -r)
		return false;
	while (abs(a - b) > 1) {
		int c = (a + b) / 2;
		(sgn(cp(l[c]-l[0], p-l[0])) > 0 ? b : a) = c;
	}
	return sgn(cp(l[b]-l[a], p-l[a])) < r;
}


./content/geometry/PolygonArea.h
/**
 * Description: Area of a polygon (convex or concave). Always non-negative. For signed area, remove \texttt{abs}.
 */
#pragma once

#include "GeometryPrimitives.h"

ld area(const pol &v) { ld s = 0; int n = v.size();
  for(int i = n-1, j = 0; j < n; i = j++) s += cp(v[i], v[j]);
  return abs(s)/2;}


./content/geometry/PolygonCenter.h
/**
 * Description: Returns the center of mass for a polygon (orientation does not matter).
 * Time: O(n)
 */
#pragma once

#include "GeometryPrimitives.h"

pt centroid(const pol &v) {
  pt res; ld A = 0; int n = v.size();
  for(int i = n-1, j = 0; j < n; i = j++)
    A+=cp(v[i],v[j]), res+=(v[i]+v[j])*cp(v[i],v[j]);
  return abs(A) < EPS ? res : res/3.L/A; }


./content/geometry/PolygonCut.h
/**
 * Description: Returns a vector with the vertices of a polygon with everything to the left of the line going from a to b cut away.
 * Status: Convex polygons tested UVa 10117,
 * Simple polygon tested KTH Challenge 2013 G (henryx: this confuses me because the remaining part could be disconnected)
 */
#pragma once

#include "GeometryPrimitives.h"
#include "Lines.h"
pol cut_polygon(const pol &v, const pt &a, const pt &b) { pol out;
  for(int i = v.size() - 1, j = 0; j < v.size(); i = j++) {
    if(cp(b-a, v[i]-a) < EPS) out.push_back(v[i]);
    if(sgn(cp(b-a, v[i]-a)) * sgn(cp(b-a, v[j]-a)) < 0) {
      pt p = line_inter(a, b, v[i], v[j]);
      if(!out.size() || abs(out.back() - p) > EPS) out.push_back(p); } }
  while(out.size() && abs(out[0] - out.back()) < EPS) out.pop_back();
  return out; }


./content/geometry/SegmentIntersection.h
/**
 * Author: Jason?
 * Description: Returns true if segment a--b intersects c--d.
 */
#pragma once

#include "GeometryPrimitives.h"
// handles ALL cases, uncomment the 3 marked lines to exclude endpoints
bool seg_x_seg(pt a, pt b, pt c, pt d) {
  //if(eq(a, b) || eq(c, d)) return 0; // exclude endpoints
  ld sa=abs(b-a), sc=abs(d-c); sa=sa>EPS?1/sa:0; sc=sc>EPS?1/sc:0;
  int r1 = sgn(cp(b-a, c-a) * sa), r2 = sgn(cp(b-a, d-a) * sa);
  int r3 = sgn(cp(d-c, a-c) * sc), r4 = sgn(cp(d-c, b-c) * sc);
  if(!r1 && !r2 && !r3) { // collinear
    if(cmp_lex(b, a)) swap(a, b);
    if(cmp_lex(d, c)) swap(c, d);
    //return cmp_lex(a, d) && cmp_lex(c, b); // exclude endpoints
    return !cmp_lex(d, a) && !cmp_lex(b, c);
  } return r1*r2 <= 0 && r3*r4 <= 0; }//change to < to exclude endpoints


./content/geometry/kdTree.h
/**
 * Author: Stanford
 * Date: Unknown
 * Source: Stanford Notebook
 * Description: KD-tree (2d, can be extended to 3d)
 * Status: Untested, but works for Stanford
 */
#pragma once

#include "Point.h"

typedef long long T;
typedef Point<T> P;
const T INF = numeric_limits<T>::max();

bool on_x(const P& a, const P& b) { return a.x < b.x; }
bool on_y(const P& a, const P& b) { return a.y < b.y; }

struct Node {
	P pt; // if this is a leaf, the single point in it
	T x0 = INF, x1 = -INF, y0 = INF, y1 = -INF; // bounds
	Node *first = 0, *second = 0;

	T distance(const P& p) { // min squared distance to a point
		T x = (p.x < x0 ? x0 : p.x > x1 ? x1 : p.x);
		T y = (p.y < y0 ? y0 : p.y > y1 ? y1 : p.y);
		return (P(x,y) - p).dist2();
	}

	Node(vector<P>&& vp) : pt(vp[0]) {
		for (P p : vp) {
			x0 = min(x0, p.x); x1 = max(x1, p.x);
			y0 = min(y0, p.y); y1 = max(y1, p.y);
		}
		if (vp.size() > 1) {
			// split on x if the box is wider than high (not best heuristic...)
			sort(all(vp), x1 - x0 >= y1 - y0 ? on_x : on_y);
			// divide by taking half the array for each child (not
			// best performance with many duplicates in the middle)
			int half = sz(vp)/2;
			first = new Node({vp.begin(), vp.begin() + half});
			second = new Node({vp.begin() + half, vp.end()});
		}
	}
};

struct KDTree {
	Node* root;
	KDTree(const vector<P>& vp) : root(new Node({all(vp)})) {}

	pair<T, P> search(Node *node, const P& p) {
		if (!node->first) {
			// uncomment if we should not find the point itself:
			// if (p == node->pt) return {INF, P()};
			return make_pair((p - node->pt).dist2(), node->pt);
		}

		Node *f = node->first, *s = node->second;
		T bfirst = f->distance(p), bsec = s->distance(p);
		if (bfirst > bsec) swap(bsec, bfirst), swap(f, s);

		// search closest side first, other side if needed
		auto best = search(f, p);
		if (bsec < best.first)
			best = min(best, search(s, p));
		return best;
	}

	// find nearest point to a point, and its squared distance
	// (requires an arbitrary operator< for Point)
	pair<T, P> nearest(const P& p) {
		return search(root, p);
	}
};


./content/geometry/linearTransformation.h
/**
 * Author: Per Austrin, Ulf Lundstrom
 * Date: 2009-04-09
 * License: CC0
 * Source:
 * Description:\\
\begin{minipage}{75mm}
 Apply the linear transformation (translation, rotation and scaling) which takes line p0-p1 to line q0-q1 to point r.
\end{minipage}
\begin{minipage}{15mm}
\vspace{-8mm}
\includegraphics[width=\textwidth]{content/geometry/linearTransformation}
\vspace{-2mm}
\end{minipage}
 * Status: not tested
 */
#pragma once

#include "Point.h"

typedef Point<double> P;
P linearTransformation(const P& p0, const P& p1,
		const P& q0, const P& q1, const P& r) {
	P dp = p1-p0, dq = q1-q0, num(dp.cross(dq), dp.dot(dq));
	return q0 + P((r-p0).cross(num), (r-p0).dot(num))/dp.dist2();
}


./content/geometry/sphericalDistance.h
/**
 * Author: Ulf Lundstrom
 * Date: 2009-04-07
 * License: CC0
 * Source: My geometric reasoning
 * Description: Returns the shortest distance on the sphere with radius radius between the points with azimuthal angles (longitude) f1 ($\phi_1$) and f2 ($\phi_2$) from x axis and zenith angles (latitude) t1 ($\theta_1$) and t2 ($\theta_2$) from z axis. All angles measured in radians. The algorithm starts by converting the spherical coordinates to cartesian coordinates so if that is what you have you can use only the two last rows. dx*radius is then the difference between the two points in the x direction and d*radius is the total distance between the points.
 * Status: somewhat tested locally
 tested with Kattis problem airlinehub
 to be tested with UVa 535
 */
#pragma once

double sphericalDistance(double f1, double t1,
		double f2, double t2, double radius) {
	double dx = sin(t2)*cos(f2) - sin(t1)*cos(f1);
	double dy = sin(t2)*sin(f2) - sin(t1)*sin(f1);
	double dz = cos(t2) - cos(t1);
	double d = sqrt(dx*dx + dy*dy + dz*dz);
	return radius*2*asin(d/2);
}


./content/graph/2sat.h
/**
 * Description: Solves the boolean 2-satisfiability problem.
 *  The boolean variable \texttt{x} is represented by \texttt{2*x} and its negation is \texttt{2*x\textasciicircum1}.
 * Usage:
 *  1) add clauses, for example add_clause(2*x, 2*y\textasciicircum1) for x || !y
 *     (can add the implication x => y directly with adj[2*x].push_back(2*y))
 *  2) if (two_sat(2*num_vars)) // satisfiable, truth[x] = assignment for x
 *     else                     // no satisfying assignment exists
 * Time: O(V+E)
 */
#pragma once

#include "SCC.h"

bool truth[N/2]; // N must be at least 2 times the number of variables
// the clause a || b becomes !a => b and !b => a in implication graph
void add_clause(int a, int b) {
  adj[a^1].push_back(b); adj[b^1].push_back(a); }
bool two_sat(int n) { get_scc(n);
  for (int i = 0; i < n; i += 2) { if (scomp[i] == scomp[i^1]) return 0;
    truth[i/2] = (scomp[i] < scomp[i^1]); } return 1; }


./content/graph/BellmanFord.h
/**
 * Author: Simon Lindholm
 * Date: 2015-02-23
 * License: CC0
 * Source: http://en.wikipedia.org/wiki/Bellman-Ford_algorithm
 * Description: Calculates shortest paths from $s$ in a graph that might have negative edge weights.
 * Unreachable nodes get dist = inf; nodes reachable through negative-weight cycles get dist = -inf.
 * Assumes $V^2 \max |w_i| < \tilde{} 2^{63}$.
 * Time: O(VE)
 * Status: Tested on kattis:shortestpath3
 */
#pragma once

const ll inf = LLONG_MAX;
struct Ed { int a, b, w, s() { return a < b ? a : -a; }};
struct Node { ll dist = inf; int prev = -1; };

void bellmanFord(vector<Node>& nodes, vector<Ed>& eds, int s) {
	nodes[s].dist = 0;
	sort(all(eds), [](Ed a, Ed b) { return a.s() < b.s(); });

	int lim = sz(nodes) / 2 + 2; // /3+100 with shuffled vertices
	rep(i,0,lim) trav(ed, eds) {
		Node cur = nodes[ed.a], &dest = nodes[ed.b];
		if (abs(cur.dist) == inf) continue;
		ll d = cur.dist + ed.w;
		if (d < dest.dist) {
			dest.prev = ed.a;
			dest.dist = (i < lim-1 ? d : -inf);
		}
	}
	rep(i,0,lim) trav(e, eds) {
		if (nodes[e.a].dist == -inf)
			nodes[e.b].dist = -inf;
	}
}


./content/graph/BiconnectedComponents.h
/**
 * Description: Finds 2-vertex- and 2-edge-connected components of a graph.
 * Time: O(V + E)
 * Status: tested Codeforces 521E
 * Usage: 1) init(); 2) add edges; 3) get_bcc(numV); 4) use isCutVertex(v) or isCutEdge(2*e)
 */
#pragma once

int vcompNum,ecompNum,I,m;
int first[N],low[N],vis[N],ecomp[N];
int nxt[2*M],ep[2*M],vcomp[2*M];
stack<int> edges, verts;
void init() { m = 0; memset(first, -1, sizeof(first)); }
void add_edge(int a, int b) {
    nxt[m] = first[ep[m] = a]; first[ep[m]] = m; ++m;
    nxt[m] = first[ep[m] = b]; first[ep[m]] = m; ++m; }
void biconnected(int u, int par){ int v,E; low[u] = vis[u] = ++I;
  verts.push(u); for (int e=first[u]; e!=-1; e=nxt[e]) { v = ep[e^1];
    if (!vis[v]) { edges.push(e); biconnected(v,e);
      low[u] = min(low[u],low[v]);
      if (vis[u] <= low[v]) {
        // u is a cut vertex unless it's a one-child root
        do { E=edges.top(); edges.pop(); vcomp[E]=vcomp[E^1]=vcompNum; }
        while (e != E && e != (E^1)); ++vcompNum; }}
    else if (vis[v] < vis[u] && e != (par^1)) {
      low[u] = min(low[u], vis[v]); edges.push(e); }
    else if (v == u) vcomp[e]=vcomp[e^1]=vcompNum++; } // e is self-loop
  if (vis[u] <= low[u]) { // par is a cut edge unless par==-1
    do { v = verts.top(); verts.pop(); ecomp[v] = ecompNum; }
    while (v != u); ++ecompNum; }
}
void get_bcc(int n) { memset(vis,0,sizeof vis); vcompNum=ecompNum=I=0;
  for (int i=0; i<n; ++i) if (!vis[i]) biconnected(i, -1);
}
// tree-independent criteria for identifying cut vertices and bridges
bool isCutVertex(int u) { for (int e = first[u]; e != -1; e = nxt[e]) {
  if (vcomp[e] != vcomp[first[u]]) return true; } return false; }
bool isCutEdge(int e) { return ecomp[ep[e]] != ecomp[ep[e^1]]; }


./content/graph/CactusDecomposition.h
/**
 * Author: henryx
 * Description: Decomposes a cactus into tree edges and cycles (or determines that the graph is not a cactus).
 * This is a very bad EXAMPLE
 * Time: O(E)
 * Status: tested unconvincingly
 */
#pragma once

struct Edge { int u, v; ll c; };
vector<Edge> adj[N]; // original graph
vector<Edge> tree[N]; // stores the tree edges
vector<int> cyc[N]; // stores the cycles indexed starting from n
unordered_set<int> skip[N];
vector<Edge> cycle[N]; // cycles stored in reverse
vector<Edge> par[N]; // parents stored in reverse (should have len 1)
bool vis[N];

void find_cycle(int u, int p, int cid) {
	cycle[cid].push_back(par[u].back());
	par[u].pop_back();
	for(int v=p; v!=u; v=par[v].back().u) {
		cycle[cid].push_back(par[v].back());
	}
	cyc[u].push_back(cid);
}

int decompose(int u, int p, int& cid) {
	if(vis[u]) {
		find_cycle(u, p, ++cid);
		skip[u].insert(p);
		return u;
	}
	vis[u] = true;
	int wait = 0;
	for(const Edge& e:adj[u]) {
		if(e.v == p || skip[u].count(e.v)) continue;
		par[e.v].push_back(e);
		int to = decompose(e.v, u, cid);
		if(!to) {
			tree[u].push_back(e);
		} else if(to != u) {
			assert(!wait); // if(wait) then not cycle
			wait = to;
		}
	}
	return wait;
}


./content/graph/CentroidHenry.h
/**
 * Author: Henry X
 * Date: 2019
 * Description: Centroid decomposition EXAMPLE
 * Time: O(N)
 * Status: Example code
 */
#pragma once

struct Edge { int v, c; };
vector<Edge> adj[N];
vector<pair<int,ll>> csub[N], cpar[N];
bool vis[N]; int sz[N], cdepth[N], cparent[N];

void get_dists(int u, int p, int x, ll d) {
	csub[x].push_back(make_pair(u,d));
	cpar[u].push_back(make_pair(x,d));
	for(const Edge& e:adj[u]) {
		if(e.v!=p && !vis[e.v]) {
			get_dists(e.v, u, x, d+e.c);
		}
	}
}

int dfs(int u, int p, vector<int>& seen) {
	seen.push_back(u);
	sz[u] = 1;
	for(const Edge& e:adj[u]) {
		if(e.v != p && !vis[e.v]) {
			sz[u] += dfs(e.v, u, seen);
		}
	}
	return sz[u];
}

int centroid(int u, int layer) {
	vector<int> seen;
	int s = dfs(u, 0, seen); // get the size
	for(int v:seen) {
		bool ok = true;
		for(const Edge& e:adj[v]) {
			if(vis[e.v]) continue;
			if(2*sz[v]<s || (sz[v]>sz[e.v] && 2*sz[e.v]>s)) {
				ok = false; break; }
		}
		if(ok) {
			get_dists(v, 0, v, 0); // do linear stuff here
			return v; // v is the centroid
		}
	} assert(false);
}

// layer is optional, use to store things in O(n) memory per layer
int decompose(int u, int layer) {
	int c = centroid(u, layer);
	cdepth[c] = layer;
	vis[c] = true;
	for(const Edge& e:adj[c]) {
		if(vis[e.v]) continue;
		int nc = decompose(e.v, layer + 1);
		cparent[nc] = c;
	}
	return c; // return centroid
}


./content/graph/CompressTree.h
/**
 * Author: Simon Lindholm
 * Date: 2016-01-14
 * License: CC0
 * Status: Tested at CodeForces
 * Description: Given a rooted tree and a subset S of nodes, compute the minimal
 * subtree that contains all the nodes by adding all (at most $|S|-1$)
 * pairwise LCA's and compressing edges.
 * Returns a list of (par, orig\_index) representing a tree rooted at 0.
 * The root points to itself.
 * Usage: T is preorder numbers; lca.query returns the lca;
 * REWRITE IN HUMAN READABLE CODE
 * Time: $O(|S| \log |S|)$
 */
#pragma once

#include "LCA.h"

vpi compressTree(LCA& lca, const vi& subset) {
	static vi rev; rev.resize(size(lca.dist));
	vi li = subset, &T = lca.time;
	auto cmp = [&](int a, int b) { return T[a] < T[b]; };
	sort(li.begin(), li.end(), cmp);
	int m = sz(li)-1;
	for (int i=0; i<m; i++) {
		int a = li[i], b = li[i+1];
		li.push_back(lca.query(a, b));
	}
	sort(li.begin(), li.end(), cmp);
	li.erase(unique(li.begin(), li.end()), li.end());
	for (int i=0; i<size(li); i++) rev[li[i]] = i;
	vpi ret = {pii(0, li[0])};
	for (int i=0; i<size(li)-1; i++) {
		int a = li[i], b = li[i+1];
		ret.emplace_back(rev[lca.query(a, b)], b);
	}
	return ret;
}


./content/graph/DFSMatching.h
/**
 * Author: Lukas Polacek
 * Date: 2009-10-28
 * License: CC0
 * Source:
 * Description: Simple bipartite matching algorithm. Graph $g$ should be a list
 * of neighbors of the left partition, and $btoa$ should be a vector full of
 * -1's of the same size as the right partition. Returns the size of
 * the matching. $btoa[i]$ will be the match for vertex $i$ on the right side,
 * or $-1$ if it's not matched.
 * Time: O(VE)
 * Usage: vi btoa(m, -1); dfsMatching(g, btoa);
 * Status: works
 */
#pragma once

bool find(int j,
    vector<vector<int>>& g, vector<int>& btoa, vector<int>& vis) {
	if (btoa[j] == -1) return 1;
	vis[j] = 1; int di = btoa[j];
	for (auto e : g[di])
		if (!vis[e] && find(e, g, btoa, vis)) {
			btoa[e] = di;
			return 1;
		}
	return 0;
}
int dfsMatching(vector<vector<int>>& g, vector<int>& btoa) {
	vector<int> vis;
	for (int i=0; i<g.size(); i++) {
		vis.assign(btoa.size(), 0);
		for (int j : g[i])
			if (find(j, g, btoa, vis)) {
				btoa[j] = i;
				break;
			}
	}
	return (int)btoa.size() - (int)count(btoa.begin(), btoa.end(), -1);
}


./content/graph/Dinic.h
/**
 * Author: henryx
 * Description: Computes the max flow. To recover flow paths, look at edges with positive flow.
 *  Not proven to be floating point safe
 * Usage: 1) add edges 2) flow(S, T, scaling?)
 * Time: O(V^2E) in general, O(\sqrt{V}E) on bipartite, O(\min(E^{1/2}, V^{2/3})E) on unit cap.
 *  O(VE \log U) ($U =$ max edge cap) with scaling, but worse constant factor
 * Status: Tested on SPOJ FASTFLOW, kattis bookclub, risk, sandart; codeforces 101986H, 101504K
 *  unit caps tested kattis/hubtown (V=4e5, E=1e6)
 */

#pragma once

#include "Flow.h"

// For floating point, try this:
// flow=0; for(int it=0;it<K && bfs(s,t,EPS);it++) flow += dfs(s,t,inf);
int L[N], cur[N], Q[N];
bool bfs(int s, int t, ll lim=1) {
  memset(L, INF, sizeof L); memset(cur, 0, sizeof cur);
  int f,b; Q[f=b=0] = s; L[s] = 0;
  while(f<=b && L[t]==INF) { int u = Q[f++];
    for(const Edge& e:adj[u]) if(L[e.v] == INF && e.c-e.f >= lim) {
      Q[++b] = e.v; L[e.v] = L[u]+1; } } return L[t] < INF; }
ll dfs(int u, int t, ll f) { if (u == t || !f) return f;
  for (int i = cur[u]; i < sz[u]; cur[u] = ++i) { Edge& e = adj[u][i];
    if(e.f<e.c && L[e.v]==L[u]+1) {
      if(ll cf = dfs(e.v, t, min(e.c-e.f, f))) {
        e.f += cf; adj[e.v][e.r].f -= cf; return cf; } } } return 0; }
ll flow(int s, int t, bool scaling=0) {ll inf=numeric_limits<ll>::max();
  ll res = 0; for(ll lim=(scaling?mc:1); lim; lim/=2) {
    while(bfs(s,t,lim))while(ll cf=dfs(s,t,inf))res += cf;} return res;}


./content/graph/EdmondsKarp.h
/**
 * Author: Chen Xing
 * Date: 2009-10-13
 * License: CC0
 * Source: N/A
 * Description: Flow algorithm with guaranteed complexity $O(VE^2)$. To get edge flow values, compare
 * capacities before and after, and take the positive values only.
 * Status: Working
 */
#pragma once

template<class T> T edmondsKarp(vector<unordered_map<int, T>>& graph, int source, int sink) {
	assert(source != sink);
	T flow = 0;
	vi par(sz(graph)), q = par;

	for (;;) {
		fill(all(par), -1);
		par[source] = 0;
		int ptr = 1;
		q[0] = source;

		rep(i,0,ptr) {
			int x = q[i];
			trav(e, graph[x]) {
				if (par[e.first] == -1 && e.second > 0) {
					par[e.first] = x;
					q[ptr++] = e.first;
					if (e.first == sink) goto out;
				}
			}
		}
		return flow;
out:
		T inc = numeric_limits<T>::max();
		for (int y = sink; y != source; y = par[y])
			inc = min(inc, graph[par[y]][y]);

		flow += inc;
		for (int y = sink; y != source; y = par[y]) {
			int p = par[y];
			if ((graph[p][y] -= inc) <= 0) graph[p].erase(y);
			graph[y][p] += inc;
		}
	}
}


./content/graph/EulerTour.h
/**
 * Description: Finds an Euler path/Euler tour in a graph. Answer is returned in reverse order.
 * Usage: ans.clear(); euler(s, ans.insert(ans.begin(), s));
 *  (For Euler path, s should be a node with odd degree.)
 * Time: O(E \log E)
 */

#pragma once

multiset<int> adj[N];
// Watch out for stack overflow. Answer is returned in reverse order.
list<int> ans;
void euler(int u, list<int>::iterator it) {
  for (auto it2 = adj[u].begin(); it2 != adj[u].end(); ) {
    int v=*it2; adj[u].erase(it2);
    /*undirected: adj[v].erase(adj[v].find(u));*/
    euler(v, ans.insert(it, v)); it2 = adj[u].begin(); } }



./content/graph/EulerWalk.h
/**
 * Author: Chen Xing
 * Date: 2009-04-14
 * License: CC0
 * Source: folklore
 * Description: Eulerian undirected/directed path/cycle algorithm. Returns a list of nodes in the Eulerian path/cycle with src at both start and end, or
 *  empty list if no cycle/path exists. To get edge indices back, also put it->second in s (and then ret).
 * Time: O(E) where E is the number of edges.
 * Status: tested
 */
#pragma once

struct V {
	vector<pii> outs; // (dest, edge index)
	int nins = 0;
};

vi euler_walk(vector<V>& nodes, int nedges, int src=0) {
	int c = 0;
	trav(n, nodes) c += abs(n.nins - sz(n.outs));
	if (c > 2) return {};
	vector<vector<pii>::iterator> its;
	trav(n, nodes)
		its.push_back(n.outs.begin());
	vector<bool> eu(nedges);
	vi ret, s = {src};
	while(!s.empty()) {
		int x = s.back();
		auto& it = its[x], end = nodes[x].outs.end();
		while(it != end && eu[it->second]) ++it;
		if(it == end) { ret.push_back(x); s.pop_back(); }
		else { s.push_back(it->first); eu[it->second] = true; }
	}
	if(sz(ret) != nedges+1)
		ret.clear(); // No Eulerian cycles/paths.
	// else, non-cycle if ret.front() != ret.back()
	reverse(all(ret));
	return ret;
}


./content/graph/Flow.h
/**
 * Author: henryx
 * Description: Data structures common to all flow routines.
 */

#pragma once

struct Edge { int v, r; ll f, c, p; };
vector<Edge> adj[N]; int sz[N]; ll mc;
vector<Edge> mcf_edges; // for mcf on large graphs with negative costs
void init(int n=N) {
  mc=0; fill(sz,sz+n,0); fill(adj,adj+n,vector<Edge>()); }
void add_edge(int a, int b, ll c=1, ll p=0) { mc = max(mc,c); // scaling
  // mcf_edges.push_back({b,a,0,c,p});
	adj[a].push_back({b,sz[b]++,0,c,p});
	adj[b].push_back({a,sz[a]++,0,0,-p}); }


./content/graph/FlowApplications.h
/**
 * Description: Flow With Lower Bounds and Max Weight Closure
 * Usage:
 *  Flow With Demands
 *    Given a flow with lower bounds graph G with source S and sink T,
 *    create a graph G' as follows:
 *    1. add two new nodes S' and T'
 *    2. add an edge from T to S with infinite capacity
 *    3. for each edge u -> v in G with capacity c and lower bound d > 0, do:
 *      a) update capacity of u -> v to c - d
 *      b) add an edge S' -> v with capacity d
 *      c) add an edge u -> T' with capacity d
 *    The circulation problem is feasible if the max flow from S' to T' is saturated.
 *    To get the max flow, run max flow on G' from S to T without resetting the flows
 *    Actual flow is f_G(u, v) = f_{G'}(u, v) + d(u, v)
 *  Max Weight Closure
 *    A closure is a subgraph with no outgoing edges. Let each vertex v have weight w_v.
 *    Add edges to G as follows
 *    1. connect S -> v with capacity w_v if w_v > 0
 *    2. connect v -> T with capacity -w_v if w_v < 0
 *    3. min_cut(S, T) gives the max weight closure
 *    Recover the closure by getting all the vertices left of the min cut
 */



./content/graph/FloydWarshall.h
/**
 * Author: Simon Lindholm
 * Date: 2016-12-15
 * License: CC0
 * Source: http://en.wikipedia.org/wiki/Floyd–Warshall_algorithm
 * Description: Calculates all-pairs shortest path in a directed graph that might have negative edge weights.
 * Input is an distance matrix $m$, where $m[i][j] = \texttt{inf}$ if $i$ and $j$ are not adjacent.
 * As output, $m[i][j]$ is set to the shortest distance between $i$ and $j$, \texttt{inf} if no path, or \texttt{-inf} if the path goes through a negative-weight cycle.
 * Time: O(N^3)
 * Status: slightly tested
 */
#pragma once

const ll inf = 1LL << 62;
void floydWarshall(vector<vector<ll>>& m) {
	int n = sz(m);
	rep(i,0,n) m[i][i] = min(m[i][i], 0LL);
	rep(k,0,n) rep(i,0,n) rep(j,0,n)
		if (m[i][k] != inf && m[k][j] != inf) {
			auto newDist = max(m[i][k] + m[k][j], -inf);
			m[i][j] = min(m[i][j], newDist);
		}
	rep(k,0,n) if (m[k][k] < 0) rep(i,0,n) rep(j,0,n)
		if (m[i][k] != inf && m[k][j] != inf) m[i][j] = -inf;
}


./content/graph/GeneralMatching.h
/**
 * Author: Simon Lindholm
 * Date: 2016-12-09
 * License: CC0
 * Source: http://www.mimuw.edu.pl/~mucha/pub/mucha_sankowski_focs04.pdf
 * Description: Matching for general graphs.
 * Fails with probability $N / mod$.
 * Time: O(N^3)
 * Status: not very well tested
 */
#pragma once

#include "../numerical/MatrixInverse-mod.h"

vector<pii> generalMatching(int N, vector<pii>& ed) {
	vector<vector<ll>> mat(N, vector<ll>(N)), A;
	trav(pa, ed) {
		int a = pa.first, b = pa.second, r = rand() % mod;
		mat[a][b] = r, mat[b][a] = (mod - r) % mod;
	}

	int r = matInv(A = mat), M = 2*N - r, fi, fj;
	assert(r % 2 == 0);

	if (M != N) do {
		mat.resize(M, vector<ll>(M));
		rep(i,0,N) {
			mat[i].resize(M);
			rep(j,N,M) {
				int r = rand() % mod;
				mat[i][j] = r, mat[j][i] = (mod - r) % mod;
			}
		}
	} while (matInv(A = mat) != M);

	vi has(M, 1); vector<pii> ret;
	rep(it,0,M/2) {
		rep(i,0,M) if (has[i])
			rep(j,i+1,M) if (A[i][j] && mat[i][j]) {
				fi = i; fj = j; goto done;
		} assert(0); done:
		if (fj < N) ret.emplace_back(fi, fj);
		has[fi] = has[fj] = 0;
		rep(sw,0,2) {
			ll a = modpow(A[fi][fj], mod-2);
			rep(i,0,M) if (has[i] && A[i][fj]) {
				ll b = A[i][fj] * a % mod;
				rep(j,0,M) A[i][j] = (A[i][j] - A[fi][j] * b) % mod;
			}
			swap(fi,fj);
		}
	}
	return ret;
}


./content/graph/GlobalMinCut.h
/**
 * Author: Stanford
 * Date: Unknown
 * Source: Stanford Notebook, http://www.cs.tau.ac.il/~zwick/grad-algo-08/gmc.pdf
 * Description: Find a global minimum cut in an undirected graph, as represented by an adjacency matrix.
 * Time: O(V^3)
 * Status: Lightly tested
 */
#pragma once

pair<int, vi> GetMinCut(vector<vi>& weights) {
	int N = sz(weights);
	vi used(N), cut, best_cut;
	int best_weight = -1;

	for (int phase = N-1; phase >= 0; phase--) {
		vi w = weights[0], added = used;
		int prev, k = 0;
		rep(i,0,phase){
			prev = k;
			k = -1;
			rep(j,1,N)
				if (!added[j] && (k == -1 || w[j] > w[k])) k = j;
			if (i == phase-1) {
				rep(j,0,N) weights[prev][j] += weights[k][j];
				rep(j,0,N) weights[j][prev] = weights[prev][j];
				used[k] = true;
				cut.push_back(k);
				if (best_weight == -1 || w[k] < best_weight) {
					best_cut = cut;
					best_weight = w[k];
				}
			} else {
				rep(j,0,N)
					w[j] += weights[k][j];
				added[k] = true;
			}
		}
	}
	return {best_weight, best_cut};
}


./content/graph/GomoryHu.h
/**
 * Description: Computes the Gomory-Hu tree, which represents the all-pairs maximum flow in an undirected network.
 *  In particular the max $s$-$t$ flow is the min weight on the $s$-$t$ path in the tree.
 * Usage: init graph/cap; build tree; call max flow(s, t)
 * Status: tested UVA 11594
 * Time: $V-1$ max flow computations to build
 */

#pragma once

typedef int Weight;
// !!!!!!!! following must be initialized by user !!!!!!!!!!!
vector<int> graph[N]; Weight capacity[N][N]; int n; // # of vertices
// !!!!!!!!
vector<int> ghtree[N]; vector<Weight> ghweight[N];
int p[N], prv[N]; Weight w[N], flow[N][N];
Weight max_memo[N][N]; //dp table, initialize to -1
#define RES(s,t) (capacity[s][t]-flow[s][t])
void build_tree() { memset(w, 0, sizeof w); memset(p, 0, sizeof(p));
  for (int s=1; s < n; ++s) { int t = p[s];
    // compute max s-t flow
    memset(flow, 0, sizeof(flow)); Weight total = 0;
    while (true) { queue<int> q; q.push(s);
      memset(prv, -1, sizeof(prv)); prv[s] = s;
      while (!q.empty() && prv[t] < 0) {
        int u = q.front(); q.pop();
        for(int v : graph[u]) if (prv[v] < 0 && RES(u, v) > 0)
          prv[v] = u, q.push(v); }
      if (prv[t] < 0) break;
      Weight inc = INF;
      for (int j=t; prv[j]!=j; j=prv[j]) inc = min(inc, RES(prv[j], j));
      for (int j=t; prv[j]!=j; j=prv[j])
        flow[prv[j]][j] += inc, flow[j][prv[j]] -= inc;
      total += inc; }
    w[s] = total;
    for (int u=0; u<n; u++) if (u!=s && prv[u]!=-1 && p[u]==t) p[u] = s;
    if (prv[p[t]] != -1) p[s]=p[t], p[t]=s, w[s] = w[t], w[t] = total; }
  for (int i=0; i<N; i++) ghtree[i].clear(), ghweight[i].clear();
  for (int s=0; s<n; s++) if (s != p[s]) {
    ghtree[s].push_back(p[s]); ghtree[p[s]].push_back(s);
    ghweight[s].push_back(w[s]); ghweight[p[s]].push_back(w[s]); }
  memset(max_memo, -1, sizeof(max_memo)); }
Weight max_flow(int u, int t, int p = -1) { Weight d = INF;
  if (max_memo[u][t]!=-1) return max_memo[u][t]; if (u==t) return INF-1;
  for(auto e=0u; e<ghtree[u].size(); e++) if (ghtree[u][e] != p) {
    Weight ans = max_flow(ghtree[u][e], t, u);
    if (ans < INF) ans = min(ans, ghweight[u][e]);
    d = min(d, ans); }
  if (d < INF) max_memo[u][t] = max_memo[t][u] = d;
  return d; }


./content/graph/HLD.h
/**
 * Author: henryx (Paths > Trees)
 * Description: Decomposes a tree into vertex disjoint heavy paths and light
 *  edges such that the path from any leaf to the root contains $O(\log n)$
 *  light edges.
 *  If SegTree operation is not commutative, require b to be an ancestor of a,
 *  and split path uv into u->lca and v->lca before using HLD.
 * Usage:
 *  0) 1-INDEXED. 1) build tree in adj 2) implement SegTree
 *  dealing with the lca: path is lca-exclusive! for lca-inclusive, remove
 *   if(pos[a]!=pos[b]), and change update(pos[b]+1,...) to update(pos[b],...)
 *  editing insert_path: 1) for query_path, change segt[]->update to segt[]->query
 *   these queries should be accumulated into some variable to be returned
 *   2) insert_node/query_node should look similar to segt[ch[a]]->query(pos[a]);
 * Status: tested cf1023F, cf101908L, cf102059A, cf101669L, SPOJ QTREE, QTREE3
 */
#pragma once

vector<int> adj[N];
struct SegTree { int n; int *segt; // EXAMPLE
  SegTree(int len) {
		n = (len>1 ? 1<<(32-__builtin_clz(len-1)) : 1);
    segt = new int[2*n]; fill(segt, segt+2*n, 0); }
  /* implement the rest of the segment tree */
  void update(int l, int r, int v) {} };
namespace HLD { SegTree* segt[N];
int d[N], par[N], sub[N], sz[N], root[N], ch[N], pos[N]; int dn, cn;
int dfs(int u, int p) { d[u] = d[par[u]=p]+1; sub[u] = 1;
	for (int x:adj[u]) { if(x!=p) sub[u] += dfs(x,u); } return sub[u]; }
void hld(int u, int p) { if (dn == cn) { root[cn]=u; sz[cn++]=0; }
  pos[u] = sz[ch[u]=dn]++; int b=-1, c=-1;
  for (int x:adj[u]) if (x!=p && sub[x]>b) b=sub[c=x];
  if (c!=-1) hld(c,u);
  for (int y:adj[u]) if (y!=p && y!=c) { dn++; hld(y,u); } }
void build(int r) { d[0] = dn = cn = 0; dfs(r,0); hld(r,0);
  for (int i=0; i<cn; i++) segt[i] = new SegTree(sz[i]); }
// Returns lca of path ab, MODIFY for insert_node,query_path,query_node
int insert_path(int a, int b, int v) {
  while (ch[a] != ch[b]) {
    if (d[root[ch[a]]] < d[root[ch[b]]]) swap(a,b);
    segt[ch[a]]->update(0, pos[a], v); a = par[root[ch[a]]]; }
  if (pos[a] != pos[b]) { if (d[a] < d[b]) swap(a,b);
    segt[ch[a]]->update(pos[b]+1, pos[a], v); } return b; } }


./content/graph/HopcroftKarp.h
/**
 * Author: Chen Xing
 * Date: 2009-10-13
 * License: CC0
 * Source: N/A
 * Description: Fast bipartite matching algorithm. Graph $g$ should be a list
 * of neighbors of the left partition, and $btoa$ should be a vector full of
 * -1's of the same size as the right partition. Returns the size of
 * the matching. $btoa[i]$ will be the match for vertex $i$ on the right side,
 * or $-1$ if it's not matched.
 * Usage: vi btoa(m, -1); hopcroftKarp(g, btoa);
 * Time: O(\sqrt{V}E)
 * Status: fuzz-tested by MinimumVertexCover, and tested on oldkattis.adkbipmatch and SPOJ:MATCHING
 */
#pragma once

bool dfs(int a, int L, vector<vi>& g, vi& btoa, vi& A, vi& B) {
	if (A[a] != L) return 0;
	A[a] = -1;
	trav(b, g[a]) if (B[b] == L + 1) {
		B[b] = 0;
		if (btoa[b] == -1 || dfs(btoa[b], L + 1, g, btoa, A, B))
			return btoa[b] = a, 1;
	}
	return 0;
}

int hopcroftKarp(vector<vi>& g, vi& btoa) {
	int res = 0;
	vi A(g.size()), B(btoa.size()), cur, next;
	for (;;) {
		fill(all(A), 0);
		fill(all(B), 0);
		/// Find the starting nodes for BFS (i.e. layer 0).
		cur.clear();
		trav(a, btoa) if(a != -1) A[a] = -1;
		rep(a,0,sz(g)) if(A[a] == 0) cur.push_back(a);
		/// Find all layers using bfs.
		for (int lay = 1;; lay++) {
			bool islast = 0;
			next.clear();
			trav(a, cur) trav(b, g[a]) {
				if (btoa[b] == -1) {
					B[b] = lay;
					islast = 1;
				}
				else if (btoa[b] != a && !B[b]) {
					B[b] = lay;
					next.push_back(btoa[b]);
				}
			}
			if (islast) break;
			if (next.empty()) return res;
			trav(a, next) A[a] = lay;
			cur.swap(next);
		}
		/// Use DFS to scan for augmenting paths.
		rep(a,0,sz(g))
			res += dfs(a, 0, g, btoa, A, B);
	}
}


./content/graph/Hungarian.h
/**
 * Author: Yury
 * Date: Unknown
 * Source: UBC
 * Description: Max weight bipartite matching.
 * Time: O(M \times N^2) ???
 */
#pragma once

// w[i][j] = weight of edge from i on left side to j on right side
// ml[i]   = matching of left vertex i
// mr[i]   = matching of right vertex j
// lbl[i]  = score of left vertex i
// lbr[j]  = score of right vertex j
int w[N][N], ml[N], mr[N], lbl[N], lbr[N], s[N], slack[N], par[N];
int wmatch(int n, int m){ // assume n <= m;
  int i, j, k, done, al, nxt, out = 0;
  for(i=0;i<n;i++) for(j=0,lbl[i]=0,ml[i]=-1;j<m;j++) {
    lbl[i]=max(lbl[i],w[i][j]); }
  for(i = 0; i < m; i++) { lbr[i] = 0; mr[i] = -1; }
  for(i=0;i<n;i++) for(j=0;j<m;j++) if(w[i][j]==lbl[i] && mr[j]==-1) {
    ml[i] = j; mr[j] = i; break; }
  for(i = 0; i < n; i++) if(ml[i] == -1) {
    for(j=0;j<m;j++) {
      s[j]=(j==i); slack[j]=(lbl[i]+lbr[j]-w[i][j]); par[j] = -1; }
    for(done = 0; !done; ) {
      for(j=0, al=INF; j<m; j++) if(par[j]==-1) al = min(al, slack[j]);
      for(j = 0, lbl[j] -= s[j]*al; j < m; ++j, lbl[j] -= s[j]*al) {
        if(par[j] != -1) lbr[j] += al; else slack[j] -= al; }
      for(j = 0; j < m; j++) if(!slack[j] && par[j] == -1) {
        for(k=0;k<n;k++) if(s[k]&&(lbl[k]+lbr[j]==w[k][j])) {
          par[j] = k; break; }
        if(mr[j] == -1) { done = 1; do {
          nxt=ml[par[j]]; mr[j]=par[j]; ml[par[j]]=j; j=nxt; }
          while(j != -1);
        } else for(k = 0, s[mr[j]] = 1; k < m; k++) {
          slack[k] = min(slack[k], lbl[mr[j]] + lbr[k] - w[mr[j]][k]);
          break; }}}}
  for(i = 0; i < n; i++) out += w[i][ml[i]];
	return out; }


./content/graph/ISAP.h
/**
 * Author: cnjzxy
 * Source: http://dspace.mit.edu/bitstream/handle/1721.1/2177/SWP-1908-18213415.pdf
 * Description: Improved shortest augmenting path algorithm for maximum flow with gap optimization.
 * Usage: preflow(T); flow(S, T);
 * Time: Same as Dinic but often significantly faster.
 */

#pragma once

#include "Flow.h"

int cur[N], h[N], vh[N], pre[N]; ll his[N];
void preflow(int t) { memset(vh, 0, sizeof vh);memset(h, INF, sizeof h);
  h[t] = 0; vh[0] = 1; queue<int> q({t});
  while (!q.empty()) { int u = q.front(); q.pop();
    for(int i = cur[u] = 0; i < sz[u]; i++) { const Edge& e = adj[u][i];
      if (h[e.v] == INF) { q.push(e.v); vh[h[e.v] = h[u]+1]++; } } } }
ll flow(int s, int t) { int u = s; ll flow = 0, aug = INF;
  while (h[s] < N) { bool push = false; his[u] = aug;
    for(int i = cur[u]; i < sz[u]; i++) { const Edge& e = adj[u][i];
      if (e.f < e.c && h[u] == h[e.v]+1) {
        push = 1; aug = min(aug, e.c-e.f); cur[u] = i; pre[u=e.v] = e.r;
        if (u == t) { for (flow += aug; u != s; u = adj[u][pre[u]].v) {
          Edge& r = adj[u][pre[u]]; r.f -= aug; adj[r.v][r.r].f += aug;}
        aug = INF; } break; } }
    if (push) continue; else if (!--vh[h[u]]) break; else h[u]=N;
    for(int i=0; i<sz[u]; i++) { const Edge& e = adj[u][i];
      if (e.f < e.c && h[e.v] < h[u]) { h[u] = h[e.v]; cur[u]=i; } }
    vh[++h[u]]++; if (u != s) { u = adj[u][pre[u]].v; aug = his[u]; } }
  return flow; }



./content/graph/LCA.h
/**
 * Author: Johan Sannemo, Simon Lindholm
 * Date: 2015-09-20
 * License: CC0
 * Source: Folklore
 * Status: Somewhat tested
 * Description: Data structure for computing lowest common
 * ancestors in a tree (with 0 as root). C should be an adjacency list of the tree,
 * either directed or undirected.
 * Can also find the distance between two nodes.
 * Usage:
 *  LCA lca(undirGraph);
 *  lca.query(firstNode, secondNode);
 *  lca.distance(firstNode, secondNode);
 * Time: $O(N \log N + Q)$
 */
#pragma once

typedef vector<pii> vpi;
typedef vector<vpi> graph;

#include "../data-structures/RMQ.h"

struct LCA {
	vi time;
	vector<ll> dist;
	RMQ<pii> rmq;

	LCA(graph& C) : time(sz(C), -99), dist(sz(C)), rmq(dfs(C)) {}

	vpi dfs(graph& C) {
		vector<tuple<int, int, int, ll>> q(1);
		vpi ret;
		int T = 0, v, p, d; ll di;
		while (!q.empty()) {
			tie(v, p, d, di) = q.back();
			q.pop_back();
			if (d) ret.emplace_back(d, p);
			time[v] = T++;
			dist[v] = di;
			trav(e, C[v]) if (e.first != p)
				q.emplace_back(e.first, v, d+1, di + e.second);
		}
		return ret;
	}

	int query(int a, int b) {
		if (a == b) return a;
		a = time[a], b = time[b];
		return rmq.query(min(a, b), max(a, b)).second;
	}
	ll distance(int a, int b) {
		int lca = query(a, b);
		return dist[a] + dist[b] - 2 * dist[lca];
	}
};


./content/graph/MatrixTree.h
/**
 * Author: Simon Lindholm
 * Date: 2016-09-06
 * Source: Wikipedia
 * Description: To count the number of spanning trees in an undirected graph $G$:
 * create an $N\times N$ matrix \texttt{mat}, and for each edge $(a, b) \in G$, do
 * \texttt{mat[a][a]++, mat[b][b]++, mat[a][b]--, mat[b][a]--}.
 * Remove the last row and column, and take the determinant.
 */


./content/graph/MaximalCliques.h
/**
 * Author: Simon Lindholm
 * Date: 2018-07-18
 * License: CC0
 * Source: https://en.wikipedia.org/wiki/Bron%E2%80%93Kerbosch_algorithm
 * Description: Runs a callback for all maximal cliques in a graph (given as a
 * symmetric bitset matrix; self-edges not allowed). Callback is given a bitset
 * representing the maximal clique. Possible optimization: on the top-most
 * recursion level, ignore 'cands', and go through nodes in order of increasing
 * degree, where degrees go down as nodes are removed.
 * Time: O(3^{n/3}), much faster for sparse graphs
 * Status: fuzz-tested
 */
#pragma once

typedef bitset<128> B;
template<class F>
void cliques(vector<B>& eds, F f, B P = ~B(), B X={}, B R={}) {
	if (!P.any()) { if (!X.any()) f(R); return; }
	auto q = (P | X)._Find_first();
	auto cands = P & ~eds[q];
	for (int i=0; i<eds.size(); i++) if (cands[i]) {
		R[i] = 1;
		cliques(eds, f, P & eds[i], X & eds[i], R);
		R[i] = P[i] = 0; X[i] = 1;
	}
}


./content/graph/MaximumClique.h
/**
 * Author: chilli, SJTU, Janez Konc
 * Date: 2019-05-10
 * License: GPL3+
 * Source: https://en.wikipedia.org/wiki/MaxCliqueDyn_maximum_clique_algorithm, https://gitlab.com/janezkonc/mcqd/blob/master/mcqd.h
 * Description: Finds a maximum clique of a graph (given as symmetric bitset
 * matrix; self-edges not allowed). Can be used to find a maximum independent
 * set by finding a clique of the complement graph.
 * Time: Runs in about 1s for n=155 and worst case random graphs (p=.90). Runs
 * faster for sparse graphs.
 * Status: fuzz-tested
 */
typedef bitset<200> B;
struct Maxclique {
	double limit=0.025, pk=0;
	struct Vertex { int i, d=0; };
	typedef vector<Vertex> vv;
	vector<B> e;
	vv V;
	vector<vector<int>> C;
	vector<int> qmax, q, S, old;
	bool cut1(int pi, const vector<int>& A) {
		for (int i : A) if (e[pi][i]) return true;
		return false;
	}
	void init(vv& r) {
		for (auto& v : r) v.d = 0;
		for (auto& v : r) for (auto& j : r) v.d += e[v.i][j.i];
		sort(r.begin(), r.end(), [](auto a, auto b) { return a.d > b.d; });
		int mxD = r[0].d;
		for (int i=0; i<r.size(); i++) r[i].d = min(i, mxD) + 1;
	}
	void expand(vv& R, int lev = 1) {
		S[lev] += S[lev - 1] - old[lev];
		old[lev] = S[lev - 1];
		while (!R.empty()) {
			if (q.size() + R.back().d <= qmax.size()) return;
			q.push_back(R.back().i);
			vv T;
			for (auto& v : R) if (e[R.back().i][v.i]) T.push_back({v.i});
			if (!T.empty()) {
				if (S[lev]++ / ++pk < limit) init(T);
				int j = 0, mxk = 1, mnk = max((int)qmax.size() - (int)q.size() + 1, 1);
				C[1].clear(), C[2].clear();
				for (auto& v : T) {
					int k = 1;
					while (cut1(v.i, C[k])) k++;
					if (k > mxk) mxk = k, C[mxk + 1].clear();
					if (k < mnk) T[j++].i = v.i;
					C[k].push_back(v.i);
				}
				if (j > 0) T[j - 1].d = 0;
				for (int k=mnk; k<=mxk; k++) for (int i : C[k])
					T[j].i = i, T[j++].d = k;
				expand(T, lev + 1);
			} else if (q.size() > qmax.size()) qmax = q;
			q.pop_back(), R.pop_back();
		}
	}
	vector<int> maxClique() { init(V), expand(V); return qmax; }
	Maxclique(vector<B> conn) :
		e(conn), C(e.size() + 1), S(e.size()+1), old(S)  {
		for (int i=0; i<e.size(); i++) V.push_back({i});
	}
};


./content/graph/MaximumIndependentSet.h
/**
 * Author: chilli
 * Date: 2019-05-17
 * Source: Wikipedia
 * Description: To obtain a maximum independent set of a graph, find a max
 * clique of the complement. If the graph is bipartite, see MinimumVertexCover.
 */


./content/graph/MinCostArb.h
/**
 * Author: henryx
 * Source: http://www.cs.tau.ac.il/~zwick/grad-algo-13/directed-mst.pdf
 * Description: Finds the minimum spanning arborescence of a strongly connected directed graph.
 *  (Make $G$ strong again by adding edges.)
 * Usage:
 *  1. MinArb::add_edge(a,b,c);  // add edge a -> b with cost c
 *  2. MinArb::contract(u);  // u is the vertex with highest id
 *  3. MinArb::expand(r);  // builds minimum out arb rooted at r
 *     arb edge ids are e=in[u] for u!=r, values are: from[e], to[e], cost[e]
 *     If multiple expands per contract, do MinArb::save(n); MinArb::expand(r); MinArb::load(n);
 *  If multiple calls to contract are needed, call MinArb::init(n);
 * Time: O(E \log E + V)
 * Status: tested nwerc2018f uva11183
 */
#pragma once

namespace MinArb { int from[M], to[M]; ll cost[M], nc[M]; int m = 0;
int in[2*N], pre[2*N], par[2*N], dsu[2*N], spar[2*N], sin[2*N];
ll sh[2*N]; vector<int> child[2*N]; priority_queue<pair<ll,int>> p[2*N];
void add_edge(int a, int b, ll c=0) {
	from[m]=a; to[m]=b; nc[m] = -c; cost[m] = c; p[b].push({-c, m++}); }
void init(int n=N) { m = 0;
	fill(p,p+2*n,priority_queue<pair<ll,int>>());
	fill(child,child+2*n,vector<int>()); }
int find(int i) { return dsu[i] == -1 ? i : dsu[i] = find(dsu[i]); }
void link(int i, int j) { if (find(i)!=find(j)) dsu[find(i)]=find(j); }
void contract(int n) { memset(dsu, -1, sizeof dsu);
	memset(in, -1, sizeof in); memset(sh, 0, sizeof sh);
	memset(pre, -1, sizeof pre); memset(par, -1, sizeof par);
	for (int a = n; !p[a].empty(); ) {
		int e=p[a].top().second; p[a].pop(); int u=from[e]; int b = find(u);
		if (a != b) { in[a] = e; pre[a] = b; if (in[u] == -1) a = b; else {
			for (int c = ++n; a != c; a = find(pre[a])) {
				par[a] = c; sh[a] = -nc[in[a]]; child[c].push_back(a);
				if (p[a].size()>p[c].size()) {
          swap(p[a],p[c]); swap(sh[a],sh[c]); }
				for (ll add=sh[a]-sh[c]; !p[a].empty(); ) { auto it=p[a].top();
					p[a].pop(); p[c].push({it.first + add, it.second});
					nc[it.second] += add; } link(a, c); } } } } } // henryx
void expand(int r) { stack<int> roots; auto dismantle = [&](int u) {
	for ( ; par[u] != -1; u = par[u]) for (int v : child[par[u]]) {
		if (u!=v) { par[v]=-1; if (!child[v].empty()) roots.push(v); } } };
  for (dismantle(r); !roots.empty(); ) { int c=roots.top(); roots.pop();
    int v = to[in[c]]; in[v] = in[c]; dismantle(v); } }
void save(int n=N) {
  for (int i=0;i<2*n;i++) { spar[i]=par[i]; sin[i]=in[i]; }}
void load(int n=N) {
  for (int i=0;i<2*n;i++) { par[i]=spar[i]; in[i]=sin[i]; }} }


./content/graph/MinCostMaxFlow.h
/**
 * Author: henryx
 * Description: Min-cost max-flow. Use $O(V^2)$ Dijkstra for dense graphs, $O(E\log V)$ otherwise.
 * Usage: 1) add edges 2) min_cost_flow(S, T, price, V, sparse?)
 * Status: Tested on kattis companypicnic, ragingriver; codeforces 1187G
 */
#pragma once

#include "Flow.h"

bool vis[N]; int par[N]; ll pot[N], dist[N];
void pot_init(int n) { fill(pot, pot+n, 0);
	// if all edge costs >= 0, we don't need to run the Bellman-Ford here
	for(int i=1; i<n; i++) for(const Edge& e:mcf_edges)
		if(e.c) pot[e.v] = min(pot[e.v], pot[e.r] + e.p); }
ll mcf(int s, int t, ll& price, int n, bool sparse) {
	fill(vis, vis+n, 0); fill(dist, dist+n, INF); dist[s] = 0;
	// only need one of the branches below
	if(sparse) {  // replace priority_queue with queue for SPFA
		priority_queue<pair<ll,int>> dk; dk.push({0,s}); while(!dk.empty()){
			int u = dk.top().second; dk.pop(); if(vis[u]) continue;
			for(const Edge& e:adj[u]) { // BUBL;BUBL;BUBL;BUBL;BUBL;BUBL;BUBL;
				if (e.f < e.c && dist[e.v] > dist[u] + pot[u] - pot[e.v] + e.p){
					dist[e.v] = dist[u] + pot[u] - pot[e.v] + e.p; par[e.v] = e.r;
					dk.push({-dist[e.v], e.v}); } } }
	} else {  // dense
		for(int u = s; u != -1; ) { vis[u] = 1; for(const Edge& e: adj[u]) {
			if (e.f < e.c && dist[e.v] > dist[u] + pot[u] - pot[e.v] + e.p) {
				dist[e.v]=dist[u] + pot[u] - pot[e.v] + e.p; par[e.v] = e.r; } }
		u = -1; ll best = INF;
		for(int i=0; i<n; i++) if(!vis[i] && dist[i]<best) best=dist[u=i]; }
	}  // end branches
	if (dist[t] >= INF) { return 0; } ll df = INF;
	for(int u = t; u != s; ) { const Edge& r = adj[u][par[u]];
		df = min(df, adj[r.v][r.r].c - adj[r.v][r.r].f); u = r.v; }
	for(int u = t; u != s; ) { Edge& r=adj[u][par[u]], &e=adj[r.v][r.r];
		e.f += df; r.f -= df; price += df*e.p; u = r.v; }
	for(int i=0;i<n;i++) { pot[i]=min(INF, dist[i]+pot[i]); } return df; }
ll min_cost_flow(int s, int t, ll& price, int n=N, bool sparse=false) {
	pot_init(n); ll flow = price = 0;
	while(ll df=mcf(s,t,price,n,sparse)) { flow += df; } return flow; }


./content/graph/MinCut.h
/**
 * Author: Simon Lindholm
 * Date: 2015-05-13
 * Source: Wikipedia
 * Description: After running max-flow, the left side of a min-cut from $s$ to $t$ is given by all vertices reachable from $s$, only traversing edges with positive residual capacity.
 * Status: works
 */


./content/graph/MinimumVertexCover.h
/**
 * Author: Johan Sannemo, Simon Lindholm
 * Date: 2016-12-15
 * License: CC0
 * Description: Finds a minimum vertex cover in a bipartite graph.
 *  The size is the same as the size of a maximum matching, and
 *  the complement is a maximum independent set.
 * Status: fuzz-tested
 */
#pragma once

#include "DFSMatching.h"

vector<int> cover(vector<vector<int>>& g, int n, int m) {
	vector<int> match(m, -1);
	int res = dfsMatching(g, match);
	vector<bool> lfound(n, true), seen(m);
	for (int it : match) if (it != -1) lfound[it] = false;
	vector<int> q, cover;
	for (int i=0; i<n; i++) if (lfound[i]) q.push_back(i);
	while (!q.empty()) {
		int i = q.back(); q.pop_back();
		lfound[i] = 1;
		for (int e : g[i]) if (!seen[e] && match[e] != -1) {
			seen[e] = true;
			q.push_back(match[e]);
		}
	}
	for (int i=0; i<n; i++) if (!lfound[i]) cover.push_back(i);
	for (int i=0; i<m; i++) if (seen[i]) cover.push_back(n+i);
	assert(cover.size() == res);
	return cover;
}


./content/graph/PushRelabel.h
/**
 * Author: Simon Lindholm
 * Date: 2015-02-24
 * License: CC0
 * Source: Wikipedia, tinyKACTL
 * Description: Push-relabel using the highest label selection rule and the gap heuristic. Quite fast in practice.
 *  To obtain the actual flow, look at positive values only.
 * Time: $O(V^2\sqrt E)$
 * Status: Tested on kattis and SPOJ
 */
#pragma once

typedef ll Flow;
struct Edge {
	int dest, back;
	Flow f, c;
};

struct PushRelabel {
	vector<vector<Edge>> g;
	vector<Flow> ec;
	vector<Edge*> cur;
	vector<vi> hs; vi H;
	PushRelabel(int n) : g(n), ec(n), cur(n), hs(2*n), H(n) {}

	void add_edge(int s, int t, Flow cap, Flow rcap=0) {
		if (s == t) return;
		g[s].push_back({t, sz(g[t]), 0, cap});
		g[t].push_back({s, sz(g[s])-1, 0, rcap});
	}

	void add_flow(Edge& e, Flow f) {
		Edge &back = g[e.dest][e.back];
		if (!ec[e.dest] && f) hs[H[e.dest]].push_back(e.dest);
		e.f += f; e.c -= f; ec[e.dest] += f;
		back.f -= f; back.c += f; ec[back.dest] -= f;
	}
	Flow maxflow(int s, int t) {
		int v = sz(g); H[s] = v; ec[t] = 1;
		vi co(2*v); co[0] = v-1;
		rep(i,0,v) cur[i] = g[i].data();
		trav(e, g[s]) add_flow(e, e.c);

		for (int hi = 0;;) {
			while (hs[hi].empty()) if (!hi--) return -ec[s];
			int u = hs[hi].back(); hs[hi].pop_back();
			while (ec[u] > 0)  // discharge u
				if (cur[u] == g[u].data() + sz(g[u])) {
					H[u] = 1e9;
					trav(e, g[u]) if (e.c && H[u] > H[e.dest]+1)
						H[u] = H[e.dest]+1, cur[u] = &e;
					if (++co[H[u]], !--co[hi] && hi < v)
						rep(i,0,v) if (hi < H[i] && H[i] < v)
							--co[H[i]], H[i] = v + 1;
					hi = H[u];
				} else if (cur[u]->c && H[u] == H[cur[u]->dest]+1)
					add_flow(*cur[u], min(ec[u], cur[u]->c));
				else ++cur[u];
		}
	}
};


./content/graph/SCC.h
/**
 * Description: Computes the strongly connected components of a graph.
 *  The SCCs form a DAG whose components are numbered in reverse topological order.
 * Time: O(V + E)
 * Status: tested GCPC2010D
 * Usage: 1) build graph; 2) get_scc(numV); 3) scomp[u] = component \# of u
 */
#pragma once

int low[N],vis[N],scomp[N],scompNum,I;
vector<int> adj[N]; stack<int> verts;
void scc(int u) { low[u] = vis[u] = ++I; verts.push(u);
  for (int v : adj[u]) {
    if (!vis[v]) scc(v);
    if (scomp[v] == -1) low[u] = min(low[u], low[v]); }
  if (vis[u] <= low[u]) { int v;
    do { v=verts.top(); verts.pop(); scomp[v]=scompNum; }while (v != u);
    ++scompNum; }}
void get_scc(int n) {
  memset(vis,0,sizeof vis); memset(scomp,-1,sizeof scomp);
  scompNum=I=0; for (int i=0; i<n; ++i) if (!vis[i]) scc(i); }


./content/graph/ScaryGeneralMatching.h
/**
 * Description: Severely broken general matching.
 *  $v$ may be matched to itself even if there is no edge $(v, v)$; discard these edges.
 * Usage: 0) USE AND PRAY. 1) populate graph 2) set n 3) size of matching = match() 4) matching is in m[] (-1 if unmatched)
 * Time: O(VE\alpha(V,E)) (supposedly)
 */

#pragma once

int pp[N];
int f(int x) { return x == pp[x] ? x : (pp[x] = f(pp[x])); }
void u(int x, int y) {pp[x] = y;} // Broken Union-Find

vector<int> graph[N]; int p[N], m[N], d[N], c1[N], c2[N], n;
int q[2*N], *qf, *qb; //queue

// least common ancestor
int v[N];
int lca(int x, int y, int r) { int i = f(x), j = f(y);
  while (i != j && v[i] != 2 && v[j] != 1) { v[i] = 1; v[j] = 2;
    if (i != r) i = f(p[i]); if (j != r) j = f(p[j]); }
  int b = i, z = j; if (v[j] == 1) swap(b, z);
  for (i = b; i != z; i = f(p[i])) v[i] = -1; v[z] = -1; return b; }

void path(int r, int x){ if (r == x) return;
  if (d[x] == 0){
    path(r, p[p[x]]); int i=p[x], j=p[p[x]]; m[i]=j; m[j]=i; }
  else if (d[x] == 1) { path(m[x], c1[x]); path(r, c2[x]);
    int i = c1[x], j = c2[x]; m[i] = j; m[j] = i; } }

void shrink_one_side(int x, int y, int b){
  for(int i=f(x); i!=b; i=f(p[i])){
    u(i, b);if(d[i]==1)c1[i]=x,c2[i]=y,*qb++=i;}}

bool BFS(int r) { if (graph[r].empty()) return false;
  for (int i = 0; i<n; ++i) pp[i] = i;
  memset(v, -1, sizeof(v)); memset(d, -1, sizeof(d)); d[r] = 0;
  qf = qb = q; *qb++ = r; while (qf < qb)
    for (int x = *qf++, i = 0, y = graph[x][0];
           i < (int)graph[x].size(); ++i, y = graph[x][i])
      if (m[y] != y && f(x) != f(y)) { if (d[y] == -1) {
        if (m[y] == -1) { path(r, x); m[x] = y; m[y] = x; return true; }
          else { p[y]=x; p[m[y]]=y; d[y]=1; d[m[y]]=0; *qb++ = m[y]; }
        } else if (d[f(y)] == 0) {
      int b = lca(x, y, r);
      shrink_one_side(x, y, b); shrink_one_side(y, x, b); } }
  return false; }

int match() { memset(m, -1, sizeof(m)); int c = 0;
  for (int i=0; i<n; ++i) if (m[i]==-1) { if(BFS(i)) c++; else m[i]=i; }
  return c; }


./content/graph/TopoSort.h
/**
 * Author: Unknown
 * Date: 2002-09-13
 * Source: predates tinyKACTL
 * Description: Topological sorting. Given is an oriented graph.
 * Output is an ordering of vertices, such that there are edges only from left to right.
 * If there are cycles, the returned list will have size smaller than $n$ -- nodes reachable
 * from cycles will not be returned.
 * Time: $O(|V|+|E|)$
 */
#pragma once

vi topo_sort(const vector<vi>& gr) {
	vi indeg(sz(gr)), ret;
	trav(li, gr) trav(x, li) indeg[x]++;
	queue<int> q; // use priority queue for lexic. smallest ans.
	rep(i,0,sz(gr)) if (indeg[i] == 0) q.push(-i);
	while (!q.empty()) {
		int i = -q.front(); // top() for priority queue
		ret.push_back(i);
		q.pop();
		trav(x, gr[i])
			if (--indeg[x] == 0) q.push(-x);
	}
	return ret;
}


./content/graph/TreePower.h
/**
 * Author: Johan Sannemo
 * Date: 2015-02-06
 * License: CC0
 * Source: Folklore
 * Description: Calculate power of two jumps in a tree,
 * to support fast upward jumps and LCAs.
 * Assumes the root node points to itself.
 * Time: construction $O(N \log N)$, queries $O(\log N)$
 * Status: Tested at Petrozavodsk
 */
#pragma once

vector<vi> treeJump(vi& P){
	int on = 1, d = 1;
	while(on < sz(P)) on *= 2, d++;
	vector<vi> jmp(d, P);
	rep(i,1,d) rep(j,0,sz(P))
		jmp[i][j] = jmp[i-1][jmp[i-1][j]];
	return jmp;
}

int jmp(vector<vi>& tbl, int nod, int steps){
	rep(i,0,sz(tbl))
		if(steps&(1<<i)) nod = tbl[i][nod];
	return nod;
}

int lca(vector<vi>& tbl, vi& depth, int a, int b) {
	if (depth[a] < depth[b]) swap(a, b);
	a = jmp(tbl, a, depth[a] - depth[b]);
	if (a == b) return a;
	for (int i = sz(tbl); i--;) {
		int c = tbl[i][a], d = tbl[i][b];
		if (c != d) a = c, b = d;
	}
	return tbl[0][a];
}


./content/graph/WeightedMatching.h
/**
 * Author: Stanford
 * Date: Unknown
 * Source: Stanford Notebook
 * Description: Min cost bipartite matching. Negate costs for max cost.
 * Time: O(N^3)
 * Status: tested during ICPC 2015
 */
#pragma once

// typedef vector<double> vd; /// include-line
bool zero(double x) { return fabs(x) < 1e-10; }
double MinCostMatching(
    const vector<vd>& cost, vector<int>& L, vector<int>& R) {
	int n = cost.size(), mated = 0;
	vd dist(n), u(n), v(n);
	vector<int> dad(n), seen(n);

	/// construct dual feasible solution
	for (int i=0; i<n; i++) {
		u[i] = cost[i][0];
		for (int j=1; j<n; j++) u[i] = min(u[i], cost[i][j]);
	}
	for (int j=0; j<n; j++) {
		v[j] = cost[0][j] - u[0];
		for (int i=1; i<n; i++) v[j] = min(v[j], cost[i][j] - u[i]);
	}

	/// find primal solution satisfying complementary slackness
	L = R = vector<int>(n, -1);
	for (int i=0; i<n; i++) for (int j=0; j<n; j++) {
		if (R[j] != -1) continue;
		if (zero(cost[i][j] - u[i] - v[j])) {
			L[i] = j;
			R[j] = i;
			mated++;
			break;
		}
	}

	for (; mated < n; mated++) { // until solution is feasible
		int s = 0;
		while (L[s] != -1) s++;
		fill(dad.begin(), dad.end(), -1);
		fill(seen.begin(), seen.end(), 0);
		for (int k=0; k<n; k++) dist[k] = cost[s][k] - u[s] - v[k];

		int j = 0;
		for (;;) { /// find closest
			j = -1;
			for (int k=0; k<n; k++){
				if (seen[k]) continue;
				if (j == -1 || dist[k] < dist[j]) j = k;
			}
			seen[j] = 1;
			int i = R[j];
			if (i == -1) break;
			for (int k=0; k<n; k++) { /// relax neighbors
				if (seen[k]) continue;
				auto new_dist = dist[j] + cost[i][k] - u[i] - v[k];
				if (dist[k] > new_dist) {
					dist[k] = new_dist;
					dad[k] = j;
				}
			}
		}

		/// update dual variables
		for (int k=0; k<n; k++) {
			if (k == j || !seen[k]) continue;
			auto w = dist[k] - dist[j];
			v[k] += w, u[R[k]] -= w;
		}
		u[s] += dist[j];

		/// augment along path
		while (dad[j] >= 0) {
			int d = dad[j];
			R[j] = R[d];
			L[R[j]] = j;
			j = d;
		}
		R[j] = s;
		L[s] = j;
	}
	auto value = vd(1)[0];
	for (int i=0; i<n; i++) value += cost[i][L[i]];
	return value;
}


./content/number-theory/CRT.h
/**
 * Author: David Zheng
 * Description: Chinese Remainder Theorem. Solves the congruences $x \equiv a_1 \pmod{m_1}, x \equiv a_2 \pmod{m_2}$ $(0 \le a_1 < m_1, 0 \le a_2 < m_2)$
 * Returns true and $0 \le A < M$ if possible, false otherwise.
 * Status: tested CCPC2018K
 * Time: $O(\log(\min(m_1, m_2)))$
 */
#pragma once

#include "Euclid.h"
bool chin_rem(ll a1, ll m1, ll a2, ll m2, ll& A, ll& M) {
  ll X1, X2, d = egcd(m1, m2, X1, X2); if (a1 % d != a2 % d) return 0;
  M = m1/d*m2, A = ((X1*(a2/d)%m2*m1 + X2*(a1/d)%m1*m2 + a1%d)%M + M)%M;
  return 1; }


./content/number-theory/ContinuedFractions.h
/**
 * Author: Simon Lindholm
 * Date: 2018-07-15
 * License: CC0
 * Source: Wikipedia
 * Description: Given $N$ and a real number $x \ge 0$, finds the closest rational approximation $p/q$ with $p, q \le N$.
 * It will obey $|p/q - x| \le 1/qN$.
 *
 * For consecutive convergents, $p_{k+1}q_k - q_{k+1}p_k = (-1)^k$.
 * ($p_k/q_k$ alternates between $>x$ and $<x$.)
 * If $x$ is rational, $y$ eventually becomes $\infty$;
 * if $x$ is the root of a degree $2$ polynomial the $a$'s eventually become cyclic.
 * Time: O(\log N)
 * Status: fuzz-tested for n <= 300
 */

typedef double d; // for N ~ 1e7; long double for N ~ 1e9
pair<ll, ll> approximate(d x, ll N) {
	ll LP = 0, LQ = 1, P = 1, Q = 0, inf = LLONG_MAX; d y = x;
	for (;;) {
		ll lim = min(P ? (N-LP) / P : inf, Q ? (N-LQ) / Q : inf),
		   a = (ll)floor(y), b = min(a, lim),
		   NP = b*P + LP, NQ = b*Q + LQ;
		if (a > b) {
			// If b > a/2, we have a semi-convergent that gives us a
			// better approximation; if b = a/2, we *may* have one.
			// Return {P, Q} here for a more canonical approximation.
			return (abs(x - (d)NP / (d)NQ) < abs(x - (d)P / (d)Q)) ?
				make_pair(NP, NQ) : make_pair(P, Q);
		}
		if (abs(y = 1/(y - (d)a)) > 3*N) {
			return {NP, NQ};
		}
		LP = P; P = NP;
		LQ = Q; Q = NQ;
	}
}


./content/number-theory/Diophantine.h
/**
 * Author: Adam Beacham, Howard Cheng
 * Description: Finds integer solutions to $a_0x_0 + a_1x_1 + \dots + a_{n-1}x_{n-1} = c$. Assumes $a_i \neq 0$.
 * If a solution exists, provides a solution in \texttt{sol}, and basis vectors to the solution space \texttt{bas[0], ..., bas[n-1]}
 * (i.e. all solutions are given by \texttt{sol + t[0]*bas[0] + ... + t[n-1]*bas[n-1]}, where \texttt{t[i]} are arbitrary integers.
 */
#pragma once

#include "Euclid.h"

ll gcd_solve(ll a[MAXN], int numV, ll sol[MAXN],
             ll bas[MAXN-1][MAXN]) {
  ll ret, d, v, i;
  if (numV == 2) {
    ret = egcd(a[0], a[1], sol[0], sol[1]);
    bas[0][0] = a[1]/ret; bas[0][1] = -a[0]/ret;
  } else if (numV > 2) {
    d = gcd_solve(a, numV-1, sol, bas);
    ret = egcd(d, a[numV-1], v, sol[numV-1]);
    for (i=0; i<numV-1; i++) {
      bas[numV-2][i] = a[numV-1]/ret * sol[i];
      sol[i] *= v; }
    bas[numV-2][numV-1] = -d/ret;
  } return ret; }
bool diophantine(ll a[MAXN], int numV, ll c, ll sol[MAXN],
                 ll bas[MAXN-1][MAXN]) {
  assert(numV > 1); ll i,j,d,q;
  for (i=0; i<numV; i++) assert(a[i] != 0);
  for (i=0; i<numV-1; i++) for (j=0; j<numV; j++) bas[i][j] = 0;
  d = gcd_solve(a, numV, sol, bas);
  if (c % d == 0) { q = c/d;
    for (i=0; i<numV; i++) sol[i] *= q;
    return true;
  } return false; }


./content/number-theory/Euclid.h
/**
 * Description: Extended Euclidean algorithm: finds $x$ and $y$ such that $ax + by = d = \gcd(a, b)$.
 *
 * Computing $a^{-1} \bmod{m}$: \texttt{if(egcd(a,m,x,y)==1) return (x+m)\%m; else ERROR}
 * Time: O(\log(\min(a, b)))
 */

#pragma once

ll egcd(ll a, ll b, ll& x, ll &y) { if (!b) {x=1; y=0; return a;}
  // to ensure d>=0: x=sgn(a);y=0;return abs(a);       ^^^^^^^^
  ll d = egcd(b, a%b, y, x); y -= x * (a/b); return d; }

// Assuming a != 0, find smallest y >= 0 such that ax+by=c (if possible)
bool canon_egcd(ll a, ll b, ll c, ll& x, ll& y) {
  ll d = egcd(a, b, x, y), z = abs(a/d); if (c%d) return false;
  y = (y*(c/d)%z + z)%z, x = (c - b*y)/a; return true; }


./content/number-theory/Factor.h
/**
 * Author: brandonzhang
 * Description: Pollard-rho randomized factorization algorithm. \texttt{get\_factor(n)} finds an arbitrary divisor of \textbf{composite} $n$.
 * Status: tested SPOJ PRIC, FACT2, CF100956C
 * Time: $O(\sqrt{p})$ gcd calls where $p$ is the smallest factor of $n$
 */
#pragma once

#include "ModMulLL.h"
#include "MillerRabin.h"

mt19937 rng;
ll get_factor(ll n) { if (n%2 == 0) return 2; if (is_prime(n)) return n;
  while (1) { ll x = rng()%(n-1)+1, c = rng()%(n-1)+1, y = 2, d = 1;
    // optimization: break when sz becomes too large
    for (int sz = 2; d == 1; sz *= 2) {
      for (int i = 0; i < sz && d <= 1; i++)
        x = (mod_mul(x,x,n)+c) % n, d = __gcd(abs(x-y), n);
    /* can replace above with the below to reduce # of gcd computations
      ll z = 1;
      for (int i = 0; i < sz && d <= 1; ) { ll px = x;
        for (int j = 0; i < sz && d <= 1 && j < 100; i++, j++)
          x = (mod_mul(x,x,n)+c)%n, z = mod_mul(z, x-y, n);
        z = abs(z); d = __gcd(z, n);
        if (d == n) { x = px, d = 1;
          for (int j = 0; d <= 1 && j < 100; j++)
            x = (mod_mul(x, x, n)+c)%n, d = __gcd(abs(x-y), n); } } */
      y = x; } if (d > 1 && d != n) return d; } }
void prime_factor(ll n) { while (n > 1) { ll k = get_factor(n);
    while (!is_prime(k)) k = get_factor(k);
    // k is a prime factor
    while (n % k == 0) n /= k; } }


./content/number-theory/Farey.h
/**
 * Description: Generates the Farey sequence of order $n$ (the sorted sequence of fractions between $0$ and $1$ in lowest terms).
 */

#pragma once

vector<pair<int, int>> farey(int n) { vector<pair<int, int>> res;
  int a=0, b=1, c=1, d=n, k; res.push_back({0, 1});
  while (c < n) { k = (n+b)/d; swap(a, c); swap(b, d);
    c = k*a-c; d = k*b-d; res.push_back({a, b}); }
  if (n==1) res.push_back({1, 1}); return res; }


./content/number-theory/FracBinarySearch.h
/**
 * Author: Lucian Bicsi, Simon Lindholm
 * Date: 2017-10-31
 * License: CC0
 * Description: Given $f$ and $N$, finds the smallest fraction $p/q \in [0, 1]$
 * such that $f(p/q)$ is true, and $p, q \le N$.
 * You may want to throw an exception from $f$ if it finds an exact solution,
 * in which case $N$ can be removed.
 * Usage: fracBS([](Frac f) { return f.p>=3*f.q; }, 10); // {1,3}
 * Time: O(\log(N))
 * Status: fuzz-tested for n <= 300
 */

struct Frac { ll p, q; };

template<class F>
Frac fracBS(F f, ll N) {
	bool dir = 1, A = 1, B = 1;
	Frac lo{0, 1}, hi{1, 1}; // Set hi to 1/0 to search (0, N]
	if (f(lo)) return lo;
	assert(f(hi));
	while (A || B) {
		ll adv = 0, step = 1; // move hi if dir, else lo
		for (int si = 0; step; (step *= 2) >>= si) {
			adv += step;
			Frac mid{lo.p * adv + hi.p, lo.q * adv + hi.q};
			if (abs(mid.p) > N || mid.q > N || dir == !f(mid)) {
				adv -= step; si = 2;
			}
		}
		hi.p += lo.p * adv;
		hi.q += lo.q * adv;
		dir = !dir;
		swap(lo, hi);
		A = B; B = !!adv;
	}
	return dir ? hi : lo;
}


./content/number-theory/MillerRabin.h
/**
 * Author: brandonzhang
 * Description: Deterministic Miller-Rabin primality test.
 * For $n < 2 \cdot 10^9$, use \texttt{wit[] = \{2, 7, 61\}}. For $n > 2^{64}$, use random witnesses.
 * Trial division on small primes ($<50$) can lead to $>2\times$ speedup.
 * Status: tested SPOJ PRIC, FACT2, CF100956C
 * Time: 7 times the complexity of $a^b \mod c$.
 */
#pragma once

#include "ModMulLL.h"
const ll wit[] = {2, 325, 9375, 28178, 450775, 9780504, 1795265022};
bool is_prime(ll n) { if (n<2) return 0; if (n%2 == 0) return n == 2;
  ll r = __builtin_ctzll(n-1), d = (n-1)>>r;
  for (ll a : wit) { a %= n; if (!a) return 1;
    if (a == 1 || a == n-1) continue;
    ll x = mod_pow(a,d,n), y;
    for (int i = 0; i < r; i++) { y = mod_mul(x,x,n);
      if (y == 1 && x != 1 && x != n-1) return 0; x = y; }
    if (x != 1) return 0; } return 1; }


./content/number-theory/ModInverse.h
/**
 * Author: brandonzhang
 * Description: Precomputes $a^{-1} \bmod{P}$ for all $a = 1, \dots, N-1$. $P$ must be prime.
 * Status: tested
 * Time: O(N)
 */
#pragma once

int P, inv[N];
void calc() {
  inv[1]=1; for (int i=2; i<N; i++) inv[i]=P-(ll)(P/i)*inv[P%i]%P; }


./content/number-theory/ModLog.h
/**
 * Description: Returns smallest $x$ such that $a^x \equiv b \pmod{M}$ or $-1$ if no such $x$ exists.
 * Time: O(\sqrt{M})
 */
#pragma once

#include "ModPow.h"

ll modlog(ll a, ll b, ll M) { ll s = (ll)sqrt(M), p, i;
  unordered_map<ll, ll> H; while (s*s < M) ++s;
  for (i = 0, p = 1; i < s; ++i, p = (p*a)%M) if (!H.count(p)) H[p] = i;
  for (i = 0, p = modpow(a, M-1-s, M); i < s; ++i, b = (b*p)%M)
    if (H.count(b)) return i*s+H[b];
  return -1; }


./content/number-theory/ModMulLL.h
/**
 * Author: chilli, Ramchandra Apte, Noam527
 * Date: 2019-04-24
 * License: CC0
 * Source: https://github.com/RamchandraApte/OmniTemplate/blob/master/modulo.h
 * Proof of correctness is in doc/modmul-proof.md.
 * Description: Calculate $a\cdot b\bmod c$ (or $a^b \bmod c$) for $0 \le a, b < c < 2^{63}$.
 * Time: O(1) for \texttt{mod\_mul}, O(\log b) for \texttt{mod\_pow}
 * Status: fuzz-tested, proven correct
 */
#pragma once

typedef unsigned long long ull;
typedef long double ld;
// WARNING: this is broken (use (__int128) a*b % M or repeated doubling)
ull mod_mul(ull a, ull b, ull M) {
	ll ret = a * b - M * ull(ld(a) * ld(b) / ld(M));
	return ret + M * (ret < 0) - M * (ret >= (ll)M);
}
ull mod_pow(ull b, ull e, ull mod) {
	ull ans = 1;
	for (; e; b = mod_mul(b, b, mod), e /= 2)
		if (e & 1) ans = mod_mul(ans, b, mod);
	return ans;
}


./content/number-theory/ModPow.h
/**
 * Author: Noam527
 * Date: 2019-04-24
 * License: CC0
 * Source: folklore
 * Description:
 * Status: tested
 */
#pragma once

ll modpow(ll b, ll e, ll mod) {
	ll ans = 1;
	for (; e; b = b * b % mod, e /= 2)
		if (e & 1) ans = ans * b % mod;
	return ans;
}


./content/number-theory/ModSqrt.h
/**
 * Author: Simon Lindholm
 * Date: 2016-08-31
 * License: CC0
 * Source: http://eli.thegreenplace.net/2009/03/07/computing-modular-square-roots-in-python/
 * Description: Tonelli-Shanks algorithm for modular square roots.
 * Time: O(\log^2 p) worst case, often O(\log p)
 * Status: Tested for all a,p <= 10000
 */
#pragma once

#include "ModPow.h"

// the modular square root exists iff legendre(a, p) >= 0
int legendre(ll a, ll p) {
  return (a%p)?(modpow(a, (p-1)/2, p)==1?1:-1):0; }

ll sqrt(ll a, ll p) {
	a %= p; if (a < 0) a += p;
	if (a == 0) return 0;
	assert(legendre(a, p) == 1);
	if (p % 4 == 3) return modpow(a, (p+1)/4, p);
	// a^(n+3)/8 or 2^(n+3)/8 * 2^(n-1)/4 works if p % 8 == 5
	ll s = p - 1, n = 2;
	int r = 0, m;
	while (s % 2 == 0)
		++r, s /= 2;
	/// find a non-square mod p
	while (modpow(n, (p - 1) / 2, p) != p - 1) ++n;
	ll x = modpow(a, (s + 1) / 2, p);
	ll b = modpow(a, s, p), g = modpow(n, s, p);
	for (;; r = m) {
		ll t = b;
		for (m = 0; m < r && t != 1; ++m)
			t = t * t % p;
		if (m == 0) return x;
		ll gs = modpow(g, 1LL << (r - m - 1), p);
		g = gs * gs % p;
		x = x * gs % p;
		b = b * g % p;
	}
}


./content/number-theory/ModSum.h
/**
 * Author: Simon Lindholm
 * Date: 2015-06-23
 * License: CC0
 * Source: own work
 * Description: Sums of mod'ed arithmetic progressions.
 *
 * \texttt{modsum(to, c, k, m)} = $\sum_{i=0}^{\mathrm{to}-1}{(ki+c) \% m}$.
 * \texttt{divsum} is similar but for floored division.
 * Status: Tested for |k|,|c|,to,m <= 50, and on "aladin" on kattis.
 * Time: $\log(m)$, with a large constant.
 */
#pragma once

typedef unsigned long long ull;
ull sumsq(ull to) { return to / 2 * ((to-1) | 1); }

ull divsum(ull to, ull c, ull k, ull m) {
	ull res = k / m * sumsq(to) + c / m * to;
	k %= m; c %= m;
	if (!k) return res;
	ull to2 = (to * k + c) / m;
	return res + (to - 1) * to2 - divsum(to2, m-1 - c, m, k);
}

ll modsum(ull to, ll c, ll k, ll m) {
	c = ((c % m) + m) % m;
	k = ((k % m) + m) % m;
	return to * c + k * sumsq(to) - m * divsum(to, c, k, m);
}


./content/number-theory/ModularArithmetic.h
/**
 * Author: Lukas Polacek
 * Date: 2009-09-28
 * License: CC0
 * Source: folklore
 * Description: Operators for modular arithmetic. You need to set {\tt mod} to
 * some number first and then you can use the structure.
 */
#pragma once

#include "euclid.h"

const ll mod = 17; // change to something else
struct Mod {
	ll x;
	Mod(ll xx) : x(xx) {}
	Mod operator+(Mod b) { return Mod((x + b.x) % mod); }
	Mod operator-(Mod b) { return Mod((x - b.x + mod) % mod); }
	Mod operator*(Mod b) { return Mod((x * b.x) % mod); }
	Mod operator/(Mod b) { return *this * invert(b); }
	Mod invert(Mod a) {
		ll x, y, g = euclid(a.x, mod, x, y);
		assert(g == 1); return Mod((x + mod) % mod);
	}
	Mod operator^(ll e) {
		if (!e) return Mod(1);
		Mod r = *this ^ (e / 2); r = r * r;
		return e&1 ? *this * r : r;
	}
};


./content/number-theory/PythagTriples.h
/**
 * Description: Returns all pythagorean triples with a, b, c < n.
 */

#pragma once

struct ptrip { int a, b, c; };
vector<ptrip> gen_triples(int n) { int a, b, p, q; vector<ptrip> res;
  for (p=2; p*p < n; p++) for (q=1+p%2; q < p && p*p+q*q < n; q += 2) {
    if (__gcd(p,q) != 1) continue;
    a = p*p-q*q; b = 2*p*q; if (a > b) swap(a, b);
    res.push_back({a, b, p*p+q*q});
  } return res; }


./content/number-theory/Sieve.h
/**
 * Author: brandonzhang
 * Description: Sieve to compute prime numbers and multiplicative functions.
 * The example given is $f(i) = \varphi(i)$, $e(i) =$ exponent of smallest prime divisor.
 * Usage:
 *   - write the correct recurrence for f on the commented lines
 *   - sieve()
 *   - ps = sorted list of primes, isc[i] = is i composite
 * Status: tested
 * Time: O(N)
 */

#pragma once

vector<int> ps; bool isc[N]; int f[N], e[N];
void sieve() { f[1] = 1;
  for (int i = 2; i < N; i++) { if (!isc[i]) {
      ps.push_back(i); f[i] = i-1; e[i] = 1; } // f(p) for prime p
    for (int ip, j = 0; j < ps.size() && (ip=i*ps[j]) < N; j++) {
      isc[ip] = 1;
      if (i % ps[j] == 0) {
        f[ip] = f[i] * ps[j]; // f(ip) = f(i/p**e[i])f(p**(e[i]+1))
        e[ip] = e[i] + 1; break;
      } else { f[ip] = f[i] * f[ps[j]]; e[ip] = 1; } // f(ip)=f(i)f(p)
    } } }


./content/numerical/BerlekampMassey.h
/**
 * Author: Lucian Bicsi
 * Date: 2017-10-31
 * License: CC0
 * Source: Wikipedia
 * Description: Recovers any $n$-order linear recurrence relation from the first
 * $2n$ terms of the recurrence.
 * Useful for guessing linear recurrences after brute-forcing the first terms.
 * Should work on any field, but numerical stability for floats is not guaranteed.
 * Output will have size $\le n$.
 * Usage: BerlekampMassey({0, 1, 1, 3, 5, 11}) // {1, 2}
 * Status: bruteforce-tested MOD 5 for n <= 5 and all s
 */
#pragma once

#include "../number-theory/ModPow.h"
const ll MOD = 1e9+7; /** exclude-line */

vector<ll> BerlekampMassey(vector<ll> s) {
	int n = s.size(), L = 0, m = 0;
	vector<ll> C(n), B(n), T;
	C[0] = B[0] = 1;

	ll b = 1;
  for (int i = 0; i < n; i++) { ++m;
		ll d = s[i] % MOD;
    for (int j = 1; j <= L; j++) d = (d + C[j] * s[i - j]) % MOD;
		if (!d) continue;
		T = C; ll coef = d * modpow(b, MOD-2, MOD) % MOD;
    for (int j = m; j < n; j++) C[j] = (C[j] - coef * B[j - m]) % MOD;
		if (2 * L > i) continue;
		L = i + 1 - L; B = T; b = d; m = 0;
	}

	C.resize(L + 1); C.erase(C.begin());
  for (auto& x : C) x = (MOD - x) % MOD;
	return C;
}


./content/numerical/Determinant.h
/**
 * Author: Simon Lindholm
 * Date: 2016-09-06
 * License: CC0
 * Source: folklore
 * Description: Calculates determinant of a matrix. Destroys the matrix.
 * Status: somewhat tested
 * Time: $O(N^3)$
 */
#pragma once

template <class T> T det(vector<vector<T>>& a) {
	int n = a.size(); T res = 1;
  for (int i = 0; i < n; i++) {
		int b = i;
    for (int j=i+1; j<n; j++) if (abs(a[j][i]) > abs(a[b][i])) b = j;
		if (i != b) swap(a[i], a[b]), res *= -1;
		res *= a[i][i];
		if (res == 0) return 0;
    for (int j = i+1; j < n; j++) {
			T v = a[j][i] / a[i][i];
			if (v != 0) for (int k = i+1; k < n; k++) a[j][k] -= v * a[i][k];
		}
	}
	return res;
}


./content/numerical/F2MatrixMultiplication.h
/**
 * Author: brandonzhang
 * Source: Algorithm 1 of http://www.gregorybard.com/papers/albrecht_bard_hart.pdf
 * Description: Multiplies two matrices with entries in $\mathbb{F}_2$.
 * Time: O(n^3/\log n/64), with a small constant factor
 * Status: tested cf100324G (square matrices)
 */
#pragma once

const int K = 7; // K ~ 0.7 log_2 n
using bs = bitset<N+K>;
using mat = vector<bs>;

vector<int> gray(int b) {
  if (b == 1) return {0};
  auto v = gray(b-1);
  const int n = v.size();
  v.push_back(b-1);
  for (int i = n-1; i >= 0; i--) {
    v.push_back(v[i]);
  }
  return v;
}
int read_bits(const bs& b, int x, int len) {
  int ans = 0;
  for (int i = 0; i < len; i++) {
    ans |= b[x+i] << i;
  }
  return ans;
}
// a is mxl, b is lxn
mat mul(const mat& a, mat& b, int m, int l, int n) {
  /// pad b so that l is divisible by K
  while (b.size() % K) b.emplace_back();
  mat ret(m);
  auto g = gray(K);
  vector<bs> t(1 << K); // t[bm] = sum_{j \in bm} b[i*K + j]
  for (int i = 0; i < b.size()/K; i++) {
    int bm = 0;
    bs cur;
    for (int j : g) {
      bm ^= 1 << j;
      cur ^= b[i*K + j];
      t[bm] = cur;
    }
    for (int j = 0; j < m; j++) {
      int x = read_bits(a[j], i*K, K);
      ret[j] ^= t[x];
    }
  }
  while (b.size() > l) b.pop_back();
  return ret;
}


./content/numerical/FastFourierTransform.h
/**
 * Author: Ludo Pulles, chilli, Simon Lindholm
 * Date: 2019-01-09
 * License: CC0
 * Source: http://neerc.ifmo.ru/trains/toulouse/2017/fft2.pdf (do read, it's excellent)
   Accuracy bound from http://www.daemonology.net/papers/fft.pdf
 * Description: fft(a) computes $\hat f(k) = \sum_x a[x] \exp(2\pi i \cdot k x / N)$ for all $k$. Useful for convolution:
   \texttt{conv(a, b) = c}, where $c[x] = \sum a[i]b[x-i]$.
   For convolution of complex numbers or more than two vectors: FFT, multiply
   pointwise, divide by n, reverse(start+1, end), FFT back.
   Rounding is safe if $(\sum a_i^2 + \sum b_i^2)\log_2{N} < 9\cdot10^{14}$
   (in practice $10^{16}$; higher for random inputs).
   Otherwise, use long doubles/NTT/FFTMod.
 * Time: O(N \log N) with $N = |A|+|B|$ ($\tilde 1s$ for $N=2^{22}$)
 * Status: somewhat tested
 */
#pragma once

typedef complex<ld> C;
typedef vector<ld> vd;
void fft(vector<C>& a) {
	int n = a.size(), L = 31 - __builtin_clz(n);
	static vector<complex<ld>> R(2, 1);
	static vector<C> rt(2, 1);  // (^ 10% faster if double)
	for (static int k = 2; k < n; k *= 2) {
		R.resize(n); rt.resize(n);
		auto x = polar(1.0L, PI / k);
    for (int i=k; i<2*k; i++) rt[i] = R[i] = i&1 ? R[i/2] * x : R[i/2];
	}
	vi rev(n);
  for (int i = 0; i < n; i++) rev[i] = (rev[i / 2] | (i & 1) << L) / 2;
  for (int i = 0; i < n; i++) if (i < rev[i]) swap(a[i], a[rev[i]]);
	for (int k = 1; k < n; k *= 2)
		for (int i = 0; i < n; i += 2 * k) for (int j = 0; j < k; j++) {
			// C z = rt[j+k] * a[i+j+k]; // (25% faster if hand-rolled)  /// include-line
			auto x = (ld *)&rt[j+k], y = (ld *)&a[i+j+k];        /// exclude-line
			C z(x[0]*y[0] - x[1]*y[1], x[0]*y[1] + x[1]*y[0]);           /// exclude-line
			a[i + j + k] = a[i + j] - z;
			a[i + j] += z;
		}
}
vd conv(const vd& a, const vd& b) {
	if (a.empty() || b.empty()) return {};
	vd res(a.size() + b.size() - 1);
	int L = 32 - __builtin_clz(res.size()), n = 1 << L;
	vector<C> in(n), out(n);
	copy(a.begin(), a.end(), in.begin());
  for (int i = 0; i < b.size(); i++) in[i].imag(b[i]);
	fft(in);
  for (auto& x : in) x *= x;
  for (int i = 0; i < n; i++) out[i] = in[-i & (n - 1)] - conj(in[i]);
	fft(out);
  for (int i = 0; i < res.size(); i++) res[i] = imag(out[i]) / (4 * n);
	return res;
}


./content/numerical/FastFourierTransformMod.h
/**
 * Author: chilli
 * Date: 2019-04-25
 * License: CC0
 * Source: http://neerc.ifmo.ru/trains/toulouse/2017/fft2.pdf
 * Description: Higher precision FFT, can be used for convolutions modulo arbitrary integers
 * as long as $N\log_2N\cdot \text{mod} < 8.6 \cdot 10^{14}$ (in practice $10^{16}$ or higher).
 * Inputs must be in $[0, \text{mod})$.
 * Time: O(N \log N), where $N = |A|+|B|$ (twice as slow as NTT or FFT)
 * Status: somewhat tested
 */
#pragma once

#include "FastFourierTransform.h"

typedef vector<ll> vl;
template<int M> vl convMod(const vl &a, const vl &b) {
	if (a.empty() || b.empty()) return {};
	vl res(a.size() + b.size() - 1);
	int B=32-__builtin_clz(res.size()), n=1<<B, cut=int(sqrt(M));
	vector<C> L(n), R(n), outs(n), outl(n);
  for (int i=0;i<a.size();i++) L[i]=C((int)a[i] / cut, (int)a[i] % cut);
  for (int i=0;i<b.size();i++) R[i]=C((int)b[i] / cut, (int)b[i] % cut);
	fft(L), fft(R);
  for (int i = 0; i < n; i++) {
		int j = -i & (n - 1);
		outl[j] = (L[i] + conj(L[j])) * R[i] / (2.L * n);
		outs[j] = (L[i] - conj(L[j])) * R[i] / (2.L * n) / C(0, 1);
	}
	fft(outl), fft(outs);
  for (int i = 0; i < res.size(); i++) {
		ll av = ll(real(outl[i])+.5), cv = ll(imag(outs[i])+.5);
		ll bv = ll(imag(outl[i])+.5) + ll(real(outs[i])+.5);
		res[i] = ((av % M * cut + bv) % M * cut + cv) % M;
	}
	return res;
}


./content/numerical/FastSubsetTransform.h
/**
 * Author: Lucian Bicsi
 * Date: 2015-06-25
 * License: GNU Free Documentation License 1.2
 * Source: csacademy
 * Description: Transform to a basis with fast convolutions of the form
 * $\displaystyle c[z] = \sum\nolimits_{z = x \oplus y} a[x] \cdot b[y]$,
 * where $\oplus$ is one of AND, OR, XOR. The size of $a$ must be a power of two.
 * Time: O(N \log N)
 * Status: tested
 */
#pragma once

void FST(vi& a, bool inv) {
	for (int n = a.size(), step = 1; step < n; step *= 2) {
		for (int i=0; i<n; i += 2 * step) for (int j=i; j<i+step; j++) {
			ll &u = a[j], &v = a[j + step]; tie(u, v) =
				inv ? pii(v - u, u) : pii(v, u + v); // AND
				// inv ? pii(v, u - v) : pii(u + v, u); // OR /// include-line
				// pii(u + v, u - v);                   // XOR /// include-line
		}
	}
	// if (inv) for (auto& x : a) x /= a.size(); // XOR only /// include-line
}
vi conv(vi a, vi b) {
	FST(a, 0); FST(b, 0);
  for (int i = 0; i < a.size(); i++) a[i] *= b[i];
	FST(a, 1); return a;
}


./content/numerical/GoldenSectionSearch.h
/**
 * Author: Ulf Lundstrom
 * Date: 2009-04-17
 * License: CC0
 * Source: Numeriska algoritmer med matlab, Gerd Eriksson, NADA, KTH
 * Description: Finds the argument minimizing the function $f$ in the interval $[a,b]$ assuming $f$ is unimodal on the interval, i.e. has only one local minimum. The maximum error in the result is $eps$. Works equally well for maximization with a small change in the code. See TernarySearch.h in the Various chapter for a discrete version.
 * Status: tested
 * Usage:
	ld func(ld x) { return 4+x+.3*x*x; }
	ld xmin = gss(-1000,1000,func);
 * Time: O(\log((b-a) / \epsilon))
 */
#pragma once

/// It is important for r to be precise, otherwise we don't necessarily maintain the inequality a < x1 < x2 < b.
template <class T> ld gss(ld a, ld b, T f) {
	ld r = (sqrt(5.L)-1)/2, eps = 1e-7;
	ld x1 = b - r*(b-a), x2 = a + r*(b-a);
	ld f1 = f(x1), f2 = f(x2);
	while (b-a > eps)
		if (f1 < f2) { //change to > to find maximum
			b = x2; x2 = x1; f2 = f1;
			x1 = b - r*(b-a); f1 = f(x1);
		} else {
			a = x1; x1 = x2; f1 = f2;
			x2 = a + r*(b-a); f2 = f(x2);
		}
	return a;
}


./content/numerical/HillClimbing.h
/**
 * Author: Simon Lindholm
 * Date: 2015-02-04
 * License: CC0
 * Source: Johan Sannemo
 * Description: Poor man's optimization for unimodal functions.
 * Status: used with great success
 */
#pragma once

typedef array<ld, 2> P;

ld func(P p) { return p[0] + p[1]; }

pair<ld, P> hillClimb(P start) {
	pair<ld, P> cur(func(start), start);
	for (ld jmp = 1e9; jmp > 1e-20; jmp /= 2) {
    for (int j = 0; j < 100; j++) {
      for (int dx = -1; dx <= 1; dx++) for (int dy = -1; dy <= 1; dy++) {
        P p = cur.second;
        p[0] += dx*jmp;
        p[1] += dy*jmp;
        cur = min(cur, make_pair(func(p), p));
      }
    }
	}
	return cur;
}


./content/numerical/IntDeterminant.h
/**
 * Author: Unknown
 * Date: 2014-11-27
 * Source: somewhere on github
 * Description: Calculates determinant using modular arithmetics.
 * Modulos can also be removed to get a pure-integer version.
 * Status: bruteforce-tested for N <= 3, mod <= 7
 * Time: $O(N^3)$
 */
#pragma once

const ll mod = 12345; /** exclude-line */
ll det(vector<vector<ll>>& a) {
	int n = a.size(); ll ans = 1;
  for (int i = 0; i < n; i++) {
    for (int j = i+1; j < n; j++) {
			while (a[j][i] != 0) { // gcd step
				ll t = a[i][i] / a[j][i];
				if (t) for (int k = i; k < n; k++)
					a[i][k] = (a[i][k] - a[j][k] * t) % mod;
				swap(a[i], a[j]);
				ans *= -1;
			}
		}
		ans = ans * a[i][i] % mod;
		if (!ans) return 0;
	}
	return (ans + mod) % mod;
}


./content/numerical/Integrate.h
/**
 * Author: Simon Lindholm
 * Date: 2015-02-11
 * License: CC0
 * Source: Wikipedia
 * Description: Simple integration of a function over an interval using
 *  Simpson's rule. The error should be proportional to $h^4$, although in
 *  practice you will want to verify that the result is stable to desired
 *  precision when epsilon changes.
 * Status: mostly untested
 */
#pragma once

template<class F>
ld quad(ld a, ld b, F f, const int n = 1000) {
	ld h = (b - a) / 2 / n, v = f(a) + f(b);
  for (int i = 1; i < n*2; i++)
		v += f(a + i*h) * (i&1 ? 4 : 2);
	return v * h / 3;
}


./content/numerical/IntegrateAdaptive.h
/**
 * Author: Simon Lindholm
 * Date: 2015-02-11
 * License: CC0
 * Source: Wikipedia
 * Description: Fast integration using an adaptive Simpson's rule.
 * Status: mostly untested
 * Usage:
	double sphereVolume = quad(-1, 1, [](double x) {
	return quad(-1, 1, [\&](double y) {
	return quad(-1, 1, [\&](double z) {
	return x*x + y*y + z*z < 1; });});});
 */
#pragma once

typedef double d;
#define S(a,b) (f(a) + 4*f((a+b) / 2) + f(b)) * (b-a) / 6

template <class F>
d rec(F& f, d a, d b, d eps, d S) {
	d c = (a + b) / 2;
	d S1 = S(a, c), S2 = S(c, b), T = S1 + S2;
	if (abs(T - S) <= 15 * eps || b - a < 1e-10)
		return T + (T - S) / 15;
	return rec(f, a, c, eps / 2, S1) + rec(f, c, b, eps / 2, S2);
}
template<class F>
d quad(d a, d b, F f, d eps = 1e-8) {
	return rec(f, a, b, eps, S(a, b));
}


./content/numerical/LinearRecurrence.h
/**
 * Author: Lucian Bicsi
 * Date: 2018-02-14
 * License: CC0
 * Source: Chinese material
 * Description: Generates the $k$'th term of an $n$-order
 * linear recurrence $S[i] = \sum_j S[i-j-1]tr[j]$,
 * given $S[0 \ldots \ge n-1]$ and $tr[0 \ldots n-1]$.
 * Faster than matrix multiplication.
 * Useful together with Berlekamp--Massey.
 * Usage: linearRec({0, 1}, {1, 1}, k) // k'th Fibonacci number
 * Time: O(n^2 \log k)
 * Status: bruteforce-tested MOD 5 for n <= 5
 */
#pragma once

const ll MOD = 5; /** exclude-line */

typedef vector<ll> Poly;
ll linearRec(Poly S, Poly tr, ll k) {
	int n = tr.size();

	auto combine = [&](Poly a, Poly b) {
		Poly res(n * 2 + 1);
    for (int i = 0; i <= n; i++) for (int j = 0; j <= n; j++)
			res[i + j] = (res[i + j] + a[i] * b[j]) % MOD;
		for (int i = 2 * n; i > n; --i) for (int j = 0; j < n; j++)
			res[i - 1 - j] = (res[i - 1 - j] + res[i] * tr[j]) % MOD;
		res.resize(n + 1);
		return res;
	};

	Poly pol(n + 1), e(pol);
	pol[0] = e[1] = 1;

	for (++k; k; k /= 2) {
		if (k % 2) pol = combine(pol, e);
		e = combine(e, e);
	}

	ll res = 0;
	for (int i = 0; i < n; i++) res = (res + pol[i + 1] * S[i]) % MOD;
	return res;
}


./content/numerical/MatrixInverse-mod.h
/**
 * Author: Simon Lindholm
 * Date: 2016-12-08
 * Source: The regular matrix inverse code
 * Description: Invert matrix $A$ modulo a prime.
 * Returns rank; result is stored in $A$ unless singular (rank < n).
 * For prime powers, repeatedly set $A^{-1} = A^{-1} (2I - AA^{-1})\  (\text{mod }p^k)$ where $A^{-1}$ starts as
 * the inverse of A mod p, and k is doubled in each step.
 * Time: O(n^3)
 * Status: Slightly tested
 */
#pragma once

#include "../number-theory/ModPow.h"

int matInv(vector<vector<ll>>& A) {
	int n = sz(A); vi col(n);
	vector<vector<ll>> tmp(n, vector<ll>(n));
	rep(i,0,n) tmp[i][i] = 1, col[i] = i;

	rep(i,0,n) {
		int r = i, c = i;
		rep(j,i,n) rep(k,i,n) if (A[j][k]) {
			r = j; c = k; goto found;
		}
		return i;
found:
		A[i].swap(A[r]); tmp[i].swap(tmp[r]);
		rep(j,0,n) swap(A[j][i], A[j][c]), swap(tmp[j][i], tmp[j][c]);
		swap(col[i], col[c]);
		ll v = modpow(A[i][i], mod - 2);
		rep(j,i+1,n) {
			ll f = A[j][i] * v % mod;
			A[j][i] = 0;
			rep(k,i+1,n) A[j][k] = (A[j][k] - f*A[i][k]) % mod;
			rep(k,0,n) tmp[j][k] = (tmp[j][k] - f*tmp[i][k]) % mod;
		}
		rep(j,i+1,n) A[i][j] = A[i][j] * v % mod;
		rep(j,0,n) tmp[i][j] = tmp[i][j] * v % mod;
		A[i][i] = 1;
	}

	for (int i = n-1; i > 0; --i) rep(j,0,i) {
		ll v = A[j][i];
		rep(k,0,n) tmp[j][k] = (tmp[j][k] - v*tmp[i][k]) % mod;
	}

	rep(i,0,n) rep(j,0,n)
		A[col[i]][col[j]] = tmp[i][j] % mod + (tmp[i][j] < 0 ? mod : 0);
	return n;
}


./content/numerical/MatrixInverse.h
/**
 * Author: Max Bennedich
 * Date: 2004-02-08
 * Description: Invert matrix $A$. Returns rank; result is stored in $A$ unless singular (rank < n).
 * Can easily be extended to prime moduli; for prime powers, repeatedly
 * set $A^{-1} = A^{-1} (2I - AA^{-1})\  (\text{mod }p^k)$ where $A^{-1}$ starts as
 * the inverse of A mod p, and k is doubled in each step.
 * Time: O(n^3)
 * Status: Slightly tested
 */
#pragma once

int matInv(vector<vector<ld>>& A) {
	int n = A.size(); vi col(n);
	vector<vector<ld>> tmp(n, vector<ld>(n));
  for (int i = 0; i < n; i++) tmp[i][i] = 1, col[i] = i;

  for (int i = 0; i < n; i++) {
    int r = i, c = i;
    for (int j = i; j < n; j++) for (int k = i; k < n; k++)
			if (abs(A[j][k]) > abs(A[r][c]))
				r = j, c = k;
		if (abs(A[r][c]) < 1e-12) return i;
		A[i].swap(A[r]); tmp[i].swap(tmp[r]);
    for (int j = 0; j < n; j++)
			swap(A[j][i], A[j][c]), swap(tmp[j][i], tmp[j][c]);
		swap(col[i], col[c]);
		ld v = A[i][i];
    for (int j = i+1; j < n; j++) {
			ld f = A[j][i] / v;
			A[j][i] = 0;
      for (int k = i+1; k < n; k++) A[j][k] -= f*A[i][k];
      for (int k = 0; k < n; k++) tmp[j][k] -= f*tmp[i][k];
		}
    for (int j = i+1; j < n; j++) A[i][j] /= v;
    for (int j = 0; j < n; j++) tmp[i][j] /= v;
		A[i][i] = 1;
	}

	/// forget A at this point, just eliminate tmp backward
	for (int i = n-1; i > 0; --i) for (int j = 0; j < i; j++) {
		ld v = A[j][i];
    for (int k = 0; k < n; k++) tmp[j][k] -= v*tmp[i][k];
	}

  for (int i=0; i<n; i++) for (int j=0; j<n; j++) {
    A[col[i]][col[j]]=tmp[i][j];
  }
	return n;
}


./content/numerical/NumberTheoreticTransform.h
/**
 * Author: chilli
 * Date: 2019-04-16
 * License: CC0
 * Source: based on KACTL's FFT
 * Description: Can be used for convolutions modulo specific nice primes
 * of the form $2^a b+1$, where the convolution result has size at most $2^a$.
 * Inputs must be in [0, mod).
 * Time: O(N \log N)
 * Status: fuzz-tested
 */
#pragma once

#include "../number-theory/ModPow.h"

const ll mod = (119 << 23) + 1, root = 62; // = 998244353
// For p < 2^30 there is also e.g. 5 << 25, 7 << 26, 479 << 21
// and 483 << 21 (same root). The last two are > 10^9.
typedef vector<ll> vl;
void ntt(vl& a, vl& rt, vl& rev, int n) {
  for (int i = 0; i < n; i++) if (i < rev[i]) swap(a[i], a[rev[i]]);
	for (int k = 1; k < n; k *= 2)
		for (int i = 0; i < n; i += 2 * k) for (int j = 0; j < k; j++) {
				ll z = rt[j + k] * a[i + j + k] % mod, &ai = a[i + j];
				a[i + j + k] = (z > ai ? ai - z + mod : ai - z);
				ai += (ai + z >= mod ? z - mod : z);
	}
}

vl conv(const vl& a, const vl& b) {
	if (a.empty() || b.empty()) return {};
	int s = a.size()+b.size()-1, B = 32 - __builtin_clz(s), n = 1 << B;
	vl L(a), R(b), out(n), rt(n, 1), rev(n);
	L.resize(n), R.resize(n);
  for (int i = 0; i < n; i++) rev[i] = (rev[i / 2] | (i & 1) << B) / 2;
	ll curL = mod / 2, inv = modpow(n, mod - 2, mod);
	for (int k = 2; k < n; k *= 2) {
		ll z[] = {1, modpow(root, curL /= 2, mod)};
    for (int i = k; i < 2*k; i++) rt[i] = rt[i / 2] * z[i & 1] % mod;
	}
	ntt(L, rt, rev, n); ntt(R, rt, rev, n);
  for (int i=0;i<n;i++) out[-i & (n-1)] = L[i] * R[i] % mod * inv % mod;
	ntt(out, rt, rev, n);
	return {out.begin(), out.begin() + s};
}


./content/numerical/OldSimplex.h
/**
 * Author: Simon Lo
 * Source: UBC
 * Description: Simplex algorithm on augmented matrix a of dimension (m+1)x(n+1)
 * first m rows describe constraints, last row describes objective function.
 * Usage: returns 1 if feasible, 0 if not feasible, -1 if unbounded
 * returns solution in b[] in original var order, max(f) in ret
 * form; maximize sum_j(a_mj*x_j)-a_mn s.t. sum_j(a_ij*x_j)<=a_in
 * in standard form.
 * To convert into standard form:
 * 1. if exists equality constraint, then replace by both >= and <=
 * 2. if variable x doesn't have nonnegativity constraint, then replace by
 *    difference of 2 variables like x1-x2, where x1>=0, x2>=0
 * 3. for a>=b constraints, convert to -a<=-b
 * 4. turn minimizing condition into maximizing by multiplying -1 to obj.func.
 * note; watch out for -0.0 in the solution, algorithm may cycle
 * EPS = 1e-7 may give wrong answer, 1e-10 is better
 * A way to fix problems: find another way to test feasibility, and if feasible,
 * gradually relax EPS until you get answer. This may be more robust.
 * Or use __float128 instead of long double, but its 10x slower.
 * On average, simplex is O( m * log n). If there are many equations and few
 * variables, its more efficient to use the dual:
 * normal; max c^T*x, s.t. Ax <= b <---> dual: min b^T*y, s.t. A^T*y >= c.
 * Status: seems to work?
 */
#pragma once

void pivot(int m,int n,ld a[MAXM][MAXN],
           int B[MAXM],int N[MAXN],int r,int c) {
  int i,j; swap(N[c], B[r]); a[r][c]=1/a[r][c];
  for(j=0;j<=n;j++) if(j!=c) a[r][j]*=a[r][c];
  for(i=0;i<=m;i++) if(i!=r) {
    for(j=0;j<=n;j++) if(j!=c) a[i][j]-=a[i][c]*a[r][j];
    a[i][c] = -a[i][c]*a[r][c]; } }
int feasible(int m,int n,ld a[MAXM][MAXN],int B[MAXM],int N[MAXN]) {
  int r,c,i; ld p,v;
  while(1) {
    for(p=INF,i=0; i<m; i++) if(a[i][n]<p) p=a[r=i][n];
    if(p>-EPS) return 1;
    for(p=0,i=0; i<n; i++) if(a[r][i]<p) p=a[r][c=i];
    if(p>-EPS) return 0;
    p = a[r][n]/a[r][c];
    for(i=r+1; i<m; i++) if(a[i][c]>EPS) {
      v = a[i][n]/a[i][c];
      if(v<p) r=i,p=v; }
    pivot(m,n,a,B,N,r,c); } }
int simplex(int m,int n,ld a[MAXM][MAXN],ld b[MAXN],ld& ret) {
  int B[MAXM],N[MAXN],r,c,i; ld p,v;
  for(i=0; i<n; i++) N[i]=i;
  for(i=0; i<m; i++) B[i]=n+i;
  if(!feasible(m,n,a,B,N)) return 0;
  while(1) {
    for(p=0,i=0; i<n; i++) if(a[m][i]>p) p=a[m][c=i];
    if(p<EPS) {
      for(i=0; i<n; i++) if(N[i]<n) b[N[i]]=0;
      for(i=0; i<m; i++) if(B[i]<n) b[B[i]]=a[i][n];
      ret = -a[m][n];
      return 1; }
    for(p=INF,i=0; i<m; i++) if(a[i][c]>EPS) {
      v = a[i][n]/a[i][c];
      if(v<p) p=v,r=i; }
    if(p==INF) return -1;
    pivot(m,n,a,B,N,r,c); } }


./content/numerical/PolyInterpolate.h
/**
 * Author: Simon Lindholm
 * Date: 2017-05-10
 * License: CC0
 * Source: Wikipedia
 * Description: Given $n$ points (x[i], y[i]), computes an n-1-degree polynomial $p$ that
 *  passes through them: $p(x) = a[0]*x^0 + ... + a[n-1]*x^{n-1}$.
 *  For numerical precision, pick $x[k] = c*\cos(k/(n-1)*\pi), k=0 \dots n-1$.
 * Time: O(n^2)
 */
#pragma once

typedef vector<ld> vd;
vd interpolate(vd x, vd y, int n) {
	vd res(n), temp(n);
  for (int k = 0; k < n-1; k++) for (int i = k+1; i < n; i++)
		y[i] = (y[i] - y[k]) / (x[i] - x[k]);
	ld last = 0; temp[0] = 1;
  for (int k = 0; k < n; k++) for (int i = 0; i < n; i++) {
		res[i] += y[k] * temp[i];
		swap(last, temp[i]);
		temp[i] -= last * x[k];
	}
	return res;
}


./content/numerical/PolyRoots.h
/**
 * Author: Per Austrin
 * Date: 2004-02-08
 * License: CC0
 * Description: Finds the real roots to a polynomial.
 * Usage: poly_roots({{2,-3,1}},-1e9,1e9) // solve x^2-3x+2 = 0
 * Time: O(n^2 \log(1/\epsilon))
 */
#pragma once

#include "Polynomial.h"

vector<ld> poly_roots(Poly<ld> p, ld xmin, ld xmax) {
	if (p.a.size() == 2) { return {-p.a[0]/p.a[1]}; }
	vector<ld> ret;
	Poly<ld> der = p;
	der.diff();
	auto dr = poly_roots(der, xmin, xmax);
	dr.push_back(xmin-1);
	dr.push_back(xmax+1);
	sort(dr.begin(), dr.end());
  for (int i = 0; i+1 < dr.size()-1; i++) {
		ld l = dr[i], h = dr[i+1];
		bool sign = p(l) > 0;
		if (sign ^ (p(h) > 0)) {
			for (int it = 0; it < 60; it++) { // while (h - l > 1e-8)
				ld m = (l + h) / 2, f = p(m);
				if ((f <= 0) ^ sign) l = m;
				else h = m;
			}
			ret.push_back((l + h) / 2);
		}
	}
	return ret;
}


./content/numerical/Polynomial.h
/**
 * Author: David Rydh, Per Austrin
 * Date: 2003-03-16
 * Description:
 */
#pragma once

template <class T> struct Poly {
	vector<T> a;
	T operator()(T x) const {
		T val = 0;
		for(int i = a.size(); i--;) (val *= x) += a[i];
		return val;
	}
	void diff() {
		for (int i = 1; i < a.size(); i++) a[i-1] = i*a[i];
		a.pop_back();
	}
	void divroot(T x0) {
		T b = a.back(), c; a.back() = 0;
		for(int i=(int)a.size()-1; i--;) c = a[i], a[i] = a[i+1]*x0+b, b=c;
		a.pop_back();
	}
};


./content/numerical/Simplex.h
/**
 * Author: Stanford
 * Source: Stanford Notebook
 * License: MIT
 * Description: Solves a general linear maximization problem: maximize $c^T x$ subject to $Ax \le b$, $x \ge 0$.
 * Returns -inf if there is no solution, inf if there are arbitrarily good solutions, or the maximum value of $c^T x$ otherwise.
 * The input vector is set to an optimal $x$ (or in the unbounded case, an arbitrary solution fulfilling the constraints).
 * Numerical stability is not guaranteed. For better performance, define variables such that $x = 0$ is viable.
 * Usage:
 * vvd A = {{1,-1}, {-1,1}, {-1,-2}};
 * vd b = {1,1,-4}, c = {-1,-1}, x;
 * T val = LPSolver(A, b, c).solve(x);
 * Time: O(NM * \#pivots), where a pivot may be e.g. an edge relaxation. O(2^n) in the general case.
 * Status: seems to work?
 */
#pragma once

typedef ld T; // long double, Rational, double + mod<P>...
// typedef vector<T> vd; /// include-line
// typedef vector<vd> vvd; /// include-line

const T eps = 1e-8, inf = 1/.0;
#define MP make_pair
#define ltj(X) if(s == -1 || MP(X[j],N[j]) < MP(X[s],N[s])) s=j

struct LPSolver {
	int m, n;
	vi N, B;
	vvd D;

	LPSolver(const vvd& A, const vd& b, const vd& c) :
		m(b.size()), n(c.size()), N(n+1), B(m), D(m+2, vd(n+2)) {
      for (int i=0; i<m; i++) for (int j=0; j<n; j++) D[i][j] = A[i][j];
			for (int i=0; i<m; i++) { B[i]=n+i; D[i][n]=-1; D[i][n+1] = b[i];}
			for (int j=0; j<n; j++) { N[j] = j; D[m][j] = -c[j]; }
			N[n] = -1; D[m+1][n] = 1;
		}

	void pivot(int r, int s) {
		T *a = D[r].data(), inv = 1 / a[s];
		for (int i=0; i<m+2; i++) if (i != r && abs(D[i][s]) > eps) {
			T *b = D[i].data(), inv2 = b[s] * inv;
			for (int j=0; j<n+2; j++) b[j] -= a[j] * inv2;
			b[s] = a[s] * inv2;
		}
		for (int j=0; j<n+2; j++) if (j != s) D[r][j] *= inv;
		for (int i=0; i<m+2; i++) if (i != r) D[i][s] *= -inv;
		D[r][s] = inv;
		swap(B[r], N[s]);
	}

	bool simplex(int phase) {
		int x = m + phase - 1;
		for (;;) {
			int s = -1;
			for (int j=0; j<=n; j++) if (N[j] != -phase) ltj(D[x]);
			if (D[x][s] >= -eps) return true;
			int r = -1;
      for (int i=0; i<m; i++) {
				if (D[i][s] <= eps) continue;
				if (r == -1 || MP(D[i][n+1] / D[i][s], B[i])
				             < MP(D[r][n+1] / D[r][s], B[r])) r = i;
			}
			if (r == -1) return false;
			pivot(r, s);
		}
	}

	T solve(vd &x) {
		int r = 0;
    for (int i=1; i<m; i++) if (D[i][n+1] < D[r][n+1]) r = i;
		if (D[r][n+1] < -eps) {
			pivot(r, n);
			if (!simplex(2) || D[m+1][n+1] < -eps) return -inf;
      for (int i=0; i<m; i++) if (B[i] == -1) {
				int s = 0;
        for (int j=1; j<=n; j++) ltj(D[i]);
				pivot(i, s);
			}
		}
		bool ok = simplex(1); x = vd(n);
		for (int i=0; i<m; i++) if (B[i] < n) x[B[i]] = D[i][n+1];
		return ok ? D[m][n+1] : inf;
	}
};


./content/numerical/SolveLinear.h
/**
 * Author: Per Austrin, Simon Lindholm
 * Date: 2004-02-08
 * License: CC0
 * Description: Solves $A * x = b$. If there are multiple solutions, an arbitrary one is returned.
 *  Returns rank, or -1 if no solutions. Data in $A$ and $b$ is lost.
 * Time: O(n^2 m)
 * Status: tested on kattis:equationsolver, and bruteforce-tested mod 3 and 5 for n,m <= 3
 */
#pragma once

const ld eps = 1e-12;

int solveLinear(vector<vd>& A, vd& b, vd& x) {
	int n = A.size(), m = x.size(), rank = 0, br, bc;
	if (n) assert(A[0].size() == m);
	vi col(m); iota(col.begin(), col.end(), 0);

  for (int i = 0; i < n; i++) {
		ld v, bv = 0;
    for (int r = i; r < n; r++) for (int c = i; c < m; c++)
			if ((v = abs(A[r][c])) > bv)
				br = r, bc = c, bv = v;
		if (bv <= eps) {
      for (int j = i; j < n; j++) if (abs(b[j]) > eps) return -1;
			break;
		}
		swap(A[i], A[br]);
		swap(b[i], b[br]);
		swap(col[i], col[bc]);
    for (int j = 0; j < n; j++) swap(A[j][i], A[j][bc]);
		bv = 1/A[i][i];
    for (int j = i+1; j < n; j++) {
			ld fac = A[j][i] * bv;
			b[j] -= fac * b[i];
      for (int k = i+1; k < m; k++) A[j][k] -= fac*A[i][k];
		}
		rank++;
	}

	x.assign(m, 0);
	for (int i = rank; i--;) {
		b[i] /= A[i][i];
		x[col[i]] = b[i];
    for (int j = 0; j < i; j++) b[j] -= A[j][i] * b[i];
	}
	return rank; // (multiple solutions if rank < m)
}


./content/numerical/SolveLinear2.h
/**
 * Author: Simon Lindholm
 * Date: 2016-09-06
 * License: CC0
 * Source: me
 * Description: To get all uniquely determined values of $x$ back from SolveLinear, make the following changes:
 * Status: tested on kattis:equationsolverplus
 */
#pragma once

#include "SolveLinear.h"

for (int j=0; j<n; j++) if (j != i) // instead of rep(j,i+1,n)
// ... then at the end:
x.assign(m, undefined);
for (int i=0; i<rank; i++) {
  for (int j=rank; j<m; j++) if (abs(A[i][j]) > eps) goto fail;
	x[col[i]] = b[i] / A[i][i];
fail:; }


./content/numerical/SolveLinearBinary.h
/**
 * Author: Simon Lindholm
 * Date: 2016-08-27
 * License: CC0
 * Source: own work
 * Description: Solves $Ax = b$ over $\mathbb F_2$. If there are multiple solutions, one is returned arbitrarily.
 *  Returns rank, or -1 if no solutions. Destroys $A$ and $b$.
 * Time: O(n^2 m/w), where $w = 64$
 * Status: bruteforce-tested for n, m <= 4
 */
#pragma once

typedef bitset<1000> bs;

int solveLinear(vector<bs>& A, vi& b, bs& x, int m) {
	int n = A.size(), rank = 0, br;
	assert(m <= x.size());
	vi col(m); iota(col.begin(), col.end(), 0);
  for (int i = 0; i < n; i++) {
		for (br=i; br<n; ++br) if (A[br].any()) break;
		if (br == n) {
      for (int j = i; j < n; j++) if(b[j]) return -1;
			break;
		}
		int bc = (int)A[br]._Find_next(i-1);
		swap(A[i], A[br]);
		swap(b[i], b[br]);
		swap(col[i], col[bc]);
    for (int j = 0; j < n; j++) if (A[j][i] != A[j][bc]) {
			A[j].flip(i); A[j].flip(bc);
		}
    for (int j = i+1; j < n; j++) if (A[j][i]) {
			b[j] ^= b[i];
			A[j] ^= A[i];
		}
		rank++;
	}

	x = bs();
	for (int i = rank; i--;) {
		if (!b[i]) continue;
		x[col[i]] = 1;
    for (int j = 0; j < i; j++) b[j] ^= A[j][i];
	}
	return rank; // (multiple solutions if rank < m)
}


./content/numerical/Tridiagonal.h
/**
 * Author: Ulf Lundstrom, Simon Lindholm
 * Date: 2009-08-15
 * License: CC0
 * Source: https://en.wikipedia.org/wiki/Tridiagonal_matrix_algorithm
 * Description: $x=\textrm{tridiagonal}(d,p,q,b)$ solves the equation system
\[
\left(\begin{array}{c}b_0\\b_1\\b_2\\b_3\\\vdots\\b_{n-1}\end{array}\right) =
\left(\begin{array}{cccccc}
d_0 & p_0 & 0 & 0 & \cdots & 0\\
q_0 & d_1 & p_1 & 0 & \cdots & 0\\
0 & q_1 & d_2 & p_2 & \cdots & 0\\
\vdots & \vdots & \ddots & \ddots & \ddots & \vdots\\
0 & 0 & \cdots & q_{n-3} & d_{n-2} & p_{n-2}\\
0 & 0 & \cdots & 0 & q_{n-2} & d_{n-1}\\
\end{array}\right)
\left(\begin{array}{c}x_0\\x_1\\x_2\\x_3\\\vdots\\x_{n-1}\end{array}\right).
\]

This is useful for solving problems on the type
\[ a_i=b_ia_{i-1}+c_ia_{i+1}+d_i,\,1\leq i\leq n, \]
where $a_0$, $a_{n+1}$, $b_i$, $c_i$ and $d_i$ are known. $a$ can then be obtained from
\begin{align*}
\{a_i\}=\textrm{tridiagonal}(&\{1,-1,-1,...,-1,1\}, \{0,c_1,c_2,\dots,c_n\},\\
&\{b_1,b_2,\dots,b_n,0\}, \{a_0,d_1,d_2,\dots,d_n,a_{n+1}\}).
\end{align*}
Fails if the solution is not unique.

If $|d_i| > |p_i| + |q_{i-1}|$ for all $i$, or $|d_i| > |p_{i-1}| + |q_i|$, or the matrix is positive definite,
the algorithm is numerically stable and neither \texttt{tr} nor the check for \texttt{diag[i] == 0} is needed.
 * Time: O(N)
 * Status: Brute-force tested mod 5 and 7 and fuzz-tested for real matrices obeying the criteria above.
 */
#pragma once

typedef double T;
vector<T> tridiagonal(vector<T> diag, const vector<T>& super,
		const vector<T>& sub, vector<T> b) {
	int n = b.size(); vi tr(n);
  for (int i = 0; i < n-1; i++) {
		if (abs(diag[i]) < 1e-9 * abs(super[i])) { // diag[i] == 0
			b[i+1] -= b[i] * diag[i+1] / super[i];
			if (i+2 < n) b[i+2] -= b[i] * sub[i+1] / super[i];
			diag[i+1] = sub[i]; tr[++i] = 1;
		} else {
			diag[i+1] -= super[i]*sub[i]/diag[i];
			b[i+1] -= b[i]*sub[i]/diag[i];
		}
	}
	for (int i = n; i--;) {
		if (tr[i]) {
			swap(b[i], b[i-1]);
			diag[i-1] = diag[i];
			b[i] /= super[i-1];
		} else {
			b[i] /= diag[i];
			if (i) b[i-1] -= b[i]*super[i-1];
		}
	}
	return b;
}


./content/strings/AhoCorasick.h
/**
 * Author: Simon Lindholm
 * Date: 2015-02-18
 * License: CC0
 * Source: marian's (TC) code
 * Description: Aho-Corasick tree is used for multiple pattern matching.
 * Initialize the tree with create(patterns). find(word) returns for each position
 * the index of the longest word that ends there, or -1 if none. findAll(\_, word) finds all words
 * (up to $N \sqrt N$ many if no duplicate patterns) that start at each position (shortest first).
 * Duplicate patterns are allowed; empty patterns are not.
 * To find the longest words that start at each position, reverse all input.
 * Time: create is $O(26N)$ where $N$ is the sum of length of patterns.
 * find is $O(M)$ where $M$ is the length of the word. findAll is $O(NM)$.
 * Status: lightly tested
 */
#pragma once

struct AhoCorasick {
	enum {alpha = 26, first = 'A'};
	struct Node {
		// (nmatches is optional)
		int back, next[alpha], start = -1, end = -1, nmatches = 0;
		Node(int v) { memset(next, v, sizeof(next)); }
	};
	vector<Node> N;
	vector<int> backp;
	void insert(string& s, int j) {
		assert(!s.empty());
		int n = 0;
    for (char c : s) {
			int& m = N[n].next[c - first];
			if (m == -1) { n = m = N.size(); N.emplace_back(-1); }
			else n = m;
		}
		if (N[n].end == -1) N[n].start = j;
		backp.push_back(N[n].end);
		N[n].end = j;
		N[n].nmatches++;
	}
	AhoCorasick(vector<string>& pat) {
		N.emplace_back(-1);
		for (int i=0; i<pat.size(); i++) insert(pat[i], i);
		N[0].back = N.size();
		N.emplace_back(0);

		queue<int> q;
		for (q.push(0); !q.empty(); q.pop()) {
			int n = q.front(), prev = N[n].back;
			for (int i=0; i<alpha; i++) {
				int &ed = N[n].next[i], y = N[prev].next[i];
				if (ed == -1) ed = y;
				else {
					N[ed].back = y;
					(N[ed].end == -1 ? N[ed].end : backp[N[ed].start]) = N[y].end;
					N[ed].nmatches += N[y].nmatches;
					q.push(ed);
				}
			}
		}
	}
	vector<int> find(string word) {
		int n = 0;
		vector<int> res; // ll count = 0;
    for (char c : word) {
			n = N[n].next[c - first];
			res.push_back(N[n].end);
			// count += N[n].nmatches;
		}
		return res;
	}
	vector<vector<int>> findAll(vector<string>& pat, string word) {
		vector<int> r = find(word);
		vector<vector<int>> res(word.size());
		for (int i=0; i<word.size(); i++) {
			int ind = r[i];
			while (ind != -1) {
				res[i - pat[ind].size() + 1].push_back(ind);
				ind = backp[ind];
			}
		}
		return res;
	}
};


./content/strings/DavidAhoCorasick.h
/**
 * Author: davidberard
 * Description: Aho-Corasick tree is KMP on a trie
 * insert() all your strings
 * build()
 */
#pragma once

struct AhoCorasick {
  enum { NMAX = 200200, ALPHA = 26 };
  int toi(char c) { assert(false); } // <- implement
  // int toi(char c) { return c - 'a'; } // char to int
  int sz;

  int f[NMAX][ALPHA]; // down edges
  int g[NMAX];        // fail links
  int h[NMAX][ALPHA]; // compressed fail/down
  ll val[NMAX];       // value at position i in 
  int ord[NMAX];       // ord[i] = location of ith string
  int qu[NMAX];        // queue 

  AhoCorasick() {
    sz = 1;
    memset(f, 0, sizeof f);
    memset(g, 0, sizeof g);
    memset(h, 0, sizeof h);
    memset(val, 0, sizeof val);
    memset(ord, 0, sizeof ord);
  }

  void insert(const string& s, int id) {
    int u = 1;
    for (int i=0; i<s.size(); ++i) {
      if (!f[u][toi(s[i])]) {
        f[u][toi(s[i])] = ++sz;
      }
      u = f[u][toi(s[i])];
    }
    ord[id] = u;
  }

  void build() {
    int qcur=0, qlen=0;
    g[1] = 1;
    for (int j=0; j<ALPHA; ++j) {
      if (f[1][j]) {
        qu[qlen++] = f[1][j];
        g[f[1][j]] = 1;
        h[1][j] = f[1][j];
      } else {
        h[1][j] = 1;
      }
    }
    while (qcur < qlen) {
      int u = qu[qcur++];
      for (int j=0; j<ALPHA; ++j) {
        if (!f[u][j]) {
          h[u][j] = h[g[u]][j];
          continue;
        }
        h[u][j] = f[u][j];

        int p=g[u];
        while (p != 1 && f[p][j] == 0) p = g[p];
        if (f[p][j]) p=f[p][j];
        g[f[u][j]] = p;

        qu[qlen++] = f[u][j];
      }
    }
  }

  // find next occurrence of char nxt
  int next(int pos, char nxt) {
    /*
    int k = toi(nxt);
    while (pos != 1 && f[pos][k] == 0) pos = g[pos];
    if (f[pos][k]) return f[pos][k];
    return 1;
    */
    return h[pos][toi(nxt)];
  }

  // propagate val across failure edges
  void propagate() {
    int qcur=0, qlen=0;
    qu[qlen++] = 1;
    while (qcur < qlen) {
      int u = qu[qcur++];
      for (int j=0; j<ALPHA; ++j) {
        if (f[u][j]) {
          qu[qlen++] = f[u][j];
        }
      }
    }

    for (int i=qlen-1; i>=0; --i) {
      int u = qu[i];
      val[g[u]] += val[u];
    }
  }
};


./content/strings/FastSuffixArray.h
/**
 * Source: Antony at UCF
 * Description: $O(N)$ suffix array.
 * Usage:
 *  sa[i] = starting index of ith suffix in sorted suff arr
 *  inv[i] = ranking of s[i..L-1] in sorted suff arr, inverse of sa
 *  lcp[i] = lcp of suffix i-1, i in sorted suff arr, lcp[0] = 0
 * Status: tested SWERC09J
 */

#pragma once

struct suff_arr { // integer rep, suffix array, inverse, adjacent lcp
  vi t, sa, inv, lcp; int N;
  suff_arr(const string& s) : N(s.size()) { // begin-hash
    sa.resize(N); t.resize(N + 3); lcp.resize(N); inv.resize(N);
    for (int i = 0; i < N; i++) t[i] = s[i];
    if (N < 3) { if (N == 2) { sa[(t[0] < t[1])] = 1; } }
    else build(t, sa, N, 128);
    genHeight(); }
  void build(vi& T, vi& sa, int n, int K) {
    int n0 = (n + 2) / 3, n1 = (n + 1) / 3, n2 = n / 3, n02 = n0 + n2;
    vi r(n02 + 3), sa12(n02 + 3), r0(n0), sa0(n0);
    for (int i = 0, j = 0; i < n + n0 - n1; i++)
      if (i % 3 != 0) r[j++] = i;
    pass(r, sa12, T, 2, n02, K);
    pass(sa12, r, T, 1, n02, K);
    pass(r, sa12, T, 0, n02, K);
    int name = 0, c0 = -1, c1 = -1, c2 = -1;
    for (int i = 0; i < n02; i++) {
      if (T[sa12[i]] != c0 || T[sa12[i]+1] != c1 || T[sa12[i]+2] != c2){
        name++;
        c0 = T[sa12[i]]; c1 = T[sa12[i] + 1]; c2 = T[sa12[i] + 2]; }
      r[(sa12[i] % 3 == 1 ? 0 : n0) + sa12[i] / 3] = name; }
    if (name < n02) {
      build(r, sa12, n02, name);
      for (int i = 0; i < n02; i++) { r[sa12[i]] = i+1; }
    } else for (int i = 0; i < n02; i++) { sa12[r[i] - 1] = i; }
    for (int i = 0, j = 0; i < n02; i++)
      if (sa12[i] < n0) r0[j++] = 3 * sa12[i];
    pass(r0, sa0, T, 0, n0, K); // end-hash: 6320ed
    for (int p = 0, t = n0 - n1, k = 0; k < n; k++) { // begin-hash
      int i = sa12[t]<n0 ? (sa12[t]*3+1) : ((sa12[t]-n0)*3+2), j=sa0[p];
      if (sa12[t]<n0 ? leq(T[i], r[sa12[t] + n0], 0, T[j], r[j / 3], 0)
        : leq(T[i], T[i+1], r[sa12[t]-n0+1], T[j], T[j+1], r[j/3+n0])) {
        sa[k] = i;
        if (++t == n02) for (k++; p < n0; sa[k++] = sa0[p++]) {}
      } else { sa[k] = j;
        if (++p == n0)
          for (k++; t < n02; sa[k++] = sa12[t] < n0
            ? (sa12[t++]*3+1) : ((sa12[t++]-n0)*3+2)) {}
      } } } // end-hash: 20a5a8
  bool leq(int a1, int a2, int a3, int b1, int b2, int b3) {
    return a1<b1 || (a1==b1 && a2<b2) || (a1==b1 && a2==b2 && a3<=b3); }
  void pass(vi& a, vi& b, vi& r, int off, int n, int k) { vi c(k + 1);
    for (int i = 0; i < n; c[r[a[i++] + off]]++);
    for (int i = 1; i <= k; i++) c[i] += c[i - 1];
    for (int i = 0; i < n; c[r[a[i++] + off]]--);
    for (int i = 0; i < n; i++) { b[c[r[a[i] + off]]++] = a[i]; } }
  void genHeight() { for (int i = 0; i < N; i++) inv[sa[i]] = i;
    for (int i = 0, h = 0; i < N; i++) if (inv[i] > 0) {
      int j = sa[inv[i] - 1];
      while (i + h < N && j + h < N && t[i + h] == t[j + h]) h++;
      lcp[inv[i]] = h;
      if (h > 0) h--; } } };


./content/strings/Hashing-codeforces.h
/**
 * Author: Simon Lindholm
 * Date: 2015-03-15
 * License: CC0
 * Source: own work
 * Description: Various self-explanatory methods for string hashing.
 * Use on Codeforces, which lacks 64-bit support and where solutions can be hacked.
 * Status: somewhat tested
 */
#pragma once

typedef long long H;
static const H M = INT_MAX;
static H C; // initialized below

// Arithmetic mod M. "typedef H K;" instead if you think
// test data is random. (Haha, good luck.)
struct K {
	H x; K(H x=0) : x(x) {}
	K operator+(K o) { H y = x + o.x; return y - (y >= M) * M; }
	K operator*(K o) { return x*o.x % M; }
	H operator-(K o) { H y = x - o.x; return y + (y < 0) * M; }
};

struct HashInterval {
	vector<K> ha, pw;
	HashInterval(string& str) : ha(sz(str)+1), pw(ha) {
		pw[0] = 1;
		rep(i,0,sz(str))
			ha[i+1] = ha[i] * C + str[i],
			pw[i+1] = pw[i] * C;
	}
	H hashInterval(int a, int b) { // hash [a, b)
		return ha[b] - ha[a] * pw[b - a];
	}
};

vector<H> getHashes(string& str, int length) {
	if (sz(str) < length) return {};
	K h = 0, pw = 1;
	rep(i,0,length)
		h = h * C + str[i], pw = pw * C;
	vector<H> ret = {h - 0};
	ret.reserve(sz(str) - length + 1);
	rep(i,length,sz(str)) {
		ret.push_back(h * C + str[i] - pw * str[i-length]);
		h = ret.back();
	}
	return ret;
}

H hashString(string& s) {
	K h = 0;
	trav(c, s) h = h * C + c;
	return h - 0;
}

#include <sys/time.h>
int main() {
	timeval tp;
	gettimeofday(&tp, 0);
	C = tp.tv_usec;
	// ...
}


./content/strings/Hashing.h
/**
 * Author: Simon Lindholm
 * Date: 2015-03-15
 * License: CC0
 * Source: own work
 * Description: Self-explanatory methods for string hashing.
 * Status: tested
 */
#pragma once

// Arithmetic mod 2^64-1. 2x slower than mod 2^64 and more
// code, but works on evil test data (e.g. Thue-Morse, where
// ABBA... and BAAB... of length 2^10 hash the same mod 2^64).
// "typedef ull H;" instead if you think test data is random,
// or work mod 10^9+7 if the Birthday paradox is not a problem.
struct H {
	typedef uint64_t ull;
	ull x; H(ull x=0) : x(x) {}
#define OP(O,A,B) H operator O(H o) { ull r = x; asm \
	(A "addq %%rdx, %0\n adcq $0,%0" : "+a"(r) : B); return r; }
	OP(+,,"d"(o.x)) OP(*,"mul %1\n", "r"(o.x) : "rdx")
	H operator-(H o) { return *this + ~o.x; }
	ull get() const { return x + !~x; }
	bool operator==(H o) const { return get() == o.get(); }
	bool operator<(H o) const { return get() < o.get(); }
};
static const H C = (ll)1e11+3; // (order ~ 3e9; random also ok)

struct HashInterval {
	vector<H> ha, pw;
	HashInterval(const string& s) : ha(s.size()+1), pw(ha) {
		pw[0] = 1;
		for (int i=0; i<s.size(); i++) {
			ha[i+1] = ha[i] * C + s[i]; pw[i+1] = pw[i] * C;
    }
	}
	H hashInterval(int a, int b) { // hash [a, b)
		return ha[b] - ha[a] * pw[b - a];
	}
};

vector<H> getHashes(const string& s, int length) {
	if (s.size() < length) return {};
	H h = 0, pw = 1;
	for (int i=0; i<length; i++) {
		h = h * C + s[i]; pw = pw * C;
  }
	vector<H> ret = {h};
	for (int i=length; i<s.size(); i++) {
		ret.push_back(h = h * C + s[i] - pw * s[i-length]);
	}
	return ret;
}

H hashString(const string& s) {
  H h{}; for (char c : s) h=h*C+c; return h; }


./content/strings/KMP.h
/**
 * Description: fail[x] computes the length of the longest prefix of s that ends at x, other than s[0...x] itself (abacaba -> 0010123).
 * Can be used to find all occurrences of a string.
 * Usage: auto v = kmp_match(s, pattern); // v = {start indices of matches}
 * Time: O(n+m)
 */
#pragma once

vector<int> kmp_init(string p) { vector<int> fail(p.size()+1);
  for (int i=0, j=-1, m=p.size(); ; ++i, ++j) {
    fail[i] = j; if (i == m) return fail;
    while (j>=0 && p[i]!=p[j]) j = fail[j];
} }
vector<int> kmp_match(string t, string p) { int n=t.size(), m=p.size();
  vector<int> matches, fail = kmp_init(p);
  for (int i=0, j=0; ; ++i, ++j) {
    if (j == m) matches.push_back(i-j), j = fail[j];
    if (i == n) return matches;
    while (j>=0 && t[i]!=p[j]) j = fail[j]; }
  return matches; }


./content/strings/Manacher.h
/**
 * Description: For each position in a string, computes
 *  len[2*i] = length of longest odd palindrome around i,
 *  len[2*i+1] = longest even palindrome at i
 * Time: O(N)
 * Status: tested
 */
#pragma once

int len[2*N-1];
void find_pals(const string& s) {
  len[0] = 1, len[1] = 0; int d;
  for (int i = 1; i+1 < 2*(int)s.length(); i += d) { int& p = len[i];
    int left = (i - p - 1)/2, right = (i + p + 1)/2;
    while (0 <= left && right < (int)s.length() && s[left] == s[right])
      --left, ++right, p += 2;
    for (d = 1; len[i-d] < p-d; ++d) len[i+d] = len[i-d];
    len[i+d] = p-d; } }


./content/strings/MinRotation.h
/**
 * Author: Stjepan Glavina
 * Source: https://github.com/stjepang/snippets/blob/master/min_rotation.cpp
 * Description: Finds the lexicographically smallest rotation of a string.
 * Time: O(N)
 * Status: Fuzz-tested
 * Usage:
 *  rotate(v.begin(), v.begin()+min_rotation(v), v.end());
 */
#pragma once

int min_rotation(string s) {
	int a=0, N=s.size(); s += s;
	for (int b=0; b<N; b++) for (int i=0; i<N; i++) {
		if (a+i == b || s[a+i] < s[b+i]) { b += max(0, i-1); break; }
		if (s[a+i] > s[b+i]) { a = b; break; }
	}
	return a;
}


./content/strings/OldAhoCorasick.h
/**
 * Description: Old Aho-Corasick. Assumes strings are lower case letters: modify \texttt{node* l} to be a map otherwise.
 *  \texttt{nxt[]} gives $O(1)$ per-char shortcut: change to compute lazily if alphabet big.
 * Usage:
 *  1. Use insert method to insert each pattern string with a UNIQUE id.
 *  2. Call build_links on the root of the tree
 *  3. Use get_matches to search for the patterns. Returns ids of strings found
 *     as well as index of last character in the first match of pattern.
 */
struct node { node* l[26], *nxt[26], *failure, *suffix; int index;
  node(){memset(l,0,sizeof l);memset(nxt,0,sizeof l);failure=suffix=0;index=0;}
  void insert(const string& s, int id, int i = 0) {
    if (i == s.size()) { index = id; return; }
    if (l[s[i]-'a'] == NULL) l[s[i]-'a'] = new node;
    l[s[i]-'a']->insert(s, id, i+1); } };
void build_links(node* root) { queue<node*> que; que.push(root);
  while (!que.empty()) { node* p = que.front(); que.pop();
    for (int i=0; i<26; ++i) { if (p->l[i]) p->nxt[i] = p->l[i]; else {
        node* q = p->failure; while (q && !q->nxt[i]) q = q->failure;
        p->nxt[i] = q ? q->nxt[i] : root; } } /*compute nxt[] state per char*/
    for (int i=0; i<26; ++i) if (p->l[i]) { node* q = p->failure;
      while (q && !q->l[i]) q = q->failure;
      if (q) { p->l[i]->failure = q->l[i];
        p->l[i]->suffix = (q->l[i]->index ? q->l[i] : q->l[i]->suffix);
      } else p->l[i]->failure = p->l[i]->suffix = root;
    que.push(p->l[i]); } /*compute fail ptr*/ } }
map<int, int> get_matches(string &s, node* root) {
  map<int, int> ids; node* cur = root;
  for (auto i=0u; i < s.size(); i++) { int c=s[i]-'a';
    /*while(cur != root && !cur->l[c]) cur = cur->failure;
    if (cur->l[c]) cur = cur->l[c];*/ cur=cur->nxt[c]; //shortcut traversal
    node* dict = cur; while (dict != root) {
      if (dict->index && !ids.count(dict->index)) ids[dict->index] = i;
      dict = dict->suffix; } }
  return ids; }


./content/strings/OldSuffixTree.h
/**
 * Author: scary
 * Description: The old suffix tree. Set \texttt{\_A} to smallest in alphabet, or to 0 and fit alphabet in \texttt{[0, ALPHA\_SIZE)}.
 */
const int ALPHA_SIZE=26; char _A='a', _$=_A+ALPHA_SIZE;
int DIM1=(int)sqrt(ALPHA_SIZE+1), DIM2=ceil((ALPHA_SIZE+1.0)/DIM1);
struct edge { typedef vector<vector<edge*> > vve;
  string &s; unsigned int begin, end; vve child; edge *sfxlink, *parent;
  edge(string &ss,int b=0,int e=0):s(ss){
		begin=b,end=e,sfxlink=parent=nullptr;}
  inline edge* get_child(char c) { int id=c-_A;
    if(!child.size() || !child[id/DIM2].size()) return nullptr;
    return child[id/DIM2][id%DIM2]; }
  edge* set_child(char c, edge *chld){ int id=c-_A;
    if(!child.size()) child.resize(DIM1);
    if(!child[id/DIM2].size()) child[id/DIM2].resize(DIM2);
    chld->parent=this; return child[id/DIM2][id%DIM2] = chld; }
  ~edge() {
    for(auto i=0u; i<child.size(); i++)
			for (auto j=0u; j<child[i].size(); j++)
				delete child[i][j];
    child.clear(); } };
// assumptions: e->parent is a root or has a suffix link; pe != 0, pe <= diff
void get_suffix(edge *&e, unsigned int &ep) {
  if((e=e->parent)->sfxlink) e = e->sfxlink, ep += (e->end - e->begin);
  else ep--; } //root
void walk_down(edge *&e, unsigned int &ep, unsigned int sp) {
  while(ep > e->end - e->begin) {
    ep -= (e->end - e->begin);
    e = e->get_child(e->s[sp - ep]); } }
// don't worry about anything above this function except setting _A
edge *build_tree(string &s){ // assume non-zero length for s
  edge *t=new edge(s), *cur=t->set_child(s[0], new edge(s, 0, 1<<30));
  for(auto phase=1u, pos=1u, f=1u; phase<s.size(); phase++, pos++){
    edge **need_sfxlink=nullptr;
    while(true){
      if(f) get_suffix(cur, pos);
      f = 1; walk_down(cur, pos, phase);
      if(cur->end == (1<<30) && pos + cur->begin == phase) continue;
      if((cur->end - cur->begin > pos && s[cur->begin+pos] == s[phase])
				|| (cur->end - cur->begin == pos && cur->get_child(s[phase]))){
           if(need_sfxlink) *need_sfxlink = cur, need_sfxlink = nullptr;
           f = 0; break; }
      if(cur->end - cur->begin > pos){
        edge *parent = cur->parent;
        edge *oedge = new edge(s, cur->begin, cur->begin + pos);
        if(need_sfxlink) *need_sfxlink = oedge, need_sfxlink = nullptr;
        cur->begin = oedge->end;
        oedge->set_child(s[oedge->end], cur);
        need_sfxlink = &oedge->sfxlink; // need to set the other child...
        parent->set_child(s[oedge->begin], oedge);
        oedge->set_child(s[phase], new edge(s, phase, 1<<30));
        cur = oedge;
      } else {
        cur->set_child(s[phase], new edge(s, phase, 1<<30));
        if(need_sfxlink) *need_sfxlink = cur, need_sfxlink = nullptr; }
      if(cur->parent == nullptr) { f = 0; break; } } }
  return t; }
edge *get_state(edge *tree, unsigned int &pos, char ch) {
  if(!tree) return nullptr;
  if(pos < tree->end) {   // inside edge
    if(pos < tree->s.size() && ch == tree->s[pos]) pos++;
    else tree = nullptr;
  } else {                 // right on leaf
    if(tree->get_child(ch))
      tree = tree->get_child(ch), pos = tree->begin + 1;
    else tree = nullptr;
  } return tree; }
bool hasSuffix(string s, string suffix) { // trivial function as example.
  s += _$; suffix += _$;
  edge *tree = build_tree(s); auto pos=0u;
  for (auto i=0u; i < suffix.size(); i++)
    if (!(tree=get_state(tree, pos, suffix[i]))) return false;
  return pos == s.size(); } // matched at [pos-s.size(),pos)


./content/strings/SuffixArray.h
/**
 * Source: adapted from Stanford Team Notebook
 * Description: Builds suffix array for a string.
 * \texttt{idx()[i]} is idx of suffix \texttt{s[i..L-1]} in sorted list of suffixes.
 * \texttt{lcp(i, j)} returns the length of the longest common prefix of \texttt{s[i..L-1]}, \texttt{s[j..L-1]} in $O(\log n)$.
 * N $\ge$ string length, A $\ge$ max(alphabet, N) + 2. Assumes non-negative alphabet.
 * Time: O(n \log^2 n)
 * Status: tested kattis/substrings, 102411/L
 */
#pragma once

namespace SuffixArray {
  const int L = 17; const int N = 1<<L; const int A = 1e9+7;
  int p[L+1][N]; pair<ll,int> m[N]; int last, n;
  /// replace pair<ll,int> ^here with pair<pair<int,int>,int> for 32-bit
  void build(const string& s) { n = s.size();
    if(n <= 1) { p[0][0] = last = 0; return; }
    for (int i = 0; i < n; i++) p[0][i] = s[i];
    for (int j = 1, v = 1; j < n; j *= 2, v++) {
      for (int i = 0; i < n; i++) {
        m[i] = { (ll)p[v-1][i] * A + (i+j<n ? p[v-1][i+j] : -1), i };
      } sort(m, m+n);
      for (int i = 0; i < n; i++) {
        p[v][m[i].second] = (i > 0 && m[i].first == m[i-1].first) ?
          p[v][m[i-1].second] : i; } last = v; } }
  int* idx() { return p[last]; }
  int lcp(int i, int j) {
    int len = 0; if (i == j) return n - i;
    for (int k = last; k >= 0 && i < n && j < n; k--) {
      if (p[k][i] == p[k][j]) { i += 1<<k; j += 1<<k; len += 1<<k; }
    } return len; }
}


./content/strings/SuffixTree.h
/**
 * Author: Unknown
 * Date: 2017-05-15
 * Source: https://e-maxx.ru/algo/ukkonen
 * Description: Ukkonen's algorithm for online suffix tree construction.
 *  Each node contains indices [l, r) into the string, and a list of child nodes.
 *  Suffixes are given by traversals of this tree, joining [l, r) substrings.
 *  The root is 0 (has l = -1, r = 0), non-existent children are -1.
 *  To get a complete tree, append a dummy symbol -- otherwise it may contain
 *  an incomplete path (still useful for substring matching, though).
 * Time: $O(26N)$
 * Status: fuzz-tested a bit
 */
#pragma once

struct SuffixTree {
	enum { N = 200010, ALPHA = 26 }; // N ~ 2*maxlen+10
	int toi(char c) { return c - 'a'; }
	string a; // v = cur node, q = cur position
	int t[N][ALPHA],l[N],r[N],p[N],s[N],v=0,q=0,m=2;

	void ukkadd(int i, int c) { suff:
		if (r[v]<=q) {
			if (t[v][c]==-1) { t[v][c]=m;  l[m]=i;
				p[m++]=v; v=s[v]; q=r[v];  goto suff; }
			v=t[v][c]; q=l[v];
		}
		if (q==-1 || c==toi(a[q])) q++; else {
			l[m+1]=i;  p[m+1]=m;  l[m]=l[v];  r[m]=q;
			p[m]=p[v];  t[m][c]=m+1;  t[m][toi(a[q])]=v;
			l[v]=q;  p[v]=m;  t[p[m]][toi(a[l[m]])]=m;
			v=s[p[m]];  q=l[m];
			while (q<r[m]) { v=t[v][toi(a[q])];  q+=r[v]-l[v]; }
			if (q==r[m])  s[m]=v;  else s[m]=m+2;
			q=r[v]-(q-r[m]);  m+=2;  goto suff;
		}
	}

	SuffixTree(string a) : a(a) {
		fill(r,r+N,a.size());
		memset(s, 0, sizeof s);
		memset(t, -1, sizeof t);
		fill(t[1],t[1]+ALPHA,0);
		s[0] = 1; l[0] = l[1] = -1; r[0] = r[1] = p[0] = p[1] = 0;
		for (int i=0; i<a.size(); i++) ukkadd(i, toi(a[i]));
	}

	// example: find longest common substring (uses ALPHA = 28)
	pii best;
	int lcs(int node, int i1, int i2, int olen) {
		if (l[node] <= i1 && i1 < r[node]) return 1;
		if (l[node] <= i2 && i2 < r[node]) return 2;
		int mask = 0, len = node ? olen + (r[node] - l[node]) : 0;
		for (int c=0; c<ALPHA; c++) if (t[node][c] != -1)
			mask |= lcs(t[node][c], i1, i2, len);
		if (mask == 3)
			best = max(best, {len, r[node] - len});
		return mask;
	}
	static pii LCS(string s, string t) {
		SuffixTree st(s + (char)('z' + 1) + t + (char)('z' + 2));
		st.lcs(0, s.size(), s.size() + 1 + t.size(), 0);
		return st.best;
	}
};


./content/strings/WaveletTree.h
/**
 * Author: henryx
 * Description: Wavelet Tree. stores elements in sorted order (i think).
 * NO UPDATES
 * Usage: WaveletTree wt(s.begin(), s.end()); // WARNING: s gets destroyed!
 * Time: O(\log A) per query
 * Status: untested
 */
#pragma once

struct WaveletTree {
    int lo, hi;
    WaveletTree *left, *right;
    vector<int> b;
    template<class T> WaveletTree(T s, T e):
        WaveletTree(s, e, *min_element(s,e), *max_element(s,e)) {}
    template<class T> WaveletTree(T s, T e, int l, int r): lo(l), hi(r) {
        if (lo == hi || s == e) { left = right = nullptr; return; }
        int mid = (lo+hi)/2;
        auto f = [&](int x) { return x <= mid; };
        b.reserve(distance(s,e)+1); b.push_back(0);
        for (auto it=s; it!=e; it++) b.push_back(b.back()+f(*it));
        auto m = stable_partition(s, e, f);
        left = new WaveletTree(s, m, lo, mid);
        right = new WaveletTree(m, e, mid+1, hi);
    }

    // nth smallest element, inclusive range, must be valid
    int nth(int l, int r, int n) {
        if (l > r) return INF;
        if (lo == hi) return lo;
        int lb = b[l-1], rb = b[r];
        if (n <= rb-lb) return left->nth(lb+1, rb, n);
        else return right->nth(l-lb, r-rb, n-rb+lb);
    }

    // number of elements less than or equal to k
    int leq(int l, int r, int k) {
        if (l > r || k < lo) return 0;
        if (hi <= k) return r-l+1;
        int lb = b[l-1], rb = b[r];
        return left->leq(lb+1, rb, k) + right->leq(l-lb, r-rb, k);
    }

    int count(int l, int r, int k) {
        if (l > r || k < lo || k > hi) return 0;
        if (lo == hi) return r-l+1;
        int lb = b[l-1], rb = b[r], m = (lo+hi)/2;
        if (k <= m) return left->count(lb+1, rb, k);
        else return right->count(l-lb, r-rb, k);
    }
};


./content/strings/Zfunc.h
/**
 * Author: chilli
 * License: CC0
 * Description: z[x] computes the length of the longest common prefix of s[i:] and s. (abacaba -> 0010301)
 *  For string matching, prepend pattern to string being searched, find i s.t. \texttt{z[i] >= pattern.size()}.
 * Time: O(n)
 * Status: fuzz-tested
 */
#pragma once

vector<int> Z(const string& s) {
	int l = -1, r = -1, n = s.size();
	vector<int> z(n); z[0] = n;
	for (int i=1; i<n; i++) {
		z[i] = i >= r ? 0 : min(r - i, z[i - l]);
		while (i + z[i] < n && s[i + z[i]] == s[z[i]]) z[i]++;
		if (i + z[i] > r) l = i, r = i + z[i];
	}
	return z;
}


./content/various/BumpAllocator.h
/**
 * Author: Simon Lindholm
 * Date: 2015-09-12
 * License: CC0
 * Source: me
 * Description: When you need to dynamically allocate many objects and don't care about freeing them.
 * "new X" otherwise has an overhead of something like 0.05us + 16 bytes per allocation.
 * Status: tested
 */
#pragma once

// Either globally or in a single class:
static char buf[450 << 20];
void* operator new(size_t s) {
	static size_t i = sizeof buf;
	assert(s < i);
	return (void*)&buf[i -= s];
}
void operator delete(void*) {}


./content/various/BumpAllocatorSTL.h
/**
 * Author: Simon Lindholm
 * Date: 2016-07-23
 * License: CC0
 * Source: me
 * Description: BumpAllocator for STL containers.
 * Usage: vector<vector<int, small<int>>> ed(N);
 * Status: tested
 */
#pragma once

char buf[450 << 20] alignas(16);
size_t buf_ind = sizeof buf;

template<class T> struct small {
	typedef T value_type;
	small() {}
	template<class U> small(const U&) {}
	T* allocate(size_t n) {
		buf_ind -= n * sizeof(T);
		buf_ind &= 0 - alignof(T);
		return (T*)(buf + buf_ind);
	}
	void deallocate(T*, size_t) {}
};


./content/various/ConstantIntervals.h
/**
 * Author: Simon Lindholm
 * Date: 2015-03-20
 * License: CC0
 * Source: me
 * Description: Split a monotone function on [from, to) into a minimal set of half-open intervals on which it has the same value.
 *  Runs a callback g for each such interval.
 * Usage: constantIntervals(0, sz(v), [\&](int x){return v[x];}, [\&](int lo, int hi, T val){...});
 * Time: O(k\log\frac{n}{k})
 * Status: tested
 */
#pragma once

template<class F, class G, class T>
void rec(int from, int to, F& f, G& g, int& i, T& p, T q) {
	if (p == q) return;
	if (from == to) {
		g(i, to, p);
		i = to; p = q;
	} else {
		int mid = (from + to) >> 1;
		rec(from, mid, f, g, i, p, f(mid));
		rec(mid+1, to, f, g, i, p, q);
	}
}
template<class F, class G>
void constantIntervals(int from, int to, F f, G g) {
	if (to <= from) return;
	int i = from; auto p = f(i), q = f(to-1);
	rec(from, to-1, f, g, i, p, q);
	g(i, to, q);
}


./content/various/DivideAndConquerDP.h
/**
 * Author: Simon Lindholm
 * License: CC0
 * Source: Codeforces
 * Description: Given $a[i] = \min_{lo(i) \le k < hi(i)}(f(i, k))$ where the (minimal) optimal $k$ increases with $i$, computes $a[i]$ for $i = L..R-1$.
 * Status: tested on http://codeforces.com/contest/321/problem/E
 * Time: O((N + (hi-lo)) \log N)
 */
#pragma once

struct DP { // Modify at will:
	int lo(int ind) { return 0; }
	int hi(int ind) { return ind; }
	ll f(int ind, int k) { return dp[ind][k]; }
	void store(int ind, int k, ll v) { res[ind] = pii(k, v); }

	void rec(int L, int R, int LO, int HI) {
		if (L >= R) return;
		int mid = (L + R) >> 1;
		pair<ll, int> best(LLONG_MAX, LO);
		rep(k, max(LO,lo(mid)), min(HI,hi(mid)))
			best = min(best, make_pair(f(mid, k), k));
		store(mid, best.second, best.first);
		rec(L, mid, LO, best.second+1);
		rec(mid+1, R, best.second, HI);
	}
	void solve(int L, int R) { rec(L, R, INT_MIN, INT_MAX); }
};


./content/various/FastMod.h
/**
 * Author: Simon Lindholm
 * Date: 2019-04-19
 * License: CC0
 * Source: https://en.wikipedia.org/wiki/Barrett_reduction
 * Description: Compute $a \% b$ about 4 times faster than usual, where $b$ is constant but not known at compile time.
 * Fails for $b = 1$.
 * Status: proven correct, fuzz-tested
 * Measured as having 3 times lower latency, and 8 times higher throughput.
 */
#pragma once

typedef unsigned long long ull;
typedef __uint128_t L;
struct FastMod {
	ull b, m;
	FastMod(ull b) : b(b), m(ull((L(1) << 64) / b)) {}
	ull reduce(ull a) {
		ull q = (ull)((L(m) * a) >> 64), r = a - q * b;
		return r >= b ? r - b : r;
	}
};


./content/various/IntervalContainer.h
/**
 * Author: Simon Lindholm
 * License: CC0
 * Description: Add and remove intervals from a set of disjoint intervals.
 * Will merge the added interval with any overlapping intervals in the set when adding.
 * Intervals are [inclusive, exclusive).
 * Status: fuzz-tested
 * Time: O(\log N)
 */
#pragma once

set<pii>::iterator addInterval(set<pii>& is, int L, int R) {
	if (L == R) return is.end();
	auto it = is.lower_bound({L, R}), before = it;
	while (it != is.end() && it->first <= R) {
		R = max(R, it->second);
		before = it = is.erase(it);
	}
	if (it != is.begin() && (--it)->second >= L) {
		L = min(L, it->first);
		R = max(R, it->second);
		is.erase(it);
	}
	return is.insert(before, {L,R});
}

void removeInterval(set<pii>& is, int L, int R) {
	if (L == R) return;
	auto it = addInterval(is, L, R);
	auto r2 = it->second;
	if (it->first == L) is.erase(it);
	else (int&)it->second = L;
	if (R != r2) is.emplace(R, r2);
}


./content/various/IntervalCover.h
/**
 * Author: Johan Sannemo
 * License: CC0
 * Description: Compute indices of smallest set of intervals covering another interval.
 * Intervals should be [inclusive, exclusive). To support [inclusive, inclusive],
 * change (A) to add \texttt{|| R.empty()}. Returns empty set on failure (or if G is empty).
 * Time: O(N \log N)
 * Status: Tested on Kattis, intervalcover
 */
#pragma once

template<class T>
vi cover(pair<T, T> G, vector<pair<T, T>> I) {
	vi S(sz(I)), R;
	iota(all(S), 0);
	sort(all(S), [&](int a, int b) { return I[a] < I[b]; });
	T cur = G.first;
	int at = 0;
	while (cur < G.second) { // (A)
		pair<T, int> mx = make_pair(cur, -1);
		while (at < sz(I) && I[S[at]].first <= cur) {
			mx = max(mx, make_pair(I[S[at]].second, S[at]));
			at++;
		}
		if (mx.second == -1) return {};
		cur = mx.first;
		R.push_back(mx.second);
	}
	return R;
}


./content/various/Josephus.h
/**
 * Description: Computes the Josephus ring survivor.
 * Usage: josephus(n, m); survive[i] = survivor for i people, starting at 0, killing every m'th.
 */

#pragma once

int survive[N];
void josephus(int n, int m) { survive[1] = 0;
  for(int i = 2; i <= n; ++i) survive[i] = (m+survive[i-1])%i; }


./content/various/KnuthDP.h
/**
 * Author: Simon Lindholm
 * License: CC0
 * Source: http://codeforces.com/blog/entry/8219
 * Description: When doing DP on intervals: $a[i][j] = \min_{i < k < j}(a[i][k] + a[k][j]) + f(i, j)$, where the (minimal) optimal $k$ increases with both $i$ and $j$,
 *  one can solve intervals in increasing order of length, and search $k = p[i][j]$ for $a[i][j]$ only between $p[i][j-1]$ and $p[i+1][j]$.
 *  This is known as Knuth DP. Sufficient criteria for this are if $f(b,c) \le f(a,d)$ and $f(a,c) + f(b,d) \le f(a,d) + f(b,c)$ for all $a \le b \le c \le d$.
 *  Consider also: LineContainer (ch. Data structures), monotone queues, ternary search.
 * Time: O(N^2)
 */


./content/various/LIS.h
/**
 * Author: Johan Sannemo
 * License: CC0
 * Description: Compute indices for the longest increasing subsequence.
 * Status: Tested on Kattis, longincsubseq
 * Time: $O(N \log N)$
 */
#pragma once

template<class I> vi lis(vector<I> S) {
	vi prev(sz(S));
	typedef pair<I, int> p;
	vector<p> res;
	rep(i,0,sz(S)) {
		p el { S[i], i };
		//S[i]+1 for non-decreasing
		auto it = lower_bound(all(res), p { S[i], 0 }); 
		if (it == res.end()) res.push_back(el), it = --res.end();
		*it = el;
		prev[i] = it==res.begin() ?0:(it-1)->second; 
	}
	int L = sz(res), cur = res.back().second;
	vi ans(L);
	while (L--) ans[L] = cur, cur = prev[cur];
	return ans;
}


./content/various/Poker.h
/**
 * Description: Poker
 */

#pragma once

int pokerEval(int c[]) {
  //c[i]=13*suit+val. suits->0-3, vals->0-12 w/ Ace = 12
  int i,j,s=0,f=1,vc[13],sc[5],sv[5],sw[5]; for(i=0;i<13;i++) vc[i]=0;
  for(i=0;i<5;i++){ sc[i]=sv[i]=0; f&=c[i]/13==c[0]/13; vc[c[i]%13]++; }
  for(i=12;i>=0;i--) { sc[j=vc[i]]++; sw[j]=sv[j]; sv[j]=i;
    if (j==1) s=s*13+i; }
  if (sc[4]) return 7000000+sv[4]*30940+sv[1];
  if (sc[2]&&sc[3]) return 6000000+sv[3]*30927+sv[2]*14;
  if (sc[3]) return 3000000+sv[3]*30927+s;
  if (sc[2]) {
    return sc[2]*1000000+max(sv[2],sw[2])*30758+min(sv[2],sw[2])*182+s;}
  if (s==349674) return 90258+1000000*(f?8:4);
  if (s==368714&&f) return 9000000+s;
  int st=(s-121186)%30941==0;
  return s+(st&&f?8:st?4:f?5:0)*1000000; }


./content/various/SIMD.h
/**
 * Author: Simon Lindholm
 * Date: 2015-03-18
 * License: CC0
 * Source: https://software.intel.com/sites/landingpage/IntrinsicsGuide/
 * Description: Cheat sheet of SSE/AVX intrinsics, for doing arithmetic on several numbers at once.
 * Can provide a constant factor improvement of about 4, orthogonal to loop unrolling.
 * Operations follow the pattern \texttt{"\_mm(256)?\_name\_(si(128|256)|epi(8|16|32|64)|pd|ps)"}. Not all are described here;
 * grep for \texttt{\_mm\_} in \texttt{/usr/lib/gcc/{*}/4.9/include/} for more.
 * If AVX is unsupported, try 128-bit operations, "emmintrin.h" and \#define \texttt{\_\_SSE\_\_} and \texttt{\_\_MMX\_\_} before including it.
 * For aligned memory use \texttt{\_mm\_malloc(size, 32)} or \texttt{int buf[N] alignas(32)}, but prefer loadu/storeu.
 */
#pragma once

#pragma GCC target ("avx2") // or sse4.1
#include "immintrin.h" /** keep-include */

typedef __m256i mi;
#define L(x) _mm256_loadu_si256((mi*)&(x))

// High-level/specific methods:
// load(u)?_si256, store(u)?_si256, setzero_si256, _mm_malloc
// blendv_(epi8|ps|pd) (z?y:x), movemask_epi8 (hibits of bytes)
// i32gather_epi32(addr, x, 4): map addr[] over 32-b parts of x
// sad_epu8: sum of absolute differences of u8, outputs 4xi64
// maddubs_epi16: dot product of unsigned i7's, outputs 16xi15
// madd_epi16: dot product of signed i16's, outputs 8xi32
// extractf128_si256(, i) (256->128), cvtsi128_si32 (128->lo32)
// permute2f128_si256(x,x,1) swaps 128-bit lanes
// shuffle_epi32(x, 3*64+2*16+1*4+0) == x for each lane
// shuffle_epi8(x, y) takes a vector instead of an imm

// Methods that work with most data types (append e.g. _epi32):
// set1, blend (i8?x:y), add, adds (sat.), mullo, sub, and/or,
// andnot, abs, min, max, sign(1,x), cmp(gt|eq), unpack(lo|hi)

int sumi32(mi m) { union {int v[8]; mi m;} u; u.m = m;
	int ret = 0; rep(i,0,8) ret += u.v[i]; return ret; }
mi zero() { return _mm256_setzero_si256(); }
mi one() { return _mm256_set1_epi32(-1); }
bool all_zero(mi m) { return _mm256_testz_si256(m, m); }
bool all_one(mi m) { return _mm256_testc_si256(m, one()); }

ll example_filteredDotProduct(int n, short* a, short* b) {
	int i = 0; ll r = 0;
	mi zero = _mm256_setzero_si256(), acc = zero;
	while (i + 16 <= n) {
		mi va = L(a[i]), vb = L(b[i]); i += 16;
		va = _mm256_and_si256(_mm256_cmpgt_epi16(vb, va), va);
		mi vp = _mm256_madd_epi16(va, vb);
		acc = _mm256_add_epi64(_mm256_unpacklo_epi32(vp, zero),
			_mm256_add_epi64(acc, _mm256_unpackhi_epi32(vp, zero)));
	}
	union {ll v[4]; mi m;} u; u.m = acc; rep(i,0,4) r += u.v[i];
	for (;i<n;++i) if (a[i] < b[i]) r += a[i]*b[i]; // <- equiv
	return r;
}


./content/various/SmallPtr.h
/**
 * Author: Simon Lindholm
 * Date: 2016-08-23
 * License: CC0
 * Source: me
 * Description: A 32-bit pointer that points into BumpAllocator memory.
 * Status: tested
 */
#pragma once

#include "BumpAllocator.h"

template<class T> struct ptr {
	unsigned ind;
	ptr(T* p = 0) : ind(p ? unsigned((char*)p - buf) : 0) {
		assert(ind < sizeof buf);
	}
	T& operator*() const { return *(T*)(buf + ind); }
	T* operator->() const { return &**this; }
	T& operator[](int a) const { return (&**this)[a]; }
	explicit operator bool() const { return ind; }
};


./content/various/TernarySearch.h
/**
 * Author: Simon Lindholm
 * Date: 2015-05-12
 * License: CC0
 * Source: own work
 * Description:
 * Find the smallest i in $[a,b]$ that maximizes $f(i)$, assuming that $f(a) < \dots < f(i) \ge \dots \ge f(b)$.
 * To reverse which of the sides allows non-strict inequalities, change the < marked with (A) to <=, and reverse the loop at (B).
 * To minimize $f$, change it to >, also at (B).
 * Status: tested
 * Usage:
	int ind = ternSearch(0,n-1,[\&](int i){return a[i];});
 * Time: O(\log(b-a))
 */
#pragma once

template<class F>
int ternSearch(int a, int b, F f) {
	assert(a <= b);
	while (b - a >= 5) {
		int mid = (a + b) / 2;
		if (f(mid) < f(mid+1)) // (A)
			a = mid;
		else
			b = mid+1;
	}
	rep(i,a+1,b+1) if (f(a) < f(i)) a = i; // (B)
	return a;
}


./content/various/Unrolling.h
/**
 * Author: Simon Lindholm
 * Date: 2015-03-19
 * License: CC0
 * Source: me
 * Description:
 */
#pragma once

#define F {...; ++i;}
int i = from;
while (i&3 && i < to) F // for alignment, if needed
while (i + 4 <= to) { F F F F }
while (i < to) F


./content/various/WeightedLIS.h
/**
 * Author: henryx
 * Description: Weighted LIS EXAMPLE
 * Time: Probably O(n\log n)
 */

#pragma once

ll weighted_lis_len(const vector<pair<int,ll>>& a) {
	int n = a.size();
	map<int,ll> lis;
	for (int i = 0; i < n; i++) {
		auto it = lis.lower_bound(a[i].first);
		ll cur = a[i].second;
		while (cur > 0 && it != lis.end()) {
			if (it->second <= cur) {
				cur -= it->second;
				it = lis.erase(it);
			} else {
				it->second -= cur;
				cur = 0;
			}
		}
		lis[a[i].first] += a[i].second;
	}
	ll len = 0;
	for (const auto& it : lis) {
		len += it.second;
	}
	return len;
}


